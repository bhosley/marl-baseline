{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[rllib,tune] in /opt/conda/lib/python3.11/site-packages (2.37.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (3.15.4)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (1.0.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (23.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (5.27.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (6.0.2)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (1.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (2.31.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (2.2.2)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (17.0.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (2024.6.1)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (0.1.8)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (0.28.1)\n",
      "Requirement already satisfied: lz4 in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (4.3.3)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (0.24.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (1.14.0)\n",
      "Requirement already satisfied: typer in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (0.12.4)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from ray[rllib,tune]) (13.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib,tune]) (2.1.0)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib,tune]) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib,tune]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib,tune]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib,tune]) (0.0.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema->ray[rllib,tune]) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->ray[rllib,tune]) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->ray[rllib,tune]) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->ray[rllib,tune]) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->ray[rllib,tune]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->ray[rllib,tune]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->ray[rllib,tune]) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->ray[rllib,tune]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->ray[rllib,tune]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->ray[rllib,tune]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->ray[rllib,tune]) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->ray[rllib,tune]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->ray[rllib,tune]) (2.18.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.11/site-packages (from scikit-image->ray[rllib,tune]) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image->ray[rllib,tune]) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.11/site-packages (from scikit-image->ray[rllib,tune]) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.11/site-packages (from scikit-image->ray[rllib,tune]) (2024.8.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.11/site-packages (from scikit-image->ray[rllib,tune]) (0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer->ray[rllib,tune]) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->ray[rllib,tune]) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->ray[rllib,tune]) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install ray[rllib,tune]\n",
    "#!pip install pettingzoo pygame pymunk\n",
    "#!pip install torch\n",
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-20 20:12:29,233\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-10-20 20:12:31,361\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-10-20 20:12:32,405\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.core.rl_module.marl_module` has been deprecated. Use `ray.rllib.core.rl_module.multi_rl_module` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.core.rl_module.marl_module import MultiAgentRLModuleSpec\n",
    "#from ray.rllib.core.rl_module.rl_module import SingleAgentRLModuleSpec\n",
    "from ray.rllib.core.rl_module.rl_module import RLModuleSpec\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "\n",
    "from pettingzoo.sisl import waterworld_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "2024-10-20 20:12:35,727\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "/opt/conda/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:555: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-10-20 20:12:37,022\tWARNING services.py:2022 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67047424 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-10-20 20:12:37,125\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268 \u001b[39m\u001b[22m\n",
      "2024-10-20 20:12:42,020\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-10-20 20:12:42,332\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from os import path\n",
    "import ray\n",
    "from ray.rllib.policy.policy import Policy\n",
    "\n",
    "ray.shutdown() \n",
    "\n",
    "# Trained to about 0 combined return\n",
    "#checkpoint_path = \"/root/ray_results/PPO_2024-08-28_20-57-45/PPO_2_agent_env_2cf59_00000_0_2024-08-28_20-57-45/checkpoint_000000\"\n",
    "checkpoint_path = \"/root/ray_results/PPO_2024-10-20_17-36-00/PPO_2_agent_waterworld_c5957_00000_0_2024-10-20_17-36-00/checkpoint_000000\"\n",
    "pols = glob(checkpoint_path+\"/policies/*\")\n",
    "specs = {path.basename(p) : Policy.from_checkpoint(p) for p in pols}\n",
    "#specs = {path.basename(p) : SingleAgentRLModuleSpec(load_state_path=p) for p in pols} # Non-deterministic policy weight return (implies new)\n",
    "\n",
    "\n",
    "num_agents = 2\n",
    "\n",
    "register_env(f\"{num_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=num_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(num_agents)}\n",
    "\n",
    "\n",
    "resto_config = (\n",
    "    get_trainable_cls(\"PPO\")\n",
    "    .get_default_config()\n",
    "    .environment(f\"{num_agents}_agent_env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .rl_module(\n",
    "        #model_config_dict={\"vf_share_layers\": True},\n",
    "        rl_module_spec=MultiAgentRLModuleSpec(\n",
    "            #load_state_path=\n",
    "            #module_specs=specs,\n",
    "            module_specs={p: RLModuleSpec() for p in policies},\n",
    "            #module_specs={p: Policy.from_checkpoint(pols[0]) for p in policies},\n",
    "        ),\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "resto_algo = resto_config.build()\n",
    "#resto_algo.get_policy(\"pursuer_0\").set_weights(specs[\"pursuer_0\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_1\").set_weights(specs[\"pursuer_1\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_0\").get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resto_algo.save_checkpoint(\"/tmp/temp_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_logits._model.0.weight': array([[-0.0057713 ,  0.02130763, -0.00332906, ..., -0.00251019,\n",
       "          0.01308718, -0.01480941],\n",
       "        [ 0.02027893, -0.00918621,  0.0372359 , ...,  0.00163348,\n",
       "          0.01085026,  0.00847802],\n",
       "        [-0.03894725,  0.07293524, -0.01994372, ...,  0.0666676 ,\n",
       "         -0.03469629, -0.02116322],\n",
       "        [ 0.00803491,  0.02462115, -0.01157856, ..., -0.0220483 ,\n",
       "         -0.02909413,  0.0477805 ]], dtype=float32),\n",
       " '_logits._model.0.bias': array([ 0.00049785,  0.00283682, -0.01044037, -0.01154366], dtype=float32),\n",
       " '_hidden_layers.0._model.0.weight': array([[-0.06341984, -0.01866287,  0.04820696, ..., -0.06329054,\n",
       "         -0.0094757 , -0.1880102 ],\n",
       "        [ 0.04908092, -0.02408476,  0.01319859, ...,  0.0380294 ,\n",
       "          0.11712942,  0.10649226],\n",
       "        [ 0.00440866, -0.02424742, -0.0211874 , ..., -0.00685773,\n",
       "          0.04866119, -0.04014146],\n",
       "        ...,\n",
       "        [ 0.05629121,  0.01958698, -0.01932536, ..., -0.06350598,\n",
       "          0.00073303,  0.02494574],\n",
       "        [ 0.05767507,  0.02367592, -0.1000184 , ..., -0.11080205,\n",
       "          0.0306826 , -0.03873601],\n",
       "        [ 0.02814285,  0.03304771, -0.09030563, ...,  0.03586492,\n",
       "          0.01803334, -0.01949282]], dtype=float32),\n",
       " '_hidden_layers.0._model.0.bias': array([-4.9215741e-03, -7.9965236e-04, -2.4410791e-03,  8.3407015e-03,\n",
       "         2.5819575e-03, -5.9175650e-03,  3.9655319e-03, -6.7910682e-03,\n",
       "        -7.5380644e-04,  4.2199772e-03,  2.0718735e-03,  2.5407004e-03,\n",
       "        -5.4690042e-03,  5.3602420e-03, -8.5677374e-03, -9.2091151e-03,\n",
       "        -5.7352977e-03, -8.4550452e-04,  3.7027923e-03, -4.0584356e-03,\n",
       "         4.9816691e-03,  8.9696562e-03,  8.3527286e-03, -6.1261132e-03,\n",
       "         5.4205512e-03,  9.8865060e-03, -1.0399016e-02,  2.7397119e-03,\n",
       "         4.7436361e-03, -3.3557618e-03,  2.9393870e-03, -1.3278585e-03,\n",
       "        -3.9261407e-03, -7.3005026e-03, -2.5783060e-03,  5.6719049e-03,\n",
       "        -1.2751970e-02,  2.0315130e-03, -5.5209566e-03, -4.3343924e-04,\n",
       "         2.6122809e-03, -1.6808164e-03,  9.3071739e-04,  6.9880101e-04,\n",
       "         1.9063377e-03, -1.9599102e-03,  1.4504656e-04,  8.4571550e-03,\n",
       "        -9.1759255e-03,  1.3203590e-04,  3.7308107e-03, -7.6364568e-03,\n",
       "        -5.3742947e-03,  5.3487602e-03,  5.0470135e-03, -2.1941641e-03,\n",
       "         4.5197131e-03,  5.4127183e-03,  6.3287566e-04, -9.9554770e-03,\n",
       "         2.7463054e-03,  9.1316234e-03,  4.4055730e-03,  4.8095430e-04,\n",
       "         3.5528291e-03,  6.7760097e-03, -5.8875280e-03, -1.9864729e-04,\n",
       "         5.6102136e-03, -1.1827166e-03,  4.0337571e-04, -3.9985552e-03,\n",
       "         3.3620661e-03,  2.8050370e-03, -6.5903459e-04,  8.4974598e-03,\n",
       "        -3.3536640e-03,  6.7684897e-03, -6.6895047e-03, -4.4209096e-03,\n",
       "        -4.0384452e-03, -5.2271625e-03, -8.6489815e-04,  4.3526744e-03,\n",
       "        -1.5154033e-02,  1.0036849e-02, -5.7738852e-03,  1.5471431e-03,\n",
       "         4.3985909e-03, -2.7652828e-03,  1.2129702e-02,  1.0046180e-02,\n",
       "         5.0983843e-03, -7.2724679e-03, -7.1640131e-03,  9.9235866e-03,\n",
       "         2.5125539e-03, -4.6541539e-04,  3.1848189e-03,  8.8275416e-04,\n",
       "        -6.1802804e-03,  2.9187303e-03,  4.0186830e-03, -8.9154448e-03,\n",
       "        -1.8736621e-03, -1.6149345e-03, -2.8330006e-03, -1.0474589e-02,\n",
       "         9.5108841e-03,  2.2977600e-03, -2.5169107e-03,  1.1776578e-02,\n",
       "        -4.5618797e-03,  3.0588498e-04, -2.6591753e-03, -6.4575137e-04,\n",
       "         2.2268115e-04, -2.6605166e-03,  1.2104529e-03, -6.7105476e-04,\n",
       "         7.9218550e-03,  9.9338088e-03, -4.3195388e-03, -8.3753197e-03,\n",
       "        -3.3879906e-03,  1.2543694e-03, -1.3198438e-03,  3.7802428e-03,\n",
       "        -4.0064944e-04,  1.0576708e-03,  4.5219925e-03,  3.2911068e-03,\n",
       "         6.8505673e-04, -1.5530059e-03,  3.3427032e-03, -2.3827814e-03,\n",
       "        -1.1705259e-03,  7.9276031e-03, -5.3756265e-03, -4.1489433e-03,\n",
       "        -9.1787409e-03, -4.5014676e-04, -8.7661762e-03,  6.9023934e-03,\n",
       "         1.8051646e-04,  6.6780695e-03, -3.6000062e-03, -5.1577948e-03,\n",
       "        -3.3317653e-03, -2.3510640e-03,  7.1135010e-03,  3.4507168e-03,\n",
       "        -1.9366671e-03, -4.5648676e-06,  4.8224319e-04,  8.4225554e-03,\n",
       "         2.3426574e-03, -1.2590097e-03,  1.8956030e-02,  4.4449833e-03,\n",
       "        -8.1024831e-03, -2.4914986e-03,  1.0293867e-03, -6.3438737e-03,\n",
       "         5.1028291e-03, -5.1667704e-03, -5.3620660e-03,  1.2200833e-03,\n",
       "         4.0453221e-03, -5.7939249e-03,  1.0953906e-03, -4.3215957e-03,\n",
       "        -6.8659522e-04,  3.5273675e-03, -2.9476173e-03,  2.9052696e-03,\n",
       "        -1.9109624e-03, -7.1653370e-03, -3.6732212e-03,  8.7197246e-03,\n",
       "         2.4582150e-03, -1.4793021e-03,  6.4889394e-04, -9.0748463e-03,\n",
       "         1.2644636e-03,  2.0964504e-03, -4.8619783e-03, -1.7664438e-03,\n",
       "         9.2152324e-05,  6.2957532e-03,  8.1428783e-03,  7.2709392e-03,\n",
       "        -1.2165843e-02,  2.3598000e-03,  4.3597552e-03,  1.1020376e-02,\n",
       "        -4.9264235e-03, -1.0092086e-02, -3.9806068e-03,  3.0257777e-04,\n",
       "        -3.3451691e-03, -2.1796445e-03, -5.1862011e-03, -5.5999756e-03,\n",
       "         6.7013726e-03, -4.7693746e-03, -8.7331859e-03,  1.2547286e-02,\n",
       "         1.5408835e-04, -1.7956800e-03, -1.0104898e-02,  4.8258323e-03,\n",
       "         5.8629732e-03, -2.6784653e-03,  3.7116827e-03, -1.7999882e-04,\n",
       "         6.4195436e-04, -9.8293822e-04,  6.4517854e-04,  4.9572578e-03,\n",
       "        -4.9804122e-04, -2.4375874e-04, -2.5525566e-03, -6.1881640e-03,\n",
       "         3.4258137e-05,  1.5054173e-03,  2.0825304e-03, -3.8640483e-04,\n",
       "         2.4520031e-03, -3.0114420e-03, -2.9144108e-03,  1.3093388e-03,\n",
       "        -2.3681950e-03, -2.7204845e-03,  4.2295670e-03,  1.5123185e-03,\n",
       "        -4.7613056e-03,  4.5374744e-03, -6.7227967e-03,  1.2252724e-03,\n",
       "        -4.1295430e-03, -7.8394526e-04, -1.4562532e-03,  8.6202075e-05,\n",
       "        -9.0148570e-03,  1.3717955e-03, -1.2362893e-03,  2.6005176e-03,\n",
       "         1.2509948e-02, -4.6894345e-03, -8.7176552e-03, -1.9968755e-03,\n",
       "        -7.5558233e-03, -1.0756257e-02,  6.1853486e-03,  2.2083875e-03],\n",
       "       dtype=float32),\n",
       " '_hidden_layers.1._model.0.weight': array([[-0.01419797, -0.12486223, -0.00886009, ..., -0.02681187,\n",
       "          0.00568813, -0.00070431],\n",
       "        [ 0.00858973,  0.01427813, -0.1839366 , ...,  0.00312674,\n",
       "          0.11305308, -0.01247808],\n",
       "        [-0.03847576, -0.08451046,  0.01350692, ...,  0.00575237,\n",
       "         -0.01126341, -0.03715782],\n",
       "        ...,\n",
       "        [ 0.06541324,  0.1559761 ,  0.06431769, ..., -0.03454493,\n",
       "         -0.0179561 ,  0.06414513],\n",
       "        [-0.05857896,  0.06287325, -0.00726445, ..., -0.09529498,\n",
       "         -0.03645266, -0.05787133],\n",
       "        [ 0.13874765, -0.10967673,  0.01516597, ..., -0.07411338,\n",
       "          0.13767652, -0.01762111]], dtype=float32),\n",
       " '_hidden_layers.1._model.0.bias': array([ 5.96611528e-03, -5.76855906e-04, -4.59683593e-03, -1.45714590e-03,\n",
       "        -7.55869178e-03,  1.00326100e-02, -1.78591337e-03,  6.73368061e-03,\n",
       "        -3.77278822e-03,  7.41181662e-04,  2.65748613e-03,  4.16512456e-04,\n",
       "        -1.59616547e-03,  1.71415100e-03, -5.23075694e-03, -1.77612307e-03,\n",
       "         7.35583855e-03, -1.09745853e-03,  5.04293479e-03,  2.58164038e-03,\n",
       "         2.45687412e-03, -4.00487287e-03,  8.41654371e-04, -1.00584887e-03,\n",
       "         2.30706250e-03, -6.99081938e-05,  9.42576677e-04,  8.06865934e-03,\n",
       "        -5.26900589e-03, -2.88849056e-04,  1.10928565e-02,  7.85285514e-03,\n",
       "        -2.32297136e-03,  1.18762872e-03,  6.04209816e-03, -4.39740391e-03,\n",
       "        -1.03426271e-03,  2.14495696e-03, -2.40828423e-03,  1.61782503e-02,\n",
       "        -6.62333984e-03, -1.27244452e-02, -3.06532718e-04,  3.40028899e-03,\n",
       "         1.58401504e-02, -4.69478918e-03,  8.73202272e-03, -8.07604846e-03,\n",
       "        -3.46625783e-03, -1.67459788e-04,  3.50534846e-03, -4.06955322e-03,\n",
       "         3.17642419e-03,  5.89969661e-03, -8.07978306e-03, -2.01826673e-02,\n",
       "        -3.78156314e-03, -3.12575442e-03, -3.42433364e-03,  7.48425769e-03,\n",
       "        -1.41151904e-05, -1.71756260e-02,  1.10869780e-02,  1.23244431e-03,\n",
       "         1.96174922e-04,  3.66872712e-03,  9.78782028e-03, -3.51770478e-03,\n",
       "         3.52498121e-03,  1.12680076e-02, -2.04273337e-03,  1.91302248e-03,\n",
       "        -9.34837572e-03, -2.31268746e-03,  1.07111584e-03,  8.64100643e-03,\n",
       "        -3.82899816e-05, -5.59639279e-03,  5.58635173e-03, -2.14619352e-03,\n",
       "        -2.16163485e-03, -2.76102714e-04,  1.68947142e-03,  9.54952743e-03,\n",
       "         8.56875069e-03,  7.31621403e-04,  4.56130365e-03, -1.59028487e-03,\n",
       "         3.57710198e-03,  7.44422025e-04,  5.35588618e-03,  3.38473311e-03,\n",
       "         1.15053300e-02, -4.25844360e-03,  1.68488862e-03, -3.30383750e-03,\n",
       "         3.11664073e-03,  1.16220806e-02, -8.04630667e-03,  1.40374964e-02,\n",
       "        -4.98975511e-04, -6.88665686e-03,  2.29330547e-03, -3.19676357e-04,\n",
       "        -8.63400381e-03, -7.61512900e-03,  8.35160725e-03,  1.85764779e-03,\n",
       "        -5.02078468e-03, -6.19360188e-04,  3.40268156e-03, -8.65096413e-03,\n",
       "         1.08707389e-02, -1.19427834e-02,  3.54797929e-04, -1.86375401e-03,\n",
       "        -1.92011602e-03, -2.16234545e-03, -2.94033601e-03,  1.53007684e-03,\n",
       "         1.17739020e-02, -3.49585389e-05, -3.07419011e-03, -6.73397444e-03,\n",
       "        -1.52760965e-03,  4.10519773e-03,  5.73435158e-04,  8.12295172e-03,\n",
       "        -5.09667164e-03,  5.78952115e-03, -2.39725225e-03, -8.71523842e-03,\n",
       "         7.69020710e-03, -3.76070122e-04,  9.68495850e-03,  6.10301504e-04,\n",
       "        -2.66626640e-03, -5.82826929e-03,  1.06024444e-02,  1.16860978e-02,\n",
       "         3.11539555e-03,  6.81164768e-03,  3.09729774e-04, -3.29445186e-03,\n",
       "        -4.48451983e-03, -1.32789393e-03,  1.59049104e-03,  2.55962904e-03,\n",
       "         6.19008578e-03,  1.06378431e-02,  6.21485291e-03, -6.74660038e-03,\n",
       "         2.13687448e-03, -3.98384919e-03,  1.84299436e-03,  3.46669724e-04,\n",
       "        -5.41885942e-03,  1.17429858e-02,  8.77584703e-03,  1.41411531e-03,\n",
       "         1.84947252e-03,  2.88689858e-04,  1.16133690e-02,  5.77970175e-03,\n",
       "        -2.27033946e-04, -2.20858841e-03, -1.97993987e-03,  2.40586861e-03,\n",
       "        -7.67981401e-03, -1.89263214e-04, -3.65916872e-03,  1.19949866e-03,\n",
       "         3.29373893e-03, -8.29509285e-04,  8.37699103e-04,  8.48740619e-03,\n",
       "        -1.03239287e-02,  9.84366145e-03,  1.15829809e-02,  5.09666186e-03,\n",
       "        -8.33827630e-03,  4.09874693e-03, -7.50868721e-03, -1.96655886e-03,\n",
       "        -1.31416763e-03,  5.00048697e-03, -2.87327426e-03, -1.36159910e-02,\n",
       "         5.92433522e-03, -1.36103695e-02,  3.88317858e-03,  8.38228688e-03,\n",
       "        -5.62498579e-03, -8.90260655e-03, -3.55811149e-04,  1.25406114e-02,\n",
       "         4.11608955e-03,  1.79491559e-04,  8.07579234e-03, -8.51192605e-03,\n",
       "         1.51429244e-03,  5.76576777e-03, -2.89966847e-04,  2.62681395e-03,\n",
       "         3.01184715e-04,  4.20235284e-03, -2.44504749e-03,  4.24479414e-03,\n",
       "        -4.53244476e-03, -4.08727350e-03, -7.61651341e-03,  1.53040164e-03,\n",
       "        -4.36132483e-04,  4.33138432e-03,  6.13777013e-03,  1.34385366e-03,\n",
       "         7.53864530e-04,  6.37923833e-03, -2.32840632e-03,  8.52599798e-04,\n",
       "        -9.07132868e-03,  4.96702362e-03,  7.25330506e-03,  1.00701768e-02,\n",
       "        -3.37843871e-04,  2.02261168e-03,  8.36737826e-03, -4.06535622e-03,\n",
       "         8.30084831e-03, -1.30080513e-03, -7.94754550e-03, -6.21039886e-03,\n",
       "        -1.52868289e-03,  1.34376809e-03, -3.39815556e-03,  2.13383045e-03,\n",
       "        -1.17406463e-02, -5.79015072e-03,  1.64820813e-03,  7.94670079e-03,\n",
       "         8.80266353e-03, -4.25690878e-03,  1.93305372e-04,  8.12825095e-03,\n",
       "         3.76156764e-03, -1.08832112e-02, -2.88135419e-03, -2.37888237e-03,\n",
       "         4.08063689e-03, -5.22716297e-03,  9.32747126e-03, -9.92594101e-03,\n",
       "        -2.14484427e-03, -8.50934163e-03,  1.00643132e-02,  2.25334777e-03],\n",
       "       dtype=float32),\n",
       " '_value_branch_separate.0._model.0.weight': array([[-0.04970036,  0.03203391,  0.00243363, ..., -0.06702767,\n",
       "         -0.12597966,  0.12103654],\n",
       "        [-0.12401084, -0.02051374,  0.05926413, ...,  0.0443644 ,\n",
       "          0.0133007 , -0.05439172],\n",
       "        [-0.02843739,  0.07499654, -0.03342893, ...,  0.0080643 ,\n",
       "         -0.12435565,  0.00427401],\n",
       "        ...,\n",
       "        [ 0.12807427,  0.01837508,  0.02018862, ..., -0.0514529 ,\n",
       "         -0.29573435, -0.09681422],\n",
       "        [ 0.08869156, -0.03710815,  0.20448565, ...,  0.0180778 ,\n",
       "          0.20351565, -0.10750779],\n",
       "        [-0.05637036, -0.07293333, -0.03156194, ...,  0.10288819,\n",
       "         -0.2955758 ,  0.06182278]], dtype=float32),\n",
       " '_value_branch_separate.0._model.0.bias': array([-0.0010297 , -0.00852578,  0.00840731, -0.00406268, -0.00499971,\n",
       "        -0.00130923,  0.0012036 ,  0.01300859,  0.01069793, -0.0054142 ,\n",
       "         0.00396203, -0.00302994,  0.00044154, -0.00879998,  0.00320336,\n",
       "         0.00323951, -0.01606052,  0.00695157, -0.00836208, -0.00547832,\n",
       "         0.01451502, -0.00267458,  0.00666413, -0.00637406,  0.00296296,\n",
       "        -0.00342759,  0.00046361,  0.00064746,  0.01322812,  0.00795913,\n",
       "         0.00802953, -0.00566066,  0.00421941,  0.00044057,  0.00717026,\n",
       "        -0.0052074 , -0.00021227,  0.00805288,  0.00884139, -0.00604825,\n",
       "         0.0035219 ,  0.0094638 , -0.00428554, -0.00165782,  0.01057032,\n",
       "         0.00396798,  0.02163752, -0.00354436,  0.01004389, -0.00344089,\n",
       "        -0.00722691,  0.00643427, -0.00405442, -0.00408284,  0.01141442,\n",
       "        -0.01200057,  0.00734671, -0.00168726, -0.00169027,  0.00094941,\n",
       "        -0.00554819,  0.00605509, -0.00045625,  0.00193306, -0.00014868,\n",
       "        -0.00648753, -0.00011278,  0.00263319, -0.00187391,  0.0099256 ,\n",
       "        -0.00286756, -0.00763068, -0.00898433,  0.00078709, -0.00385257,\n",
       "         0.00167723, -0.01235814,  0.00331029,  0.01149394,  0.00689055,\n",
       "        -0.00943056, -0.01100323, -0.01235725, -0.00195728,  0.00019799,\n",
       "         0.01160845,  0.0083557 , -0.00146513, -0.00969621, -0.00735722,\n",
       "         0.00252102,  0.00466229,  0.00112646, -0.00778371, -0.00022134,\n",
       "        -0.00884005,  0.00911994,  0.00136713,  0.00307578,  0.0071259 ,\n",
       "         0.00929253,  0.00166829,  0.01058448, -0.00024754,  0.00732977,\n",
       "         0.001108  , -0.0049492 ,  0.0054294 , -0.00062842, -0.00379291,\n",
       "         0.00720747,  0.00288305, -0.00146543, -0.00859149, -0.0083317 ,\n",
       "        -0.00706867,  0.00633601, -0.01014439,  0.00367313, -0.0030167 ,\n",
       "         0.00972833,  0.0008775 , -0.00576993,  0.00166002,  0.01222146,\n",
       "        -0.00310087,  0.0018407 ,  0.00182144,  0.00289183, -0.0092439 ,\n",
       "        -0.00995371,  0.00308712, -0.00299237,  0.00392276, -0.00422367,\n",
       "         0.00114275, -0.00966086, -0.00299619,  0.00050538, -0.00147799,\n",
       "         0.00207396, -0.00452284, -0.01703806,  0.00146503, -0.00732849,\n",
       "         0.00180093, -0.00182914, -0.00940056, -0.01067785,  0.00270051,\n",
       "         0.01260122, -0.00019225, -0.00246878,  0.00354375, -0.00056727,\n",
       "         0.00536013,  0.00115221, -0.00561405, -0.01397411,  0.00878822,\n",
       "         0.00017763,  0.00554326,  0.00312585,  0.00276149, -0.0028667 ,\n",
       "        -0.00783686,  0.01168928, -0.0019508 ,  0.00146498,  0.00787322,\n",
       "         0.01301087, -0.00127864, -0.00401893,  0.00183864,  0.00051559,\n",
       "         0.0103961 , -0.00699071,  0.00087868, -0.00992878,  0.0066347 ,\n",
       "        -0.00039348,  0.00187528, -0.00379433, -0.00036312,  0.00396534,\n",
       "        -0.00642555, -0.00246436,  0.00349093,  0.00433336, -0.00451706,\n",
       "         0.00398069, -0.00011469, -0.00211482,  0.0084324 , -0.00434367,\n",
       "         0.00838219,  0.00870765, -0.00177449, -0.00033412, -0.01077957,\n",
       "        -0.01560737, -0.00792194, -0.0149783 , -0.01514071, -0.000693  ,\n",
       "         0.0031766 , -0.000684  , -0.02231018, -0.00271035,  0.00685956,\n",
       "         0.00607167,  0.00712792,  0.00080275,  0.00074943, -0.00731311,\n",
       "         0.00332331,  0.00198254, -0.00471799, -0.01244231, -0.00858918,\n",
       "        -0.00344909,  0.0066731 ,  0.00465444, -0.01350829,  0.00253004,\n",
       "        -0.00211454,  0.01013362, -0.00179413,  0.00696708, -0.00233623,\n",
       "        -0.01076809,  0.00956486, -0.00852775,  0.00588326, -0.00687923,\n",
       "         0.00644134,  0.01405144,  0.00488838,  0.00171498,  0.01001802,\n",
       "         0.00216297, -0.00828313, -0.00688689, -0.00479712, -0.00318053,\n",
       "         0.00674059, -0.00067008, -0.00209929,  0.00138947, -0.00319238,\n",
       "         0.00493294, -0.00367873, -0.00570769,  0.00463654,  0.003082  ,\n",
       "         0.0147713 ], dtype=float32),\n",
       " '_value_branch_separate.1._model.0.weight': array([[ 0.11341242,  0.08716995, -0.06344729, ...,  0.05233669,\n",
       "         -0.18362823,  0.02336317],\n",
       "        [ 0.10005645,  0.06784332,  0.03034151, ..., -0.0227753 ,\n",
       "         -0.01229427, -0.06866226],\n",
       "        [ 0.12753579,  0.16951483, -0.16183662, ..., -0.09463967,\n",
       "         -0.01709697, -0.00039028],\n",
       "        ...,\n",
       "        [-0.08854911, -0.03754264,  0.04793702, ..., -0.06958213,\n",
       "         -0.04912792,  0.0291281 ],\n",
       "        [-0.1665807 , -0.03394984, -0.03100488, ..., -0.07425211,\n",
       "          0.04243387,  0.14282341],\n",
       "        [ 0.05781211, -0.16986232,  0.02373631, ...,  0.11714494,\n",
       "          0.09787598, -0.08373186]], dtype=float32),\n",
       " '_value_branch_separate.1._model.0.bias': array([ 1.83917247e-02, -1.36149619e-02,  5.69366664e-03,  3.32698645e-03,\n",
       "        -5.49690053e-03, -2.66673043e-02, -1.89405885e-02, -7.24653574e-03,\n",
       "         2.85876985e-03, -1.12694036e-03,  5.55469934e-03, -1.31472135e-02,\n",
       "        -1.19780470e-02,  2.00648103e-02, -2.86532212e-02, -6.39350293e-03,\n",
       "        -6.80475915e-03,  4.53639030e-03, -3.15486314e-03, -1.86809117e-03,\n",
       "         5.56976441e-03,  1.59810428e-02, -5.70418313e-03, -2.09201351e-02,\n",
       "        -1.87541563e-02, -8.86297610e-04, -2.94110067e-02,  4.55507456e-04,\n",
       "         2.79180449e-03,  3.29859438e-03,  1.56854000e-02, -8.86365771e-03,\n",
       "        -1.00039458e-03, -6.84447167e-03, -6.28631702e-03,  2.48845224e-03,\n",
       "        -2.44015437e-02, -2.67841425e-02, -6.80375332e-03,  1.42600713e-02,\n",
       "        -2.51439288e-02, -2.05777697e-02, -1.01484004e-02, -3.11026786e-04,\n",
       "        -1.74308605e-02, -6.08120067e-03,  3.12358439e-02, -4.25180234e-03,\n",
       "        -6.94517931e-03,  1.44485030e-02, -1.72435921e-02, -7.77855376e-03,\n",
       "        -3.75466887e-03, -9.88923293e-03, -1.36983646e-02, -4.91092587e-03,\n",
       "         9.28977598e-03, -2.85947528e-02, -1.98397245e-02,  2.61260965e-03,\n",
       "         1.23012085e-02, -5.56888990e-04, -5.65416366e-03, -1.65598113e-02,\n",
       "         1.50595009e-02,  1.72409117e-02, -5.62938303e-03,  4.13298700e-03,\n",
       "        -1.13364514e-02, -3.28048074e-04,  3.16801458e-03,  5.28352743e-04,\n",
       "        -5.53474575e-03,  3.69769968e-02,  2.01235041e-02,  2.81581376e-02,\n",
       "        -2.06387546e-02,  4.04673256e-03, -7.86217675e-03,  3.68101825e-03,\n",
       "        -5.29834826e-04,  1.06832432e-02,  1.72478482e-02, -1.09616760e-02,\n",
       "         1.75877381e-02,  6.44774060e-04,  2.09306178e-04, -1.26633029e-02,\n",
       "         3.45106749e-03, -2.27224771e-02, -7.37315509e-03, -9.57677793e-03,\n",
       "        -1.75516633e-03, -3.62847783e-02,  4.12855064e-03, -5.47849433e-03,\n",
       "         8.77382793e-03,  1.80660170e-02, -1.39645981e-02, -9.38950293e-03,\n",
       "        -6.71099965e-03, -1.95905776e-03, -6.05876558e-03,  6.95621781e-03,\n",
       "         2.13016197e-03,  4.88668028e-03,  1.38794528e-02, -2.75584683e-02,\n",
       "         2.32414361e-02,  2.25696689e-03, -1.92658808e-02, -3.00269704e-02,\n",
       "        -2.02525035e-02,  1.85527317e-02,  1.37196276e-02, -1.40309967e-02,\n",
       "        -1.42517220e-02, -7.03857047e-04, -1.50419706e-02,  5.65500231e-03,\n",
       "        -1.59192886e-02,  3.75211681e-03, -2.79593654e-03, -4.78360569e-03,\n",
       "        -3.78741464e-03,  2.24756077e-02, -2.73554903e-02,  3.35502322e-03,\n",
       "         1.30266082e-02, -3.01851728e-03, -5.58734220e-03,  6.64214778e-04,\n",
       "        -2.87574623e-03, -1.49302678e-02, -2.63644960e-02, -1.01035275e-02,\n",
       "        -2.59499308e-02,  1.43308006e-02,  1.93049069e-02,  1.73238181e-02,\n",
       "         4.92123887e-03, -1.01344865e-02, -1.93313360e-02, -5.32076741e-03,\n",
       "         3.45347379e-03,  1.40181854e-02, -2.11265944e-02, -2.19652499e-03,\n",
       "        -2.85258889e-02, -6.24373322e-03,  1.36956209e-04,  4.83896583e-03,\n",
       "        -1.97553318e-02, -2.33800393e-02, -1.23552354e-02,  1.69963781e-02,\n",
       "        -1.43900430e-02,  2.10716501e-02, -1.00222100e-02,  1.36076985e-02,\n",
       "        -1.69816297e-02, -8.69629002e-05,  7.23565277e-03, -5.58940321e-03,\n",
       "         2.16803215e-02, -4.97017847e-03, -1.00251846e-02,  2.62200320e-03,\n",
       "        -7.23797781e-03, -1.75426751e-02, -8.70757643e-03,  2.04810258e-02,\n",
       "        -4.63855965e-03,  4.69230162e-03,  3.41936410e-03, -1.37198977e-02,\n",
       "        -1.17255850e-02,  9.57384147e-03, -3.60641512e-03, -3.66260298e-02,\n",
       "        -3.97244329e-03,  1.00812856e-02,  3.91897839e-03,  3.82599770e-03,\n",
       "        -1.36469323e-02,  1.06421551e-02, -2.63078022e-03,  4.79093613e-03,\n",
       "         2.14642403e-03, -5.08898776e-03, -7.70621700e-03,  2.70997756e-04,\n",
       "        -2.62012612e-02, -2.06580991e-03, -2.11661987e-04,  2.10426114e-02,\n",
       "        -1.65745188e-02, -1.16886208e-02, -1.51587115e-03, -1.39020439e-02,\n",
       "         1.49001237e-02, -1.49046455e-03,  1.41456621e-02, -2.17592679e-02,\n",
       "        -5.02850115e-03,  9.31894127e-03, -2.72554848e-02, -6.89003197e-03,\n",
       "        -1.86259225e-02,  5.43540437e-03,  8.36206041e-03,  1.33735267e-02,\n",
       "        -3.88419256e-02, -2.60464307e-02,  2.42727958e-02,  2.11467072e-02,\n",
       "        -4.34266869e-03,  3.31167411e-03,  2.90701608e-03, -9.91424825e-03,\n",
       "         1.18218940e-02,  2.18369327e-02, -1.56094844e-03,  1.50163937e-02,\n",
       "        -2.92854533e-02,  7.18914717e-03,  2.33976599e-02,  1.99346431e-03,\n",
       "         7.23156519e-03, -9.25445464e-03,  2.14480776e-02, -1.98617019e-02,\n",
       "        -4.29213466e-03,  2.57133413e-02,  3.87445907e-03, -9.24794003e-03,\n",
       "         2.09915023e-02,  5.15318103e-03, -2.98643392e-02, -3.68958036e-03,\n",
       "        -2.65078489e-02, -2.65691280e-02, -9.46378056e-03, -2.94499770e-02,\n",
       "         2.68020644e-03, -1.74437538e-02, -6.41596690e-03,  3.60183138e-03,\n",
       "        -9.90363187e-04, -8.43373872e-03, -3.80091392e-03,  9.42771323e-03,\n",
       "        -8.83641373e-03, -1.30815031e-02, -5.49820811e-03,  1.28217852e-02],\n",
       "       dtype=float32),\n",
       " '_value_branch._model.0.weight': array([[-0.09685739,  0.10204422,  0.11382004, -0.12016171,  0.1879257 ,\n",
       "          0.09951178,  0.10325524,  0.12050769,  0.0956592 ,  0.11051001,\n",
       "         -0.12163546,  0.09477183, -0.12168957, -0.09488759,  0.09661108,\n",
       "          0.12156169,  0.12760012, -0.09287509, -0.11088078,  0.14327872,\n",
       "          0.1145133 , -0.09619763,  0.09689442,  0.09385432,  0.12525001,\n",
       "          0.10574875,  0.09873099,  0.09497759, -0.11035238, -0.09303454,\n",
       "          0.12295954, -0.12243055, -0.12541397,  0.12748022,  0.09774599,\n",
       "         -0.12213303,  0.09694438,  0.09608631,  0.09635255, -0.10911861,\n",
       "          0.09908074,  0.09432366, -0.12600142, -0.09972029, -0.12736513,\n",
       "         -0.11211174, -0.09514734,  0.11757316,  0.10018542, -0.10184382,\n",
       "         -0.10178859,  0.09816045, -0.1308878 , -0.09957751, -0.12599885,\n",
       "         -0.12994067, -0.0930857 ,  0.0954634 ,  0.12031533,  0.12296412,\n",
       "         -0.09304298,  0.11716642, -0.10327705, -0.13351755, -0.12576172,\n",
       "         -0.09778485,  0.1130378 ,  0.12515235,  0.0946253 , -0.08888732,\n",
       "          0.13284028,  0.11598621, -0.09612398, -0.09862149, -0.0982853 ,\n",
       "         -0.10014033,  0.09789253, -0.09670278,  0.09126233,  0.12469993,\n",
       "         -0.15661107,  0.1083665 , -0.09805214,  0.10745321, -0.09614501,\n",
       "         -0.1083281 ,  0.10105564,  0.0963931 , -0.16180405,  0.09738844,\n",
       "         -0.12404702,  0.09328256, -0.16514298,  0.09415328, -0.09432323,\n",
       "          0.09723281, -0.12799422, -0.09096902,  0.13229536, -0.11052245,\n",
       "          0.09667765, -0.12037994,  0.10032708, -0.11593886,  0.09917749,\n",
       "         -0.09225675, -0.09388541, -0.14716603, -0.09971527,  0.0916438 ,\n",
       "          0.09890755,  0.09747197,  0.09915451, -0.10045778, -0.12382446,\n",
       "         -0.12377475, -0.11824128, -0.09723979,  0.097005  , -0.11364949,\n",
       "         -0.09568013, -0.09642328,  0.08992667, -0.10917249, -0.11126029,\n",
       "         -0.09933977,  0.09924643, -0.09783559, -0.11439145, -0.11262877,\n",
       "          0.14036617,  0.12375462, -0.09724275,  0.09480543,  0.15616457,\n",
       "         -0.09328046,  0.09829656, -0.10160958, -0.09489747, -0.09886203,\n",
       "          0.10223646,  0.09433934, -0.11793679,  0.11709118,  0.10497491,\n",
       "         -0.09794281,  0.09964287, -0.09561935,  0.09728532,  0.13291009,\n",
       "         -0.11992565, -0.09627008,  0.09916302,  0.1002488 ,  0.09775931,\n",
       "         -0.09671386,  0.09936415,  0.12133887,  0.0934125 , -0.09608831,\n",
       "          0.09773172,  0.1274399 ,  0.12244686, -0.12104436, -0.09878192,\n",
       "          0.10890982,  0.0935517 , -0.09553151,  0.10010022,  0.09649426,\n",
       "          0.09624248, -0.08957305, -0.12201768, -0.09760268, -0.07038572,\n",
       "          0.0912165 ,  0.10187466,  0.0981763 ,  0.09910034,  0.09720149,\n",
       "         -0.10342839, -0.09560277, -0.09791899, -0.18800297,  0.09836881,\n",
       "         -0.09698343, -0.08763644, -0.09929045, -0.11313511,  0.08587165,\n",
       "         -0.11101194, -0.12209579,  0.09547919, -0.09600978, -0.09235878,\n",
       "         -0.09826187,  0.09500773,  0.0997613 ,  0.1070352 ,  0.10135145,\n",
       "         -0.10064498, -0.123394  , -0.09379527,  0.09180369,  0.09140099,\n",
       "          0.11559799,  0.09893335,  0.09528342,  0.09731776, -0.09769794,\n",
       "          0.09318442, -0.10523485,  0.09546892,  0.09479638, -0.09704197,\n",
       "         -0.09264503,  0.1095501 ,  0.1301942 ,  0.11389173,  0.09472876,\n",
       "         -0.09736084, -0.09747019,  0.10929353, -0.0990186 ,  0.09510524,\n",
       "         -0.09104326, -0.09646888, -0.12138402,  0.10693341, -0.08857139,\n",
       "         -0.0995316 ,  0.09742892,  0.09972417, -0.09662492,  0.14916362,\n",
       "          0.11451414, -0.09754356,  0.10391837,  0.09850677,  0.12448643,\n",
       "          0.09781878,  0.10033976,  0.09578694,  0.10092627, -0.09539241,\n",
       "          0.09980961, -0.12053497,  0.11823866, -0.10596152,  0.09905232,\n",
       "          0.10496774,  0.10488825,  0.09813692,  0.0960589 ,  0.09729555,\n",
       "         -0.13879882]], dtype=float32),\n",
       " '_value_branch._model.0.bias': array([-0.09462959], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs['pursuer_0'].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we restore an algo to its original size, and evaluate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_runners': {'episode_reward_max': np.float64(104.48447046235398),\n",
       "  'episode_reward_min': np.float64(-49.97758701259906),\n",
       "  'episode_reward_mean': np.float64(34.31495169008534),\n",
       "  'episode_len_mean': np.float64(500.0),\n",
       "  'episode_media': {},\n",
       "  'episodes_timesteps_total': 5000,\n",
       "  'policy_reward_min': {'pursuer_0': np.float64(-27.80399612520721),\n",
       "   'pursuer_1': np.float64(-74.73581968384396)},\n",
       "  'policy_reward_max': {'pursuer_0': np.float64(108.50397211584374),\n",
       "   'pursuer_1': np.float64(66.59594375510522)},\n",
       "  'policy_reward_mean': {'pursuer_0': np.float64(32.97170784631929),\n",
       "   'pursuer_1': np.float64(1.3432438437660394)},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [np.float64(44.487376281462424),\n",
       "    np.float64(98.65380257932057),\n",
       "    np.float64(84.50964155764572),\n",
       "    np.float64(20.08502968193733),\n",
       "    np.float64(104.48447046235398),\n",
       "    np.float64(-38.577462399422544),\n",
       "    np.float64(-49.97758701259906),\n",
       "    np.float64(20.465628189378837),\n",
       "    np.float64(91.2633147856224),\n",
       "    np.float64(-32.24469722484628)],\n",
       "   'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "   'policy_pursuer_0_reward': [np.float64(40.07564281289912),\n",
       "    np.float64(53.608308921809055),\n",
       "    np.float64(70.12441925264447),\n",
       "    np.float64(-27.80399612520721),\n",
       "    np.float64(37.88852670724881),\n",
       "    np.float64(-4.464299391091167),\n",
       "    np.float64(4.619717553032),\n",
       "    np.float64(4.673664157016454),\n",
       "    np.float64(108.50397211584374),\n",
       "    np.float64(42.49112245899767)],\n",
       "   'policy_pursuer_1_reward': [np.float64(4.411733468563258),\n",
       "    np.float64(45.04549365751143),\n",
       "    np.float64(14.38522230500113),\n",
       "    np.float64(47.889025807144655),\n",
       "    np.float64(66.59594375510522),\n",
       "    np.float64(-34.113163008331284),\n",
       "    np.float64(-54.59730456563125),\n",
       "    np.float64(15.79196403236251),\n",
       "    np.float64(-17.24065733022132),\n",
       "    np.float64(-74.73581968384396)]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.337330916680976),\n",
       "   'mean_inference_ms': np.float64(1.317882094427581),\n",
       "   'mean_action_processing_ms': np.float64(0.18205562599562794),\n",
       "   'mean_env_wait_ms': np.float64(1.6657234775866285),\n",
       "   'mean_env_render_ms': np.float64(0.0)},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0024259090423583984),\n",
       "   'StateBufferConnector_ms': np.float64(0.0023412704467773438),\n",
       "   'ViewRequirementAgentConnector_ms': np.float64(0.05772590637207031)},\n",
       "  'num_episodes': 10,\n",
       "  'episode_return_max': np.float64(104.48447046235398),\n",
       "  'episode_return_min': np.float64(-49.97758701259906),\n",
       "  'episode_return_mean': np.float64(34.31495169008534),\n",
       "  'episodes_this_iter': 10},\n",
       " 'num_agent_steps_sampled_this_iter': 10000,\n",
       " 'num_env_steps_sampled_this_iter': 5000,\n",
       " 'timesteps_this_iter': 5000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resto_algo.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets try with a different number of test agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Policy\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241m.\u001b[39mshutdown() \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Trained to about 0 combined return\u001b[39;00m\n\u001b[1;32m     10\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/root/ray_results/PPO_2024-08-28_20-57-45/PPO_2_agent_env_2cf59_00000_0_2024-08-28_20-57-45/checkpoint_000000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ray' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from os import path\n",
    "from ray.rllib.policy.policy import Policy\n",
    "import numpy as np\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "# Trained to about 0 combined return\n",
    "checkpoint_path = \"/root/ray_results/PPO_2024-08-28_20-57-45/PPO_2_agent_env_2cf59_00000_0_2024-08-28_20-57-45/checkpoint_000000\"\n",
    "pols = glob(checkpoint_path+\"/policies/*\")\n",
    "specs = {path.basename(p) : Policy.from_checkpoint(p) for p in pols}\n",
    "#specs = {path.basename(p) : SingleAgentRLModuleSpec(load_state_path=p) for p in pols} # Non-deterministic policy weight return (implies new)\n",
    "\n",
    "num_trained_agents = 2\n",
    "num_test_agents = 6\n",
    "\n",
    "register_env(f\"{num_test_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=num_test_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(num_test_agents)}\n",
    "\n",
    "\n",
    "resto_config = (\n",
    "    get_trainable_cls(\"PPO\")\n",
    "    .get_default_config()\n",
    "    .environment(f\"{num_test_agents}_agent_env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .rl_module(\n",
    "        #model_config_dict={\"vf_share_layers\": True},\n",
    "        rl_module_spec=MultiAgentRLModuleSpec(\n",
    "            #load_state_path=\n",
    "            #module_specs=specs,\n",
    "            module_specs={p: SingleAgentRLModuleSpec() for p in policies},\n",
    "        ),\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "resto_algo = resto_config.build()\n",
    "for test_id in range(num_test_agents):\n",
    "    train_id = np.random.randint(num_trained_agents)\n",
    "    resto_algo.get_policy(f\"pursuer_{test_id}\").set_weights(specs[f\"pursuer_{train_id}\"].get_weights())\n",
    "\n",
    "#resto_algo.get_policy(\"pursuer_0\").set_weights(specs[\"pursuer_0\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_1\").set_weights(specs[\"pursuer_1\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_0\").get_weights()\n",
    "\n",
    "resto_algo.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 17:55:20,672\tWARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'env_runners': {'episode_reward_max': np.float64(-364.769848341295),\n",
       "   'episode_reward_min': np.float64(-619.0375683355406),\n",
       "   'episode_reward_mean': np.float64(-493.78093420107905),\n",
       "   'episode_len_mean': np.float64(500.0),\n",
       "   'episode_media': {},\n",
       "   'episodes_timesteps_total': 5000,\n",
       "   'policy_reward_min': {'pursuer_0': np.float64(-113.90485384019159),\n",
       "    'pursuer_1': np.float64(-109.27251741852379),\n",
       "    'pursuer_2': np.float64(-114.55402342215696),\n",
       "    'pursuer_3': np.float64(-111.76090622319133),\n",
       "    'pursuer_4': np.float64(-109.0597747992956),\n",
       "    'pursuer_5': np.float64(-217.50166684483233)},\n",
       "   'policy_reward_max': {'pursuer_0': np.float64(11.303415129637894),\n",
       "    'pursuer_1': np.float64(0.2069972847033158),\n",
       "    'pursuer_2': np.float64(-46.84567547040106),\n",
       "    'pursuer_3': np.float64(-6.933874989835202),\n",
       "    'pursuer_4': np.float64(-7.903867561959164),\n",
       "    'pursuer_5': np.float64(-102.74657319368887)},\n",
       "   'policy_reward_mean': {'pursuer_0': np.float64(-62.68889913535977),\n",
       "    'pursuer_1': np.float64(-65.25422536988678),\n",
       "    'pursuer_2': np.float64(-74.27730941244923),\n",
       "    'pursuer_3': np.float64(-65.3008027191293),\n",
       "    'pursuer_4': np.float64(-63.75138013879174),\n",
       "    'pursuer_5': np.float64(-162.50831742546185)},\n",
       "   'custom_metrics': {},\n",
       "   'hist_stats': {'episode_reward': [np.float64(-512.3823702423662),\n",
       "     np.float64(-508.5460752882049),\n",
       "     np.float64(-613.3155297566499),\n",
       "     np.float64(-364.769848341295),\n",
       "     np.float64(-495.4410446420681),\n",
       "     np.float64(-619.0375683355406),\n",
       "     np.float64(-389.5228384962124),\n",
       "     np.float64(-382.61291184917025),\n",
       "     np.float64(-603.3023013627752),\n",
       "     np.float64(-448.8788536965084)],\n",
       "    'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "    'policy_pursuer_0_reward': [np.float64(-60.37390249750134),\n",
       "     np.float64(-60.741754372675686),\n",
       "     np.float64(-92.38409091020394),\n",
       "     np.float64(11.303415129637894),\n",
       "     np.float64(-89.95122930874328),\n",
       "     np.float64(-113.90485384019159),\n",
       "     np.float64(-33.69541775768187),\n",
       "     np.float64(-57.605645430906925),\n",
       "     np.float64(-82.23981599404104),\n",
       "     np.float64(-47.29569637128995)],\n",
       "    'policy_pursuer_1_reward': [np.float64(-69.16587427966073),\n",
       "     np.float64(-49.64229550423252),\n",
       "     np.float64(-96.41777564875132),\n",
       "     np.float64(-69.87433716798475),\n",
       "     np.float64(-109.27251741852379),\n",
       "     np.float64(-89.99336501878994),\n",
       "     np.float64(0.2069972847033158),\n",
       "     np.float64(-10.887723201806109),\n",
       "     np.float64(-93.20806475836568),\n",
       "     np.float64(-64.28729798545638)],\n",
       "    'policy_pursuer_2_reward': [np.float64(-89.8094922272591),\n",
       "     np.float64(-68.80568767053518),\n",
       "     np.float64(-114.55402342215696),\n",
       "     np.float64(-70.71135157105256),\n",
       "     np.float64(-75.0275389938279),\n",
       "     np.float64(-47.789534609511726),\n",
       "     np.float64(-46.88852374743173),\n",
       "     np.float64(-91.35057806874335),\n",
       "     np.float64(-46.84567547040106),\n",
       "     np.float64(-90.99068834357274)],\n",
       "    'policy_pursuer_3_reward': [np.float64(-111.32630440205934),\n",
       "     np.float64(-103.95080333396903),\n",
       "     np.float64(-84.83800127252131),\n",
       "     np.float64(-6.933874989835202),\n",
       "     np.float64(-8.589331807829799),\n",
       "     np.float64(-111.76090622319133),\n",
       "     np.float64(-30.30373001435348),\n",
       "     np.float64(-11.583014317344874),\n",
       "     np.float64(-110.78242937291465),\n",
       "     np.float64(-72.93963145727405)],\n",
       "    'policy_pursuer_4_reward': [np.float64(-66.7274235142958),\n",
       "     np.float64(-7.903867561959164),\n",
       "     np.float64(-54.9051831086639),\n",
       "     np.float64(-109.0597747992956),\n",
       "     np.float64(-52.28148786129459),\n",
       "     np.float64(-71.4751414424136),\n",
       "     np.float64(-67.6893324307532),\n",
       "     np.float64(-46.52229002548692),\n",
       "     np.float64(-90.3303342985284),\n",
       "     np.float64(-70.61896634522623)],\n",
       "    'policy_pursuer_5_reward': [np.float64(-114.97937332158938),\n",
       "     np.float64(-217.50166684483233),\n",
       "     np.float64(-170.21645539435244),\n",
       "     np.float64(-119.49392494276402),\n",
       "     np.float64(-160.31893925184878),\n",
       "     np.float64(-184.113767201442),\n",
       "     np.float64(-211.15283183069522),\n",
       "     np.float64(-164.66366080488214),\n",
       "     np.float64(-179.89598146852364),\n",
       "     np.float64(-102.74657319368887)]},\n",
       "   'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(1.2004366875553045),\n",
       "    'mean_inference_ms': np.float64(5.637246124172983),\n",
       "    'mean_action_processing_ms': np.float64(0.6170369138623248),\n",
       "    'mean_env_wait_ms': np.float64(6.577228381745566),\n",
       "    'mean_env_render_ms': np.float64(0.0)},\n",
       "   'num_faulty_episodes': 0,\n",
       "   'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0030291080474853516),\n",
       "    'StateBufferConnector_ms': np.float64(0.002672274907430013),\n",
       "    'ViewRequirementAgentConnector_ms': np.float64(0.0721895694732666)},\n",
       "   'num_episodes': 10,\n",
       "   'episode_return_max': np.float64(-364.769848341295),\n",
       "   'episode_return_min': np.float64(-619.0375683355406),\n",
       "   'episode_return_mean': np.float64(-493.78093420107905),\n",
       "   'episodes_this_iter': 10},\n",
       "  'num_agent_steps_sampled_this_iter': 30000,\n",
       "  'num_env_steps_sampled_this_iter': 5000,\n",
       "  'timesteps_this_iter': 5000,\n",
       "  'num_healthy_workers': 0,\n",
       "  'num_in_flight_async_reqs': 0,\n",
       "  'num_remote_worker_restarts': 0},\n",
       " 'custom_metrics': {},\n",
       " 'episode_media': {},\n",
       " 'info': {'learner': {'pursuer_1': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(8.284326),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.566026151676973),\n",
       "     'policy_loss': np.float64(0.09367009556881385),\n",
       "     'vf_loss': np.float64(6.283298968772093),\n",
       "     'vf_explained_var': np.float64(0.08557038928071657),\n",
       "     'kl': np.float64(0.9452853819413576),\n",
       "     'entropy': np.float64(3.36656474818786),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_2': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(9.113566),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.077735746900241),\n",
       "     'policy_loss': np.float64(0.0958497002410392),\n",
       "     'vf_loss': np.float64(5.798774990439415),\n",
       "     'vf_explained_var': np.float64(0.037562563084065914),\n",
       "     'kl': np.float64(0.9155552069811771),\n",
       "     'entropy': np.float64(3.340836751833558),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_4': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(5.2964835),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.91358299801747),\n",
       "     'policy_loss': np.float64(0.06978534823089527),\n",
       "     'vf_loss': np.float64(6.716566329697768),\n",
       "     'vf_explained_var': np.float64(-0.01836751662194729),\n",
       "     'kl': np.float64(0.6361566481510332),\n",
       "     'entropy': np.float64(3.28274431626002),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_3': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(10.332651),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.854018593331178),\n",
       "     'policy_loss': np.float64(0.09294957247087345),\n",
       "     'vf_loss': np.float64(6.589247601230939),\n",
       "     'vf_explained_var': np.float64(0.09223279201736052),\n",
       "     'kl': np.float64(0.8591070479790991),\n",
       "     'entropy': np.float64(3.249066265951842),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_0': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(13.473987),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(8.077613924443721),\n",
       "     'policy_loss': np.float64(0.2053523147891004),\n",
       "     'vf_loss': np.float64(7.52750322073698),\n",
       "     'vf_explained_var': np.float64(0.006246730933586756),\n",
       "     'kl': np.float64(1.723792077577673),\n",
       "     'entropy': np.float64(3.565287616228064),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_5': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(6.1548185),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(9.17444859991471),\n",
       "     'policy_loss': np.float64(0.06458147976275844),\n",
       "     'vf_loss': np.float64(8.96580339173476),\n",
       "     'vf_explained_var': np.float64(0.117337599893411),\n",
       "     'kl': np.float64(0.7203187775623519),\n",
       "     'entropy': np.float64(3.3291859274109203),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}},\n",
       "  'num_env_steps_sampled_for_evaluation_this_iter': 5000,\n",
       "  'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 24000,\n",
       "  'num_agent_steps_trained': 24000},\n",
       " 'env_runners': {'episode_reward_max': np.float64(-327.1718818863369),\n",
       "  'episode_reward_min': np.float64(-651.0568312071787),\n",
       "  'episode_reward_mean': np.float64(-521.166285331625),\n",
       "  'episode_len_mean': np.float64(500.0),\n",
       "  'episode_media': {},\n",
       "  'episodes_timesteps_total': 4000,\n",
       "  'policy_reward_min': {'pursuer_0': np.float64(-89.84811267121047),\n",
       "   'pursuer_1': np.float64(-112.50249861020443),\n",
       "   'pursuer_2': np.float64(-91.24802819055824),\n",
       "   'pursuer_3': np.float64(-107.97904688389782),\n",
       "   'pursuer_4': np.float64(-111.11837925890522),\n",
       "   'pursuer_5': np.float64(-212.1694086810163)},\n",
       "  'policy_reward_max': {'pursuer_0': np.float64(-7.318217051177981),\n",
       "   'pursuer_1': np.float64(-27.58393728642566),\n",
       "   'pursuer_2': np.float64(-48.906998868469366),\n",
       "   'pursuer_3': np.float64(-9.74873670808441),\n",
       "   'pursuer_4': np.float64(-8.12314018169635),\n",
       "   'pursuer_5': np.float64(-79.59940902683455)},\n",
       "  'policy_reward_mean': {'pursuer_0': np.float64(-49.37423269147564),\n",
       "   'pursuer_1': np.float64(-78.80312803094313),\n",
       "   'pursuer_2': np.float64(-79.74707460928532),\n",
       "   'pursuer_3': np.float64(-73.11886170322728),\n",
       "   'pursuer_4': np.float64(-69.70677086543017),\n",
       "   'pursuer_5': np.float64(-170.41621743126296)},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [np.float64(-327.1718818863369),\n",
       "    np.float64(-651.0568312071787),\n",
       "    np.float64(-620.2393821320601),\n",
       "    np.float64(-489.3921927436716),\n",
       "    np.float64(-410.1731976198102),\n",
       "    np.float64(-581.8466747940897),\n",
       "    np.float64(-575.4050666625217),\n",
       "    np.float64(-514.0450556073309)],\n",
       "   'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500],\n",
       "   'policy_pursuer_0_reward': [np.float64(-7.318217051177981),\n",
       "    np.float64(-89.84811267121047),\n",
       "    np.float64(-67.81082695742018),\n",
       "    np.float64(-71.91190472880133),\n",
       "    np.float64(-27.599276463261358),\n",
       "    np.float64(-31.960898365748204),\n",
       "    np.float64(-49.030113199761296),\n",
       "    np.float64(-49.51451209442428)],\n",
       "   'policy_pursuer_1_reward': [np.float64(-74.23225189379251),\n",
       "    np.float64(-68.39240528210188),\n",
       "    np.float64(-111.25103087508597),\n",
       "    np.float64(-111.30135546528297),\n",
       "    np.float64(-78.52141808791102),\n",
       "    np.float64(-46.64012674674057),\n",
       "    np.float64(-112.50249861020443),\n",
       "    np.float64(-27.58393728642566)],\n",
       "   'policy_pursuer_2_reward': [np.float64(-48.906998868469366),\n",
       "    np.float64(-91.24802819055824),\n",
       "    np.float64(-91.00219260111501),\n",
       "    np.float64(-88.84490928958596),\n",
       "    np.float64(-68.45956923680166),\n",
       "    np.float64(-89.8016870322555),\n",
       "    np.float64(-90.06113917726304),\n",
       "    np.float64(-69.65207247823379)],\n",
       "   'policy_pursuer_3_reward': [np.float64(-9.74873670808441),\n",
       "    np.float64(-107.97904688389782),\n",
       "    np.float64(-66.036674815765),\n",
       "    np.float64(-84.80410159987245),\n",
       "    np.float64(-68.74731589259862),\n",
       "    np.float64(-90.15617470942277),\n",
       "    np.float64(-88.53004439188066),\n",
       "    np.float64(-68.94879862429651)],\n",
       "   'policy_pursuer_4_reward': [np.float64(-8.12314018169635),\n",
       "    np.float64(-90.02686706189297),\n",
       "    np.float64(-111.09759313888274),\n",
       "    np.float64(-52.930512633294214),\n",
       "    np.float64(-9.520213959131988),\n",
       "    np.float64(-111.11837925890522),\n",
       "    np.float64(-68.83816491212305),\n",
       "    np.float64(-105.99929577751489)],\n",
       "   'policy_pursuer_5_reward': [np.float64(-178.84253718311618),\n",
       "    np.float64(-203.5623711175165),\n",
       "    np.float64(-173.04106374379046),\n",
       "    np.float64(-79.59940902683455),\n",
       "    np.float64(-157.3254039801049),\n",
       "    np.float64(-212.1694086810163),\n",
       "    np.float64(-166.44310637128856),\n",
       "    np.float64(-192.34643934643628)]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(1.3141188843139466),\n",
       "   'mean_inference_ms': np.float64(5.375802308425255),\n",
       "   'mean_action_processing_ms': np.float64(0.6453345740574232),\n",
       "   'mean_env_wait_ms': np.float64(6.361957551955223),\n",
       "   'mean_env_render_ms': np.float64(0.0)},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.005188087622324626),\n",
       "   'StateBufferConnector_ms': np.float64(0.002494951089223226),\n",
       "   'ViewRequirementAgentConnector_ms': np.float64(0.06810774405797322)},\n",
       "  'num_episodes': 8,\n",
       "  'episode_return_max': np.float64(-327.1718818863369),\n",
       "  'episode_return_min': np.float64(-651.0568312071787),\n",
       "  'episode_return_mean': np.float64(-521.166285331625),\n",
       "  'episodes_this_iter': 8},\n",
       " 'num_healthy_workers': 2,\n",
       " 'num_in_flight_async_sample_reqs': 0,\n",
       " 'num_remote_worker_restarts': 0,\n",
       " 'num_agent_steps_sampled': 24000,\n",
       " 'num_agent_steps_trained': 24000,\n",
       " 'num_env_steps_sampled': 4000,\n",
       " 'num_env_steps_trained': 4000,\n",
       " 'num_env_steps_sampled_this_iter': 4000,\n",
       " 'num_env_steps_trained_this_iter': 4000,\n",
       " 'num_env_steps_sampled_throughput_per_sec': 13.793587026868678,\n",
       " 'num_env_steps_trained_throughput_per_sec': 13.793587026868678,\n",
       " 'timesteps_total': 4000,\n",
       " 'num_env_steps_sampled_lifetime': 4000,\n",
       " 'num_agent_steps_sampled_lifetime': 24000,\n",
       " 'num_steps_trained_this_iter': 4000,\n",
       " 'agent_timesteps_total': 24000,\n",
       " 'timers': {'training_iteration_time_ms': 289989.883,\n",
       "  'restore_workers_time_ms': 0.089,\n",
       "  'training_step_time_ms': 289989.692,\n",
       "  'sample_time_ms': 28168.457,\n",
       "  'learn_time_ms': 261805.355,\n",
       "  'learn_throughput': 15.279,\n",
       "  'synch_weights_time_ms': 15.047,\n",
       "  'restore_eval_workers_time_ms': 0.015,\n",
       "  'evaluation_iteration_time_ms': 70558.346,\n",
       "  'evaluation_iteration_throughput': 70.863},\n",
       " 'counters': {'num_env_steps_sampled_for_evaluation_this_iter': 5000,\n",
       "  'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 24000,\n",
       "  'num_agent_steps_trained': 24000},\n",
       " 'done': False,\n",
       " 'training_iteration': 1,\n",
       " 'trial_id': 'default',\n",
       " 'date': '2024-09-03_18-00-53',\n",
       " 'timestamp': 1725386453,\n",
       " 'time_this_iter_s': 360.55868124961853,\n",
       " 'time_total_s': 360.55868124961853,\n",
       " 'pid': 1345171,\n",
       " 'hostname': 'e-bgbfbjbn-sfks6-0',\n",
       " 'node_ip': '10.42.142.216',\n",
       " 'config': {'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'placement_strategy': 'PACK',\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_for_main_process': 1,\n",
       "  'eager_tracing': True,\n",
       "  'eager_max_retraces': 20,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'torch_compile_learner': False,\n",
       "  'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
       "  'torch_compile_learner_dynamo_backend': 'inductor',\n",
       "  'torch_compile_learner_dynamo_mode': None,\n",
       "  'torch_compile_worker': False,\n",
       "  'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
       "  'torch_compile_worker_dynamo_mode': None,\n",
       "  'enable_rl_module_and_learner': False,\n",
       "  'enable_env_runner_and_connector_v2': False,\n",
       "  'env': '6_agent_env',\n",
       "  'env_config': {},\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  '_is_atari': None,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'action_mask_key': 'action_mask',\n",
       "  'env_runner_cls': None,\n",
       "  'num_env_runners': 2,\n",
       "  'num_envs_per_env_runner': 1,\n",
       "  'num_cpus_per_env_runner': 1,\n",
       "  'num_gpus_per_env_runner': 0,\n",
       "  'custom_resources_per_env_runner': {},\n",
       "  'validate_env_runners_after_construction': True,\n",
       "  'sample_timeout_s': 60.0,\n",
       "  '_env_to_module_connector': None,\n",
       "  'add_default_connectors_to_env_to_module_pipeline': True,\n",
       "  '_module_to_env_connector': None,\n",
       "  'add_default_connectors_to_module_to_env_pipeline': True,\n",
       "  'episode_lookback_horizon': 1,\n",
       "  'rollout_fragment_length': 'auto',\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'compress_observations': False,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'enable_tf1_exec_eagerly': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'update_worker_filter_stats': True,\n",
       "  'use_worker_filter_stats': True,\n",
       "  'enable_connectors': True,\n",
       "  'sampler_perf_stats_ema_coef': None,\n",
       "  'num_learners': 0,\n",
       "  'num_gpus_per_learner': 0,\n",
       "  'num_cpus_per_learner': 1,\n",
       "  'local_gpu_idx': 0,\n",
       "  'gamma': 0.99,\n",
       "  'lr': 5e-05,\n",
       "  'grad_clip': None,\n",
       "  'grad_clip_by': 'global_norm',\n",
       "  'train_batch_size': 4000,\n",
       "  'train_batch_size_per_learner': None,\n",
       "  'model': {'_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'fcnet_weights_initializer': None,\n",
       "   'fcnet_weights_initializer_config': None,\n",
       "   'fcnet_bias_initializer': None,\n",
       "   'fcnet_bias_initializer_config': None,\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'conv_kernel_initializer': None,\n",
       "   'conv_kernel_initializer_config': None,\n",
       "   'conv_bias_initializer': None,\n",
       "   'conv_bias_initializer_config': None,\n",
       "   'conv_transpose_kernel_initializer': None,\n",
       "   'conv_transpose_kernel_initializer_config': None,\n",
       "   'conv_transpose_bias_initializer': None,\n",
       "   'conv_transpose_bias_initializer_config': None,\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'post_fcnet_weights_initializer': None,\n",
       "   'post_fcnet_weights_initializer_config': None,\n",
       "   'post_fcnet_bias_initializer': None,\n",
       "   'post_fcnet_bias_initializer_config': None,\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   'lstm_weights_initializer': None,\n",
       "   'lstm_weights_initializer_config': None,\n",
       "   'lstm_bias_initializer': None,\n",
       "   'lstm_bias_initializer_config': None,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'encoder_latent_dim': None,\n",
       "   'always_check_shapes': False,\n",
       "   'lstm_use_prev_action_reward': -1,\n",
       "   '_use_default_native_models': -1},\n",
       "  '_learner_connector': None,\n",
       "  'add_default_connectors_to_learner_pipeline': True,\n",
       "  'learner_config_dict': {},\n",
       "  'optimizer': {},\n",
       "  'max_requests_in_flight_per_sampler_worker': 2,\n",
       "  '_learner_class': None,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'algorithm_config_overrides_per_module': {},\n",
       "  '_per_module_overrides': {},\n",
       "  'count_steps_by': 'env_steps',\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_mapping_fn': <function __main__.<lambda>(aid, *args, **kwargs)>,\n",
       "  'policies_to_train': None,\n",
       "  'policy_states_are_swappable': False,\n",
       "  'observation_fn': None,\n",
       "  'input_read_method': 'read_parquet',\n",
       "  'input_read_method_kwargs': {},\n",
       "  'input_read_schema': {},\n",
       "  'map_batches_kwargs': {},\n",
       "  'iter_batches_kwargs': {},\n",
       "  'prelearner_class': None,\n",
       "  'prelearner_module_synch_period': 10,\n",
       "  'dataset_num_iters_per_learner': None,\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_config': {},\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'offline_sampling': False,\n",
       "  'evaluation_interval': 1,\n",
       "  'evaluation_duration': 10,\n",
       "  'evaluation_duration_unit': 'episodes',\n",
       "  'evaluation_sample_timeout_s': 120.0,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'evaluation_force_reset_envs_before_iteration': True,\n",
       "  'evaluation_config': None,\n",
       "  'off_policy_estimation_methods': {},\n",
       "  'ope_split_batch_by_episode': True,\n",
       "  'evaluation_num_env_runners': 0,\n",
       "  'in_evaluation': False,\n",
       "  'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
       "  'keep_per_episode_custom_metrics': False,\n",
       "  'metrics_episode_collection_timeout_s': 60.0,\n",
       "  'metrics_num_episodes_for_smoothing': 100,\n",
       "  'min_time_s_per_iteration': None,\n",
       "  'min_train_timesteps_per_iteration': 0,\n",
       "  'min_sample_timesteps_per_iteration': 0,\n",
       "  'export_native_model_files': False,\n",
       "  'checkpoint_trainable_policies_only': False,\n",
       "  'logger_creator': None,\n",
       "  'logger_config': None,\n",
       "  'log_level': 'WARN',\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'seed': None,\n",
       "  '_run_training_always_in_thread': False,\n",
       "  '_evaluation_parallel_to_training_wo_thread': False,\n",
       "  'ignore_env_runner_failures': False,\n",
       "  'recreate_failed_env_runners': False,\n",
       "  'max_num_env_runner_restarts': 1000,\n",
       "  'delay_between_env_runner_restarts_s': 60.0,\n",
       "  'restart_failed_sub_environments': False,\n",
       "  'num_consecutive_env_runner_failures_tolerance': 100,\n",
       "  'env_runner_health_probe_timeout_s': 30,\n",
       "  'env_runner_restore_timeout_s': 1800,\n",
       "  '_model_config_dict': {},\n",
       "  '_rl_module_spec': MultiAgentRLModuleSpec(marl_module_class=<class 'ray.rllib.core.rl_module.marl_module.MultiAgentRLModule'>, inference_only=False, module_specs={'pursuer_1': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_2': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_4': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_3': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_0': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_5': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None),\n",
       "  '_AlgorithmConfig__prior_exploration_config': None,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  '_disable_initialize_loss_from_dummy_batch': False,\n",
       "  '_dont_auto_sync_env_runner_states': False,\n",
       "  'simple_optimizer': True,\n",
       "  'policy_map_cache': -1,\n",
       "  'worker_cls': -1,\n",
       "  'synchronize_filters': -1,\n",
       "  'enable_async_evaluation': -1,\n",
       "  'custom_async_evaluation_function': -1,\n",
       "  '_enable_rl_module_api': -1,\n",
       "  'auto_wrap_old_gym_envs': -1,\n",
       "  'disable_env_checking': -1,\n",
       "  'always_attach_evaluation_results': -1,\n",
       "  'replay_sequence_length': None,\n",
       "  '_disable_execution_plan_api': -1,\n",
       "  'lr_schedule': None,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'use_kl_loss': True,\n",
       "  'kl_coeff': 0.2,\n",
       "  'kl_target': 0.01,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'mini_batch_size_per_learner': None,\n",
       "  'num_sgd_iter': 30,\n",
       "  'shuffle_sequences': True,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'vf_share_layers': -1,\n",
       "  'lambda': 1.0,\n",
       "  'input': 'sampler',\n",
       "  'policies': {'pursuer_1': (None, None, None, None),\n",
       "   'pursuer_2': (None, None, None, None),\n",
       "   'pursuer_4': (None, None, None, None),\n",
       "   'pursuer_3': (None, None, None, None),\n",
       "   'pursuer_0': (None, None, None, None),\n",
       "   'pursuer_5': (None, None, None, None)},\n",
       "  'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       "  'create_env_on_driver': False,\n",
       "  'custom_eval_function': None,\n",
       "  'framework': 'torch'},\n",
       " 'time_since_restore': 360.55868124961853,\n",
       " 'iterations_since_restore': 1,\n",
       " 'perf': {'cpu_util_percent': np.float64(38.932853717026376),\n",
       "  'ram_util_percent': np.float64(9.687649880095922)}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resto_algo.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Callbacks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 02:04:18,759\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "/opt/conda/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:557: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-09-28 02:04:20,394\tWARNING services.py:2017 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67047424 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-09-28 02:04:21,522\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268 \u001b[39m\u001b[22m\n",
      "2024-09-28 02:04:27,830\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-09-28 02:04:27,834\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-09-28 02:50:27,373 E 196176 196176] (raylet) node_manager.cc:3064: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: e236b453d486271274e658140a30de7353a58d29b8000dc1df989521, IP: 10.42.142.216) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.42.142.216`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-28 02:51:30,075 E 196176 196176] (raylet) node_manager.cc:3064: 7 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: e236b453d486271274e658140a30de7353a58d29b8000dc1df989521, IP: 10.42.142.216) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.42.142.216`\n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-28 03:16:33,717 E 196176 196176] (raylet) node_manager.cc:3064: 5 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: e236b453d486271274e658140a30de7353a58d29b8000dc1df989521, IP: 10.42.142.216) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.42.142.216`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-28 03:17:40,295 E 196176 196176] (raylet) node_manager.cc:3064: 8 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: e236b453d486271274e658140a30de7353a58d29b8000dc1df989521, IP: 10.42.142.216) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.42.142.216`\n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-09-28 03:18:40,297 E 196176 196176] (raylet) node_manager.cc:3064: 5 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: e236b453d486271274e658140a30de7353a58d29b8000dc1df989521, IP: 10.42.142.216) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.42.142.216`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.evaluation import Episode, RolloutWorker\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyCallbacks(DefaultCallbacks):\n",
    "    def on_episode_start(self, *, episode: Episode, **kwargs) -> None:\n",
    "        episode.hist_data[\"mean_agent_return\"] = []\n",
    "\n",
    "    def on_episode_end(self, *, episode: Episode, **kwargs) -> None:\n",
    "        episode.hist_data[\"mean_agent_return\"].append(\n",
    "            episode.total_reward / len(policies) )\n",
    "        #episode.hist_data['mod_return'] = episode.hist_data['episode_reward']/2\n",
    "    \n",
    "    def on_train_result(self, *, algorithm, result: dict, **kwargs) -> None:\n",
    "        #n_agents = len(policies)        \n",
    "        n_agents = len(result['info']['learner'])\n",
    "        result[\"num_agents\"] = n_agents\n",
    "        #result[\"mod_return\"] = result['info']['hist_stats'][\"episode_reward\"]/2\n",
    "        result[\"mod_return\"] = np.divide(\n",
    "            result['env_runners']['hist_stats']['episode_reward'], n_agents)\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "\n",
    "num_agents = 2\n",
    "register_env(f\"{num_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=num_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(num_agents)}\n",
    "\n",
    "config = (\n",
    "    get_trainable_cls(\"PPO\")\n",
    "    .get_default_config()\n",
    "    .environment(f\"{num_agents}_agent_env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .rl_module(\n",
    "        rl_module_spec=MultiAgentRLModuleSpec(\n",
    "            module_specs={p: SingleAgentRLModuleSpec() for p in policies},\n",
    "        ),\n",
    "    )\n",
    "    #.evaluation(\n",
    "    #    evaluation_interval=1,\n",
    "    #)\n",
    "    .callbacks(MyCallbacks)\n",
    "    #.training(trained_agents=num_agents)\n",
    ")\n",
    "\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 02:05:00,769\tWARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "results = algo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-224.56955954147745),\n",
       " np.float64(-210.60704272678404),\n",
       " np.float64(-270.4674606087424),\n",
       " np.float64(-300.55186835564245),\n",
       " np.float64(-269.2034552824137),\n",
       " np.float64(-225.00378578885667),\n",
       " np.float64(-221.94251529451898),\n",
       " np.float64(-224.5826295071694),\n",
       " np.float64(-225.01705161938244),\n",
       " np.float64(-289.68626249930134),\n",
       " np.float64(-244.16540430415856),\n",
       " np.float64(-266.06146701715795),\n",
       " np.float64(-177.1772171119893),\n",
       " np.float64(-185.088584697531),\n",
       " np.float64(-243.36592972517653),\n",
       " np.float64(-225.87668550926975)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['env_runners']['hist_stats']['episode_reward']\n",
    "np.divide(results['env_runners']['hist_stats']['episode_reward'],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['info']['learner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Script Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async Running\n",
    "`apt-get install tmux`\n",
    "`tmux new-session -d 'python run_this.py'`\n",
    "\n",
    "Other possible useful commands?\n",
    "   `tmux ls`\n",
    "   `tmux kill-session -t <session-number>`\n",
    "   `tmux attach-session -t <session-number>`\n",
    "\n",
    "\n",
    "tmux new-session -d 'python test.py --num-agents=2 --stop-iters=10'\n",
    "\n",
    "tmux new-session -d 'python test.py --wandb-project=mini_test_ww2 --wandb-key=913528a8e92bf601b6eb055a459bcc89130c7f5f --num-env-runners=30 --checkpoint-at-end --num-agents=2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plateau Stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "\n",
    "TrialPlateauStopper(metric=\"episode_return_mean\")\n",
    "\n",
    "run_rllib_example_script_experiment(base_config, args, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python test.py --wandb-project=mini_test_ww2 --wandb-key=913528a8e92bf601b6eb055a459bcc89130c7f5f \\\n",
    "--num-env-runners=30 --checkpoint-at-end --num-agents=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organized Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "2024-09-28 14:41:08,361\tWARNING services.py:2017 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67047424 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=8.58gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-09-28 14:41:09,569\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8269 \u001b[39m\u001b[22m\n",
      "2024-09-28 14:41:10,601\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-09-28 14:41:10,603\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-09-28 14:41:10,611\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-09-28 14:41:10,612\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:10 (running for 00:00:00.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 PENDING)\n",
      "+------------------------------------+----------+-------+\n",
      "| Trial name                         | status   | loc   |\n",
      "|------------------------------------+----------+-------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | PENDING  |       |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | PENDING  |       |\n",
      "+------------------------------------+----------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=408432)\u001b[0m 2024-09-28 14:41:15,109\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:15 (running for 00:00:05.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 PENDING)\n",
      "+------------------------------------+----------+-------+\n",
      "| Trial name                         | status   | loc   |\n",
      "|------------------------------------+----------+-------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | PENDING  |       |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | PENDING  |       |\n",
      "+------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:20 (running for 00:00:10.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 PENDING)\n",
      "+------------------------------------+----------+-------+\n",
      "| Trial name                         | status   | loc   |\n",
      "|------------------------------------+----------+-------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | PENDING  |       |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | PENDING  |       |\n",
      "+------------------------------------+----------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=408432)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(PPO pid=408432)\u001b[0m 2024-09-28 14:41:21,595\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:25 (running for 00:00:15.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+\n",
      "| Trial name                         | status   | loc                  |\n",
      "|------------------------------------+----------+----------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |\n",
      "+------------------------------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=408432)\u001b[0m 2024-09-28 14:41:29,869\tWARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=408431)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(PPO pid=408431)\u001b[0m 2024-09-28 14:41:22,110\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:30 (running for 00:00:20.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+\n",
      "| Trial name                         | status   | loc                  |\n",
      "|------------------------------------+----------+----------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |\n",
      "+------------------------------------+----------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:36 (running for 00:00:25.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+\n",
      "| Trial name                         | status   | loc                  |\n",
      "|------------------------------------+----------+----------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |\n",
      "+------------------------------------+----------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:41 (running for 00:00:30.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+\n",
      "| Trial name                         | status   | loc                  |\n",
      "|------------------------------------+----------+----------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |\n",
      "+------------------------------------+----------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:46 (running for 00:00:35.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+\n",
      "| Trial name                         | status   | loc                  |\n",
      "|------------------------------------+----------+----------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |\n",
      "+------------------------------------+----------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                            </th><th>custom_metrics  </th><th>env_runners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </th><th>episode_media  </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_sample_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                                                   </th><th>timers                                                                                                                                                                                                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_2_agent_waterworld_b4113_00000</td><td style=\"text-align: right;\">                  80000</td><td>{&#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 80000, &#x27;num_agent_steps_trained&#x27;: 80000}</td><td>{}              </td><td>{&#x27;episode_reward_max&#x27;: np.float64(-109.91431194146944), &#x27;episode_reward_min&#x27;: np.float64(-298.7184147633438), &#x27;episode_reward_mean&#x27;: np.float64(-228.94587691636798), &#x27;episode_len_mean&#x27;: np.float64(500.0), &#x27;episode_media&#x27;: {}, &#x27;episodes_timesteps_total&#x27;: 40000, &#x27;policy_reward_min&#x27;: {&#x27;pursuer_0&#x27;: np.float64(-113.8010956018662), &#x27;pursuer_1&#x27;: np.float64(-220.75756586131507)}, &#x27;policy_reward_max&#x27;: {&#x27;pursuer_0&#x27;: np.float64(37.806550781453886), &#x27;pursuer_1&#x27;: np.float64(-51.75556256831941)}, &#x27;policy_reward_mean&#x27;: {&#x27;pursuer_0&#x27;: np.float64(-65.86400982364955), &#x27;pursuer_1&#x27;: np.float64(-163.08186709271837)}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [np.float64(-288.19604400750137), np.float64(-263.7468038366759), np.float64(-244.30111123903578), np.float64(-283.9948898961454), np.float64(-266.52424942426353), np.float64(-283.24287880404324), np.float64(-284.17441424624997), np.float64(-248.62746680865448), np.float64(-257.9417130533655), np.float64(-220.42647413159722), np.float64(-279.10487828195244), np.float64(-225.83226865969763), np.float64(-267.5815759207497), np.float64(-271.49241709495544), np.float64(-178.22703088448463), np.float64(-229.84590911390137), np.float64(-283.29252735448046), np.float64(-221.4788464036972), np.float64(-242.04756682274078), np.float64(-209.87059251260922), np.float64(-263.5882247304495), np.float64(-279.5352918810063), np.float64(-207.44858996916977), np.float64(-285.56029219438506), np.float64(-273.78530598321595), np.float64(-216.366507748988), np.float64(-157.21812407740353), np.float64(-279.2009393513053), np.float64(-224.1327013249195), np.float64(-258.9438470860721), np.float64(-214.21352376888956), np.float64(-176.96741257154406), np.float64(-216.26404294800517), np.float64(-279.6278106961485), np.float64(-208.9982970535929), np.float64(-298.7184147633438), np.float64(-287.40283754424377), np.float64(-253.73638213813956), np.float64(-176.14185961165376), np.float64(-270.23272851396246), np.float64(-231.5977383001091), np.float64(-228.2317140956118), np.float64(-142.97772652541653), np.float64(-224.06504969032426), np.float64(-216.31520108962522), np.float64(-161.94456375292484), np.float64(-163.2006765974115), np.float64(-228.09950280356236), np.float64(-206.44540298297636), np.float64(-248.0693002335791), np.float64(-238.0591045290493), np.float64(-224.96247305625587), np.float64(-226.36519768391653), np.float64(-163.07998073919688), np.float64(-242.084650185815), np.float64(-214.34671619042751), np.float64(-246.7996298110595), np.float64(-109.91431194146944), np.float64(-297.73409381647144), np.float64(-171.42468026493637), np.float64(-283.58250590538063), np.float64(-290.4526932581631), np.float64(-261.38643421717035), np.float64(-227.41501198040567), np.float64(-242.515063822877), np.float64(-161.37458440122356), np.float64(-158.41690014386194), np.float64(-146.23992380707847), np.float64(-249.44759438357062), np.float64(-236.96364034289675), np.float64(-198.42201909025943), np.float64(-159.28626787164157), np.float64(-203.1828814992124), np.float64(-200.89287378134142), np.float64(-242.6789717237335), np.float64(-227.3448139903929), np.float64(-126.00548816260753), np.float64(-198.78253444865277), np.float64(-216.27547814287493), np.float64(-221.25396559271206)], &#x27;episode_lengths&#x27;: [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], &#x27;policy_pursuer_0_reward&#x27;: [np.float64(-67.43847814618631), np.float64(-87.01379060574175), np.float64(-49.678346047075436), np.float64(-88.41905269889577), np.float64(-70.43092731998523), np.float64(-67.89562608166656), np.float64(-111.52255883910973), np.float64(-91.86081243678316), np.float64(-68.27276719717983), np.float64(-89.20450022380615), np.float64(-108.9048830176642), np.float64(-29.810811391292283), np.float64(-69.14586756039105), np.float64(-74.15235687394541), np.float64(-50.76983075748302), np.float64(-89.22796895587922), np.float64(-90.41257166313841), np.float64(-111.47712615942426), np.float64(-43.93062332799966), np.float64(-48.90796985908147), np.float64(-85.61332762702827), np.float64(-85.56041558013236), np.float64(-72.5702600039611), np.float64(-90.98792754691185), np.float64(-104.60089364497696), np.float64(-103.6947405911414), np.float64(-46.25422893490652), np.float64(-109.06477154876286), np.float64(-30.06257926610819), np.float64(-87.0399728363215), np.float64(-85.19555027496872), np.float64(-3.3234484530167534), np.float64(-45.61793227588634), np.float64(-68.01766143446345), np.float64(-63.35798382196723), np.float64(-86.14136708394201), np.float64(-85.58663815074983), np.float64(-45.79046148286436), np.float64(-88.26425804432336), np.float64(-68.85190050516039), np.float64(-42.15027200468986), np.float64(-113.8010956018662), np.float64(-41.44781130619788), np.float64(-60.467221914845084), np.float64(-104.59458265433146), np.float64(-48.49453590206116), np.float64(-24.51670045124924), np.float64(-39.85201313087268), np.float64(-64.48492465649565), np.float64(-63.72223624722697), np.float64(-80.56958856923775), np.float64(-82.39071543464719), np.float64(-22.679745411820523), np.float64(-43.133812170536764), np.float64(-80.84140494752786), np.float64(-84.87055463893823), np.float64(-61.64944773527349), np.float64(-58.15874937315008), np.float64(-104.74780377368405), np.float64(18.288976596539484), np.float64(-78.70178752804192), np.float64(-104.21177021215824), np.float64(-59.047468954171634), np.float64(-59.68425366231564), np.float64(-82.88091340582244), np.float64(-89.39760087770851), np.float64(-35.913954005344806), np.float64(37.806550781453886), np.float64(-80.96395793394198), np.float64(-38.2855542208746), np.float64(-15.937873661372281), np.float64(-18.93716190318739), np.float64(-102.14447938795182), np.float64(-41.83242019973604), np.float64(-95.49982253451242), np.float64(-39.18781142321924), np.float64(21.621880822003956), np.float64(-80.31830692637276), np.float64(-53.7684032592031), np.float64(-83.47824980105196)], &#x27;policy_pursuer_1_reward&#x27;: [np.float64(-220.75756586131507), np.float64(-176.73301323093426), np.float64(-194.6227651919605), np.float64(-195.57583719724977), np.float64(-196.09332210427843), np.float64(-215.34725272237662), np.float64(-172.65185540714018), np.float64(-156.76665437187114), np.float64(-189.66894585618525), np.float64(-131.2219739077913), np.float64(-170.19999526428822), np.float64(-196.02145726840556), np.float64(-198.4357083603586), np.float64(-197.34006022101002), np.float64(-127.45720012700166), np.float64(-140.6179401580221), np.float64(-192.87995569134222), np.float64(-110.00172024427266), np.float64(-198.11694349474112), np.float64(-160.96262265352794), np.float64(-177.97489710342134), np.float64(-193.97487630087383), np.float64(-134.87832996520848), np.float64(-194.572364647473), np.float64(-169.1844123382389), np.float64(-112.67176715784672), np.float64(-110.96389514249705), np.float64(-170.1361678025425), np.float64(-194.0701220588113), np.float64(-171.90387424975077), np.float64(-129.0179734939207), np.float64(-173.64396411852744), np.float64(-170.6461106721188), np.float64(-211.61014926168505), np.float64(-145.6403132316256), np.float64(-212.5770476794018), np.float64(-201.8161993934941), np.float64(-207.94592065527533), np.float64(-87.87760156733042), np.float64(-201.3808280088021), np.float64(-189.44746629541905), np.float64(-114.43061849374548), np.float64(-101.5299152192185), np.float64(-163.5978277754791), np.float64(-111.72061843529373), np.float64(-113.45002785086385), np.float64(-138.6839761461619), np.float64(-188.24748967268977), np.float64(-141.96047832648074), np.float64(-184.34706398635208), np.float64(-157.48951595981134), np.float64(-142.57175762160884), np.float64(-203.68545227209603), np.float64(-119.94616856866006), np.float64(-161.24324523828696), np.float64(-129.47616155148904), np.float64(-185.15018207578598), np.float64(-51.75556256831941), np.float64(-192.98629004278743), np.float64(-189.7136568614758), np.float64(-204.88071837733895), np.float64(-186.2409230460048), np.float64(-202.33896526299867), np.float64(-167.73075831809012), np.float64(-159.63415041705446), np.float64(-71.9769835235151), np.float64(-122.50294613851715), np.float64(-184.04647458853208), np.float64(-168.48363644962856), np.float64(-198.67808612202208), np.float64(-182.48414542888705), np.float64(-140.34910596845415), np.float64(-101.03840211126058), np.float64(-159.06045358160554), np.float64(-147.17914918922116), np.float64(-188.15700256717338), np.float64(-147.62736898461145), np.float64(-118.46422752228023), np.float64(-162.5070748836717), np.float64(-137.7757157916601)]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: np.float64(0.45197264253195446), &#x27;mean_inference_ms&#x27;: np.float64(1.6312213667720208), &#x27;mean_action_processing_ms&#x27;: np.float64(0.21701613847897255), &#x27;mean_env_wait_ms&#x27;: np.float64(1.8669775382498046), &#x27;mean_env_render_ms&#x27;: np.float64(0.0)}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: np.float64(0.0037285685539245605), &#x27;StateBufferConnector_ms&#x27;: np.float64(0.0026425719261169434), &#x27;ViewRequirementAgentConnector_ms&#x27;: np.float64(0.06747499108314514)}, &#x27;num_episodes&#x27;: 8, &#x27;episode_return_max&#x27;: np.float64(-109.91431194146944), &#x27;episode_return_min&#x27;: np.float64(-298.7184147633438), &#x27;episode_return_mean&#x27;: np.float64(-228.94587691636798), &#x27;episodes_this_iter&#x27;: 8}</td><td>{}             </td><td>{&#x27;learner&#x27;: {&#x27;pursuer_0&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: np.float64(0.0), &#x27;grad_gnorm&#x27;: np.float32(3.6451383), &#x27;cur_kl_coeff&#x27;: np.float64(0.10000000000000002), &#x27;cur_lr&#x27;: np.float64(5.0000000000000016e-05), &#x27;total_loss&#x27;: np.float64(4.388929148266713), &#x27;policy_loss&#x27;: np.float64(-0.021291275953505343), &#x27;vf_loss&#x27;: np.float64(4.408763808508714), &#x27;vf_explained_var&#x27;: np.float64(0.02267032687862714), &#x27;kl&#x27;: np.float64(0.014566012486125185), &#x27;entropy&#x27;: np.float64(2.242644399901231), &#x27;entropy_coeff&#x27;: np.float64(0.0)}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: np.float64(125.0), &#x27;num_grad_updates_lifetime&#x27;: np.float64(9120.5), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float64(479.5)}, &#x27;pursuer_1&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: np.float64(0.0), &#x27;grad_gnorm&#x27;: np.float32(2.6652873), &#x27;cur_kl_coeff&#x27;: np.float64(0.10000000000000002), &#x27;cur_lr&#x27;: np.float64(5.0000000000000016e-05), &#x27;total_loss&#x27;: np.float64(6.674920690556367), &#x27;policy_loss&#x27;: np.float64(-0.014248947574136158), &#x27;vf_loss&#x27;: np.float64(6.688073832293352), &#x27;vf_explained_var&#x27;: np.float64(6.457169850667318e-09), &#x27;kl&#x27;: np.float64(0.010958172467432343), &#x27;entropy&#x27;: np.float64(2.3664672071735064), &#x27;entropy_coeff&#x27;: np.float64(0.0)}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: np.float64(125.0), &#x27;num_grad_updates_lifetime&#x27;: np.float64(9120.5), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float64(479.5)}}, &#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 80000, &#x27;num_agent_steps_trained&#x27;: 80000} </td><td style=\"text-align: right;\">                    80000</td><td style=\"text-align: right;\">                             80000</td><td style=\"text-align: right;\">                    80000</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                           40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   150.758</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   150.758</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(32.27631578947369), &#x27;ram_util_percent&#x27;: np.float64(17.650000000000006)}</td><td>{&#x27;training_iteration_time_ms&#x27;: 27057.386, &#x27;restore_workers_time_ms&#x27;: 0.045, &#x27;training_step_time_ms&#x27;: 27057.24, &#x27;sample_time_ms&#x27;: 8556.097, &#x27;learn_time_ms&#x27;: 18479.763, &#x27;learn_throughput&#x27;: 216.453, &#x27;synch_weights_time_ms&#x27;: 19.452} </td></tr>\n",
       "<tr><td>PPO_2_agent_waterworld_b4113_00001</td><td style=\"text-align: right;\">                  80000</td><td>{&#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 80000, &#x27;num_agent_steps_trained&#x27;: 80000}</td><td>{}              </td><td>{&#x27;episode_reward_max&#x27;: np.float64(-88.59814663137603), &#x27;episode_reward_min&#x27;: np.float64(-327.5372595245201), &#x27;episode_reward_mean&#x27;: np.float64(-213.68207949729018), &#x27;episode_len_mean&#x27;: np.float64(500.0), &#x27;episode_media&#x27;: {}, &#x27;episodes_timesteps_total&#x27;: 40000, &#x27;policy_reward_min&#x27;: {&#x27;pursuer_0&#x27;: np.float64(-112.15139658689594), &#x27;pursuer_1&#x27;: np.float64(-219.46226524053978)}, &#x27;policy_reward_max&#x27;: {&#x27;pursuer_0&#x27;: np.float64(63.218716075993676), &#x27;pursuer_1&#x27;: np.float64(-80.10107204170268)}, &#x27;policy_reward_mean&#x27;: {&#x27;pursuer_0&#x27;: np.float64(-51.49456132324792), &#x27;pursuer_1&#x27;: np.float64(-162.18751817404222)}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [np.float64(-163.55706401094625), np.float64(-223.6296668324708), np.float64(-287.36318449284613), np.float64(-211.81659079575184), np.float64(-285.894972558428), np.float64(-249.15760113814466), np.float64(-308.4128001162764), np.float64(-205.03461011949804), np.float64(-290.899096788498), np.float64(-206.88563948073354), np.float64(-236.9071112586494), np.float64(-275.24847084220227), np.float64(-223.40165228904863), np.float64(-263.92671544773845), np.float64(-284.6287054277883), np.float64(-222.35383193727307), np.float64(-273.30191343731315), np.float64(-224.00144059772592), np.float64(-286.32985161231875), np.float64(-288.15026051732497), np.float64(-187.23595171170717), np.float64(-182.21618793750613), np.float64(-172.75706634983155), np.float64(-327.5372595245201), np.float64(-216.99751529452527), np.float64(-203.0578745001306), np.float64(-242.56806582483105), np.float64(-271.93423679740044), np.float64(-167.4629692554303), np.float64(-232.29777653870968), np.float64(-251.42691688604205), np.float64(-250.68566398330418), np.float64(-88.59814663137603), np.float64(-184.78393681933966), np.float64(-243.35676513349273), np.float64(-205.94192745887207), np.float64(-222.9108424954063), np.float64(-209.24988208903304), np.float64(-243.77355991027557), np.float64(-267.8926025452551), np.float64(-264.13252962005424), np.float64(-281.04963965162347), np.float64(-176.69844913873857), np.float64(-235.471756455781), np.float64(-154.44258133509484), np.float64(-159.169025319122), np.float64(-200.28342012072946), np.float64(-193.5007591495159), np.float64(-125.91157633181624), np.float64(-175.70513694661022), np.float64(-172.95351502538222), np.float64(-218.5764213963486), np.float64(-233.93520573111522), np.float64(-248.6981881099773), np.float64(-107.57900771093867), np.float64(-300.5009437742603), np.float64(-280.71760473985944), np.float64(-213.5208644380312), np.float64(-186.8181678287598), np.float64(-156.1422581915858), np.float64(-213.26766932172936), np.float64(-189.0545426572954), np.float64(-232.78629935588734), np.float64(-127.06078950855938), np.float64(-194.66035168603764), np.float64(-178.92020447096928), np.float64(-200.12535759875666), np.float64(-251.83915662855932), np.float64(-146.4520350378026), np.float64(-196.73276021213732), np.float64(-210.6694797214984), np.float64(-250.56222266877882), np.float64(-235.71191707505795), np.float64(-119.17821681513107), np.float64(-125.33162714514444), np.float64(-98.31586478338365), np.float64(-128.95455177924978), np.float64(-126.7681736353628), np.float64(-203.5129793994155), np.float64(-195.26878187914716)], &#x27;episode_lengths&#x27;: [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], &#x27;policy_pursuer_0_reward&#x27;: [np.float64(-27.273564969250696), np.float64(-50.23968375421234), np.float64(-107.75383069514464), np.float64(-72.25874997795505), np.float64(-91.07873816366528), np.float64(-73.8921093942477), np.float64(-90.19461047490454), np.float64(-69.70578231325185), np.float64(-110.88641093689522), np.float64(-49.51019167973318), np.float64(-49.920194181303884), np.float64(-112.15139658689594), np.float64(-65.67300514498757), np.float64(-70.09154985299807), np.float64(-90.26071524998164), np.float64(-11.282684387809729), np.float64(-86.87711007226166), np.float64(-30.161819407448014), np.float64(-94.18938379728824), np.float64(-93.24607736810731), np.float64(-50.04201679870226), np.float64(-24.66412153729765), np.float64(-17.485925708222766), np.float64(-108.07499428398033), np.float64(-62.632012252245595), np.float64(-60.464054667652746), np.float64(-87.00916716695406), np.float64(-88.24966117602558), np.float64(-12.216348549195025), np.float64(-66.11210489008579), np.float64(-90.89115711355274), np.float64(-107.05621377207851), np.float64(63.218716075993676), np.float64(-7.745235544675222), np.float64(-67.15664709770904), np.float64(-48.35236845029673), np.float64(-71.53745243329715), np.float64(-48.602052415963975), np.float64(-70.77962010336944), np.float64(-92.40845394706008), np.float64(-67.47778342627657), np.float64(-68.5809296342887), np.float64(-48.84348484149235), np.float64(-45.18551425597062), np.float64(-38.404000660142145), np.float64(-66.83484285236788), np.float64(-28.056994458685473), np.float64(-71.39307962476043), np.float64(0.37888781618597067), np.float64(-41.49658761338609), np.float64(-3.546459385687965), np.float64(-81.13759232175138), np.float64(-22.11577722680005), np.float64(-65.14667115364016), np.float64(-2.533881636298743), np.float64(-86.57235302255701), np.float64(-109.8629505252991), np.float64(-66.12725783972853), np.float64(-60.87195873463635), np.float64(-21.467276956695773), np.float64(-60.95777612480822), np.float64(-2.0427358416525423), np.float64(-19.63119916043664), np.float64(-1.7670508193898637), np.float64(-12.534273190602246), np.float64(-81.26003956174611), np.float64(-83.73256619010671), np.float64(-62.017569872384925), np.float64(-16.664456897663353), np.float64(-8.807607385252595), np.float64(-23.421182150321478), np.float64(-87.45896312967005), np.float64(-66.999924392644), np.float64(-26.463238036138193), np.float64(-17.326918695409713), np.float64(-18.21479274168097), np.float64(44.759198888701135), np.float64(19.567397002252914), np.float64(-9.050297925821585), np.float64(-25.35590104006608)], &#x27;policy_pursuer_1_reward&#x27;: [np.float64(-136.28349904169545), np.float64(-173.38998307825844), np.float64(-179.60935379770137), np.float64(-139.55784081779672), np.float64(-194.8162343947623), np.float64(-175.26549174389694), np.float64(-218.21818964137185), np.float64(-135.3288278062462), np.float64(-180.0126858516028), np.float64(-157.37544780100038), np.float64(-186.98691707734542), np.float64(-163.09707425530604), np.float64(-157.72864714406091), np.float64(-193.83516559474043), np.float64(-194.36799017780672), np.float64(-211.07114754946318), np.float64(-186.42480336505142), np.float64(-193.8396211902778), np.float64(-192.14046781503052), np.float64(-194.9041831492174), np.float64(-137.1939349130047), np.float64(-157.5520664002084), np.float64(-155.2711406416091), np.float64(-219.46226524053978), np.float64(-154.3655030422797), np.float64(-142.5938198324778), np.float64(-155.55889865787702), np.float64(-183.6845756213749), np.float64(-155.2466207062352), np.float64(-166.18567164862378), np.float64(-160.5357597724894), np.float64(-143.62945021122576), np.float64(-151.81686270736978), np.float64(-177.03870127466425), np.float64(-176.20011803578348), np.float64(-157.58955900857543), np.float64(-151.37339006210908), np.float64(-160.6478296730689), np.float64(-172.99393980690562), np.float64(-175.4841485981951), np.float64(-196.65474619377753), np.float64(-212.46871001733479), np.float64(-127.8549642972461), np.float64(-190.28624219981054), np.float64(-116.03858067495273), np.float64(-92.33418246675419), np.float64(-172.2264256620441), np.float64(-122.10767952475533), np.float64(-126.29046414800227), np.float64(-134.20854933322406), np.float64(-169.40705563969408), np.float64(-137.4388290745972), np.float64(-211.81942850431523), np.float64(-183.55151695633708), np.float64(-105.04512607463985), np.float64(-213.92859075170304), np.float64(-170.85465421456024), np.float64(-147.3936065983026), np.float64(-125.94620909412353), np.float64(-134.67498123489005), np.float64(-152.3098931969213), np.float64(-187.01180681564293), np.float64(-213.15510019545056), np.float64(-125.29373868916947), np.float64(-182.1260784954353), np.float64(-97.66016490922273), np.float64(-116.39279140864988), np.float64(-189.82158675617413), np.float64(-129.7875781401393), np.float64(-187.92515282688476), np.float64(-187.2482975711769), np.float64(-163.1032595391086), np.float64(-168.71199268241404), np.float64(-92.71497877899301), np.float64(-108.00470844973479), np.float64(-80.10107204170268), np.float64(-173.71375066795068), np.float64(-146.33557063761566), np.float64(-194.46268147359382), np.float64(-169.91288083908114)]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: np.float64(0.4311195631143619), &#x27;mean_inference_ms&#x27;: np.float64(1.5308585708678597), &#x27;mean_action_processing_ms&#x27;: np.float64(0.2080200872965438), &#x27;mean_env_wait_ms&#x27;: np.float64(1.793121419794589), &#x27;mean_env_render_ms&#x27;: np.float64(0.0)}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: np.float64(0.003678947687149048), &#x27;StateBufferConnector_ms&#x27;: np.float64(0.0027632713317871094), &#x27;ViewRequirementAgentConnector_ms&#x27;: np.float64(0.06836071610450745)}, &#x27;num_episodes&#x27;: 8, &#x27;episode_return_max&#x27;: np.float64(-88.59814663137603), &#x27;episode_return_min&#x27;: np.float64(-327.5372595245201), &#x27;episode_return_mean&#x27;: np.float64(-213.68207949729018), &#x27;episodes_this_iter&#x27;: 8}</td><td>{}             </td><td>{&#x27;learner&#x27;: {&#x27;pursuer_0&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: np.float64(0.0), &#x27;grad_gnorm&#x27;: np.float32(3.126109), &#x27;cur_kl_coeff&#x27;: np.float64(0.10000000000000002), &#x27;cur_lr&#x27;: np.float64(5.0000000000000016e-05), &#x27;total_loss&#x27;: np.float64(8.143767655392487), &#x27;policy_loss&#x27;: np.float64(-0.017855608288664372), &#x27;vf_loss&#x27;: np.float64(8.160278207063675), &#x27;vf_explained_var&#x27;: np.float64(-0.005060878830651442), &#x27;kl&#x27;: np.float64(0.013450785714182227), &#x27;entropy&#x27;: np.float64(2.1470594136665264), &#x27;entropy_coeff&#x27;: np.float64(0.0)}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: np.float64(125.0), &#x27;num_grad_updates_lifetime&#x27;: np.float64(9120.5), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float64(479.5)}, &#x27;pursuer_1&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: np.float64(0.0), &#x27;grad_gnorm&#x27;: np.float32(2.4878275), &#x27;cur_kl_coeff&#x27;: np.float64(0.20000000000000004), &#x27;cur_lr&#x27;: np.float64(5.0000000000000016e-05), &#x27;total_loss&#x27;: np.float64(6.591445065041383), &#x27;policy_loss&#x27;: np.float64(-0.01917047797420916), &#x27;vf_loss&#x27;: np.float64(6.608088782429695), &#x27;vf_explained_var&#x27;: np.float64(4.805624485015869e-08), &#x27;kl&#x27;: np.float64(0.012633896415870075), &#x27;entropy&#x27;: np.float64(2.4823521005610627), &#x27;entropy_coeff&#x27;: np.float64(0.0)}, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: np.float64(125.0), &#x27;num_grad_updates_lifetime&#x27;: np.float64(9120.5), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float64(479.5)}}, &#x27;num_env_steps_sampled&#x27;: 40000, &#x27;num_env_steps_trained&#x27;: 40000, &#x27;num_agent_steps_sampled&#x27;: 80000, &#x27;num_agent_steps_trained&#x27;: 80000}</td><td style=\"text-align: right;\">                    80000</td><td style=\"text-align: right;\">                             80000</td><td style=\"text-align: right;\">                    80000</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                           40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   170.122</td><td style=\"text-align: right;\">                  40000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   170.122</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                         4000</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(32.84411764705882), &#x27;ram_util_percent&#x27;: np.float64(17.735294117647058)}</td><td>{&#x27;training_iteration_time_ms&#x27;: 24123.206, &#x27;restore_workers_time_ms&#x27;: 0.034, &#x27;training_step_time_ms&#x27;: 24123.106, &#x27;sample_time_ms&#x27;: 8158.672, &#x27;learn_time_ms&#x27;: 15949.955, &#x27;learn_throughput&#x27;: 250.784, &#x27;synch_weights_time_ms&#x27;: 14.054}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:51 (running for 00:00:40.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      1 |          27.8271 | 4000 |          -270.351 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      1 |          24.6068 | 4000 |          -241.858 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:41:56 (running for 00:00:45.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      1 |          27.8271 | 4000 |          -270.351 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      1 |          24.6068 | 4000 |          -241.858 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:01 (running for 00:00:50.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      1 |          27.8271 | 4000 |          -270.351 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      1 |          24.6068 | 4000 |          -241.858 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:06 (running for 00:00:55.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      1 |          27.8271 | 4000 |          -270.351 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      1 |          24.6068 | 4000 |          -241.858 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:11 (running for 00:01:00.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      1 |          27.8271 | 4000 |          -270.351 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      2 |          47.6689 | 8000 |          -246.195 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:16 (running for 00:01:05.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      1 |          27.8271 | 4000 |          -270.351 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      2 |          47.6689 | 8000 |          -246.195 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:21 (running for 00:01:10.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      2 |          54.4278 | 8000 |          -255.829 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      2 |          47.6689 | 8000 |          -246.195 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:26 (running for 00:01:15.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      2 |          54.4278 | 8000 |          -255.829 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      2 |          47.6689 | 8000 |          -246.195 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:31 (running for 00:01:20.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |   ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      2 |          54.4278 | 8000 |          -255.829 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      2 |          47.6689 | 8000 |          -246.195 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:36 (running for 00:01:25.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      2 |          54.4278 |  8000 |          -255.829 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      3 |          71.6023 | 12000 |          -245.027 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:41 (running for 00:01:31.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      2 |          54.4278 |  8000 |          -255.829 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      3 |          71.6023 | 12000 |          -245.027 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:46 (running for 00:01:36.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      3 |          81.1752 | 12000 |          -253.587 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      3 |          71.6023 | 12000 |          -245.027 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:51 (running for 00:01:41.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      3 |          81.1752 | 12000 |          -253.587 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      3 |          71.6023 | 12000 |          -245.027 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:42:56 (running for 00:01:46.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      3 |          81.1752 | 12000 |          -253.587 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      3 |          71.6023 | 12000 |          -245.027 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:01 (running for 00:01:51.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      3 |          81.1752 | 12000 |          -253.587 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      4 |          96.4576 | 16000 |          -241.159 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:06 (running for 00:01:56.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      3 |          81.1752 | 12000 |          -253.587 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      4 |          96.4576 | 16000 |          -241.159 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:11 (running for 00:02:01.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      4 |         108.927  | 16000 |          -246.466 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      4 |          96.4576 | 16000 |          -241.159 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:16 (running for 00:02:06.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      4 |         108.927  | 16000 |          -246.466 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      4 |          96.4576 | 16000 |          -241.159 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:21 (running for 00:02:11.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      4 |         108.927  | 16000 |          -246.466 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      4 |          96.4576 | 16000 |          -241.159 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:26 (running for 00:02:16.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      4 |          108.927 | 16000 |          -246.466 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      5 |          121.724 | 20000 |          -234.59  |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:32 (running for 00:02:21.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      4 |          108.927 | 16000 |          -246.466 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      5 |          121.724 | 20000 |          -234.59  |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:37 (running for 00:02:26.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      4 |          108.927 | 16000 |          -246.466 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      5 |          121.724 | 20000 |          -234.59  |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:42 (running for 00:02:31.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      5 |          136.059 | 20000 |          -246.951 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      5 |          121.724 | 20000 |          -234.59  |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:47 (running for 00:02:36.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      5 |          136.059 | 20000 |          -246.951 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      5 |          121.724 | 20000 |          -234.59  |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:52 (running for 00:02:41.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      5 |          136.059 | 20000 |          -246.951 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      6 |          145.409 | 24000 |          -230.174 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:43:57 (running for 00:02:46.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      5 |          136.059 | 20000 |          -246.951 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      6 |          145.409 | 24000 |          -230.174 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:02 (running for 00:02:51.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      5 |          136.059 | 20000 |          -246.951 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      6 |          145.409 | 24000 |          -230.174 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:07 (running for 00:02:56.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      6 |          162.521 | 24000 |          -239.051 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      6 |          145.409 | 24000 |          -230.174 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:12 (running for 00:03:01.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      6 |          162.521 | 24000 |          -239.051 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      7 |          169.678 | 28000 |          -225.575 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:17 (running for 00:03:06.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      6 |          162.521 | 24000 |          -239.051 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      7 |          169.678 | 28000 |          -225.575 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:22 (running for 00:03:11.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      6 |          162.521 | 24000 |          -239.051 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      7 |          169.678 | 28000 |          -225.575 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:27 (running for 00:03:16.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      6 |          162.521 | 24000 |          -239.051 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      7 |          169.678 | 28000 |          -225.575 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:32 (running for 00:03:21.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      6 |          162.521 | 24000 |          -239.051 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      7 |          169.678 | 28000 |          -225.575 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:37 (running for 00:03:27.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      7 |          190.469 | 28000 |          -236.391 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      8 |          193.495 | 32000 |          -222.368 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:42 (running for 00:03:32.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      7 |          190.469 | 28000 |          -236.391 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      8 |          193.495 | 32000 |          -222.368 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:47 (running for 00:03:37.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      7 |          190.469 | 28000 |          -236.391 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      8 |          193.495 | 32000 |          -222.368 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:52 (running for 00:03:42.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      7 |          190.469 | 28000 |          -236.391 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      8 |          193.495 | 32000 |          -222.368 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:44:57 (running for 00:03:47.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      7 |          190.469 | 28000 |          -236.391 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      8 |          193.495 | 32000 |          -222.368 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:02 (running for 00:03:52.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      8 |          217.293 | 32000 |          -236.353 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      9 |          217.813 | 36000 |          -220.299 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:07 (running for 00:03:57.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      8 |          217.293 | 32000 |          -236.353 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      9 |          217.813 | 36000 |          -220.299 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:12 (running for 00:04:02.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      8 |          217.293 | 32000 |          -236.353 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      9 |          217.813 | 36000 |          -220.299 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:17 (running for 00:04:07.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      8 |          217.293 | 32000 |          -236.353 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      9 |          217.813 | 36000 |          -220.299 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:22 (running for 00:04:12.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 RUNNING)\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status   | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+----------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING  | 10.42.142.216:408431 |      8 |          217.293 | 32000 |          -236.353 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | RUNNING  | 10.42.142.216:408432 |      9 |          217.813 | 36000 |          -220.299 |\n",
      "+------------------------------------+----------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=408432)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00001_1_2024-09-28_14-41-10/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=408431)\u001b[0m 2024-09-28 14:41:31,681\tWARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:28 (running for 00:04:17.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status     | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+------------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING    | 10.42.142.216:408431 |      9 |          244.106 | 36000 |          -231.656 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | TERMINATED | 10.42.142.216:408432 |     10 |          241.336 | 40000 |          -213.682 |\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:33 (running for 00:04:22.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status     | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+------------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING    | 10.42.142.216:408431 |      9 |          244.106 | 36000 |          -231.656 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | TERMINATED | 10.42.142.216:408432 |     10 |          241.336 | 40000 |          -213.682 |\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:38 (running for 00:04:27.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status     | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+------------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING    | 10.42.142.216:408431 |      9 |          244.106 | 36000 |          -231.656 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | TERMINATED | 10.42.142.216:408432 |     10 |          241.336 | 40000 |          -213.682 |\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:43 (running for 00:04:32.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status     | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+------------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING    | 10.42.142.216:408431 |      9 |          244.106 | 36000 |          -231.656 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | TERMINATED | 10.42.142.216:408432 |     10 |          241.336 | 40000 |          -213.682 |\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:48 (running for 00:04:37.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status     | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+------------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING    | 10.42.142.216:408431 |      9 |          244.106 | 36000 |          -231.656 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | TERMINATED | 10.42.142.216:408432 |     10 |          241.336 | 40000 |          -213.682 |\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 14:45:53,345\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/PPO_2024-09-28_14-41-10' in 0.0250s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:53 (running for 00:04:42.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (1 RUNNING, 1 TERMINATED)\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status     | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+------------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | RUNNING    | 10.42.142.216:408431 |     10 |          270.649 | 40000 |          -228.946 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | TERMINATED | 10.42.142.216:408432 |     10 |          241.336 | 40000 |          -213.682 |\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2024-09-28 14:45:53 (running for 00:04:42.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/64 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2024-09-28_14-41-06_816937_376672/artifacts/2024-09-28_14-41-10/PPO_2024-09-28_14-41-10/driver_artifacts\n",
      "Number of trials: 2/2 (2 TERMINATED)\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "| Trial name                         | status     | loc                  |   iter |   total time (s) |    ts |   combined return |\n",
      "|------------------------------------+------------+----------------------+--------+------------------+-------+-------------------|\n",
      "| PPO_2_agent_waterworld_b4113_00000 | TERMINATED | 10.42.142.216:408431 |     10 |          270.649 | 40000 |          -228.946 |\n",
      "| PPO_2_agent_waterworld_b4113_00001 | TERMINATED | 10.42.142.216:408432 |     10 |          241.336 | 40000 |          -213.682 |\n",
      "+------------------------------------+------------+----------------------+--------+------------------+-------+-------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=408431)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00000_0_2024-09-28_14-41-10/checkpoint_000000)\n",
      "2024-09-28 14:45:54,019\tINFO tune.py:1041 -- Total run time: 283.44 seconds (282.72 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "parser = add_rllib_example_script_args(\n",
    "    default_iters=10,\n",
    "    default_timesteps=1000000,\n",
    "    default_reward=300,\n",
    ")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.checkpoint_at_end = True\n",
    "args.num_samples = 2\n",
    "args.num_agents = 2\n",
    "env = 'waterworld'\n",
    "\n",
    "from pettingzoo.sisl import waterworld_v4\n",
    "register_env(f\"{args.num_agents}_agent_{env}\", lambda _:\n",
    "    ParallelPettingZooEnv(\n",
    "        waterworld_v4.parallel_env(n_pursuers=args.num_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(args.num_agents)}\n",
    "\n",
    "config = (\n",
    "        get_trainable_cls(args.algo)\n",
    "        .get_default_config()\n",
    "        .environment( f\"{args.num_agents}_agent_{env}\" )\n",
    "        .multi_agent(\n",
    "            policies=policies,\n",
    "            # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "            policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "        )\n",
    "        .rl_module(\n",
    "            model_config_dict={\"vf_share_layers\": True},\n",
    "            rl_module_spec=MultiAgentRLModuleSpec(\n",
    "                module_specs={p: SingleAgentRLModuleSpec() for p in policies},\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "results = run_rllib_example_script_experiment(config,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'pursuer_0': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(3.6451383), 'cur_kl_coeff': np.float64(0.10000000000000002), 'cur_lr': np.float64(5.0000000000000016e-05), 'total_loss': np.float64(4.388929148266713), 'policy_loss': np.float64(-0.021291275953505343), 'vf_loss': np.float64(4.408763808508714), 'vf_explained_var': np.float64(0.02267032687862714), 'kl': np.float64(0.014566012486125185), 'entropy': np.float64(2.242644399901231), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(125.0), 'num_grad_updates_lifetime': np.float64(9120.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}, 'pursuer_1': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(2.6652873), 'cur_kl_coeff': np.float64(0.10000000000000002), 'cur_lr': np.float64(5.0000000000000016e-05), 'total_loss': np.float64(6.674920690556367), 'policy_loss': np.float64(-0.014248947574136158), 'vf_loss': np.float64(6.688073832293352), 'vf_explained_var': np.float64(6.457169850667318e-09), 'kl': np.float64(0.010958172467432343), 'entropy': np.float64(2.3664672071735064), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(125.0), 'num_grad_updates_lifetime': np.float64(9120.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'env_runners': {'episode_reward_max': np.float64(-109.91431194146944), 'episode_reward_min': np.float64(-298.7184147633438), 'episode_reward_mean': np.float64(-228.94587691636798), 'episode_len_mean': np.float64(500.0), 'episode_media': {}, 'episodes_timesteps_total': 40000, 'policy_reward_min': {'pursuer_0': np.float64(-113.8010956018662), 'pursuer_1': np.float64(-220.75756586131507)}, 'policy_reward_max': {'pursuer_0': np.float64(37.806550781453886), 'pursuer_1': np.float64(-51.75556256831941)}, 'policy_reward_mean': {'pursuer_0': np.float64(-65.86400982364955), 'pursuer_1': np.float64(-163.08186709271837)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-288.19604400750137), np.float64(-263.7468038366759), np.float64(-244.30111123903578), np.float64(-283.9948898961454), np.float64(-266.52424942426353), np.float64(-283.24287880404324), np.float64(-284.17441424624997), np.float64(-248.62746680865448), np.float64(-257.9417130533655), np.float64(-220.42647413159722), np.float64(-279.10487828195244), np.float64(-225.83226865969763), np.float64(-267.5815759207497), np.float64(-271.49241709495544), np.float64(-178.22703088448463), np.float64(-229.84590911390137), np.float64(-283.29252735448046), np.float64(-221.4788464036972), np.float64(-242.04756682274078), np.float64(-209.87059251260922), np.float64(-263.5882247304495), np.float64(-279.5352918810063), np.float64(-207.44858996916977), np.float64(-285.56029219438506), np.float64(-273.78530598321595), np.float64(-216.366507748988), np.float64(-157.21812407740353), np.float64(-279.2009393513053), np.float64(-224.1327013249195), np.float64(-258.9438470860721), np.float64(-214.21352376888956), np.float64(-176.96741257154406), np.float64(-216.26404294800517), np.float64(-279.6278106961485), np.float64(-208.9982970535929), np.float64(-298.7184147633438), np.float64(-287.40283754424377), np.float64(-253.73638213813956), np.float64(-176.14185961165376), np.float64(-270.23272851396246), np.float64(-231.5977383001091), np.float64(-228.2317140956118), np.float64(-142.97772652541653), np.float64(-224.06504969032426), np.float64(-216.31520108962522), np.float64(-161.94456375292484), np.float64(-163.2006765974115), np.float64(-228.09950280356236), np.float64(-206.44540298297636), np.float64(-248.0693002335791), np.float64(-238.0591045290493), np.float64(-224.96247305625587), np.float64(-226.36519768391653), np.float64(-163.07998073919688), np.float64(-242.084650185815), np.float64(-214.34671619042751), np.float64(-246.7996298110595), np.float64(-109.91431194146944), np.float64(-297.73409381647144), np.float64(-171.42468026493637), np.float64(-283.58250590538063), np.float64(-290.4526932581631), np.float64(-261.38643421717035), np.float64(-227.41501198040567), np.float64(-242.515063822877), np.float64(-161.37458440122356), np.float64(-158.41690014386194), np.float64(-146.23992380707847), np.float64(-249.44759438357062), np.float64(-236.96364034289675), np.float64(-198.42201909025943), np.float64(-159.28626787164157), np.float64(-203.1828814992124), np.float64(-200.89287378134142), np.float64(-242.6789717237335), np.float64(-227.3448139903929), np.float64(-126.00548816260753), np.float64(-198.78253444865277), np.float64(-216.27547814287493), np.float64(-221.25396559271206)], 'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], 'policy_pursuer_0_reward': [np.float64(-67.43847814618631), np.float64(-87.01379060574175), np.float64(-49.678346047075436), np.float64(-88.41905269889577), np.float64(-70.43092731998523), np.float64(-67.89562608166656), np.float64(-111.52255883910973), np.float64(-91.86081243678316), np.float64(-68.27276719717983), np.float64(-89.20450022380615), np.float64(-108.9048830176642), np.float64(-29.810811391292283), np.float64(-69.14586756039105), np.float64(-74.15235687394541), np.float64(-50.76983075748302), np.float64(-89.22796895587922), np.float64(-90.41257166313841), np.float64(-111.47712615942426), np.float64(-43.93062332799966), np.float64(-48.90796985908147), np.float64(-85.61332762702827), np.float64(-85.56041558013236), np.float64(-72.5702600039611), np.float64(-90.98792754691185), np.float64(-104.60089364497696), np.float64(-103.6947405911414), np.float64(-46.25422893490652), np.float64(-109.06477154876286), np.float64(-30.06257926610819), np.float64(-87.0399728363215), np.float64(-85.19555027496872), np.float64(-3.3234484530167534), np.float64(-45.61793227588634), np.float64(-68.01766143446345), np.float64(-63.35798382196723), np.float64(-86.14136708394201), np.float64(-85.58663815074983), np.float64(-45.79046148286436), np.float64(-88.26425804432336), np.float64(-68.85190050516039), np.float64(-42.15027200468986), np.float64(-113.8010956018662), np.float64(-41.44781130619788), np.float64(-60.467221914845084), np.float64(-104.59458265433146), np.float64(-48.49453590206116), np.float64(-24.51670045124924), np.float64(-39.85201313087268), np.float64(-64.48492465649565), np.float64(-63.72223624722697), np.float64(-80.56958856923775), np.float64(-82.39071543464719), np.float64(-22.679745411820523), np.float64(-43.133812170536764), np.float64(-80.84140494752786), np.float64(-84.87055463893823), np.float64(-61.64944773527349), np.float64(-58.15874937315008), np.float64(-104.74780377368405), np.float64(18.288976596539484), np.float64(-78.70178752804192), np.float64(-104.21177021215824), np.float64(-59.047468954171634), np.float64(-59.68425366231564), np.float64(-82.88091340582244), np.float64(-89.39760087770851), np.float64(-35.913954005344806), np.float64(37.806550781453886), np.float64(-80.96395793394198), np.float64(-38.2855542208746), np.float64(-15.937873661372281), np.float64(-18.93716190318739), np.float64(-102.14447938795182), np.float64(-41.83242019973604), np.float64(-95.49982253451242), np.float64(-39.18781142321924), np.float64(21.621880822003956), np.float64(-80.31830692637276), np.float64(-53.7684032592031), np.float64(-83.47824980105196)], 'policy_pursuer_1_reward': [np.float64(-220.75756586131507), np.float64(-176.73301323093426), np.float64(-194.6227651919605), np.float64(-195.57583719724977), np.float64(-196.09332210427843), np.float64(-215.34725272237662), np.float64(-172.65185540714018), np.float64(-156.76665437187114), np.float64(-189.66894585618525), np.float64(-131.2219739077913), np.float64(-170.19999526428822), np.float64(-196.02145726840556), np.float64(-198.4357083603586), np.float64(-197.34006022101002), np.float64(-127.45720012700166), np.float64(-140.6179401580221), np.float64(-192.87995569134222), np.float64(-110.00172024427266), np.float64(-198.11694349474112), np.float64(-160.96262265352794), np.float64(-177.97489710342134), np.float64(-193.97487630087383), np.float64(-134.87832996520848), np.float64(-194.572364647473), np.float64(-169.1844123382389), np.float64(-112.67176715784672), np.float64(-110.96389514249705), np.float64(-170.1361678025425), np.float64(-194.0701220588113), np.float64(-171.90387424975077), np.float64(-129.0179734939207), np.float64(-173.64396411852744), np.float64(-170.6461106721188), np.float64(-211.61014926168505), np.float64(-145.6403132316256), np.float64(-212.5770476794018), np.float64(-201.8161993934941), np.float64(-207.94592065527533), np.float64(-87.87760156733042), np.float64(-201.3808280088021), np.float64(-189.44746629541905), np.float64(-114.43061849374548), np.float64(-101.5299152192185), np.float64(-163.5978277754791), np.float64(-111.72061843529373), np.float64(-113.45002785086385), np.float64(-138.6839761461619), np.float64(-188.24748967268977), np.float64(-141.96047832648074), np.float64(-184.34706398635208), np.float64(-157.48951595981134), np.float64(-142.57175762160884), np.float64(-203.68545227209603), np.float64(-119.94616856866006), np.float64(-161.24324523828696), np.float64(-129.47616155148904), np.float64(-185.15018207578598), np.float64(-51.75556256831941), np.float64(-192.98629004278743), np.float64(-189.7136568614758), np.float64(-204.88071837733895), np.float64(-186.2409230460048), np.float64(-202.33896526299867), np.float64(-167.73075831809012), np.float64(-159.63415041705446), np.float64(-71.9769835235151), np.float64(-122.50294613851715), np.float64(-184.04647458853208), np.float64(-168.48363644962856), np.float64(-198.67808612202208), np.float64(-182.48414542888705), np.float64(-140.34910596845415), np.float64(-101.03840211126058), np.float64(-159.06045358160554), np.float64(-147.17914918922116), np.float64(-188.15700256717338), np.float64(-147.62736898461145), np.float64(-118.46422752228023), np.float64(-162.5070748836717), np.float64(-137.7757157916601)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.45197264253195446), 'mean_inference_ms': np.float64(1.6312213667720208), 'mean_action_processing_ms': np.float64(0.21701613847897255), 'mean_env_wait_ms': np.float64(1.8669775382498046), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0037285685539245605), 'StateBufferConnector_ms': np.float64(0.0026425719261169434), 'ViewRequirementAgentConnector_ms': np.float64(0.06747499108314514)}, 'num_episodes': 8, 'episode_return_max': np.float64(-109.91431194146944), 'episode_return_min': np.float64(-298.7184147633438), 'episode_return_mean': np.float64(-228.94587691636798), 'episodes_this_iter': 8}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 150.75771106284066, 'num_env_steps_trained_throughput_per_sec': 150.75771106284066, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 80000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 27057.386, 'restore_workers_time_ms': 0.045, 'training_step_time_ms': 27057.24, 'sample_time_ms': 8556.097, 'learn_time_ms': 18479.763, 'learn_throughput': 216.453, 'synch_weights_time_ms': 19.452}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'perf': {'cpu_util_percent': np.float64(32.27631578947369), 'ram_util_percent': np.float64(17.650000000000006)}},\n",
       "    path='/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00000_0_2024-09-28_14-41-10',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00000_0_2024-09-28_14-41-10/checkpoint_000000)\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'pursuer_0': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(3.126109), 'cur_kl_coeff': np.float64(0.10000000000000002), 'cur_lr': np.float64(5.0000000000000016e-05), 'total_loss': np.float64(8.143767655392487), 'policy_loss': np.float64(-0.017855608288664372), 'vf_loss': np.float64(8.160278207063675), 'vf_explained_var': np.float64(-0.005060878830651442), 'kl': np.float64(0.013450785714182227), 'entropy': np.float64(2.1470594136665264), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(125.0), 'num_grad_updates_lifetime': np.float64(9120.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}, 'pursuer_1': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(2.4878275), 'cur_kl_coeff': np.float64(0.20000000000000004), 'cur_lr': np.float64(5.0000000000000016e-05), 'total_loss': np.float64(6.591445065041383), 'policy_loss': np.float64(-0.01917047797420916), 'vf_loss': np.float64(6.608088782429695), 'vf_explained_var': np.float64(4.805624485015869e-08), 'kl': np.float64(0.012633896415870075), 'entropy': np.float64(2.4823521005610627), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(125.0), 'num_grad_updates_lifetime': np.float64(9120.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'env_runners': {'episode_reward_max': np.float64(-88.59814663137603), 'episode_reward_min': np.float64(-327.5372595245201), 'episode_reward_mean': np.float64(-213.68207949729018), 'episode_len_mean': np.float64(500.0), 'episode_media': {}, 'episodes_timesteps_total': 40000, 'policy_reward_min': {'pursuer_0': np.float64(-112.15139658689594), 'pursuer_1': np.float64(-219.46226524053978)}, 'policy_reward_max': {'pursuer_0': np.float64(63.218716075993676), 'pursuer_1': np.float64(-80.10107204170268)}, 'policy_reward_mean': {'pursuer_0': np.float64(-51.49456132324792), 'pursuer_1': np.float64(-162.18751817404222)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-163.55706401094625), np.float64(-223.6296668324708), np.float64(-287.36318449284613), np.float64(-211.81659079575184), np.float64(-285.894972558428), np.float64(-249.15760113814466), np.float64(-308.4128001162764), np.float64(-205.03461011949804), np.float64(-290.899096788498), np.float64(-206.88563948073354), np.float64(-236.9071112586494), np.float64(-275.24847084220227), np.float64(-223.40165228904863), np.float64(-263.92671544773845), np.float64(-284.6287054277883), np.float64(-222.35383193727307), np.float64(-273.30191343731315), np.float64(-224.00144059772592), np.float64(-286.32985161231875), np.float64(-288.15026051732497), np.float64(-187.23595171170717), np.float64(-182.21618793750613), np.float64(-172.75706634983155), np.float64(-327.5372595245201), np.float64(-216.99751529452527), np.float64(-203.0578745001306), np.float64(-242.56806582483105), np.float64(-271.93423679740044), np.float64(-167.4629692554303), np.float64(-232.29777653870968), np.float64(-251.42691688604205), np.float64(-250.68566398330418), np.float64(-88.59814663137603), np.float64(-184.78393681933966), np.float64(-243.35676513349273), np.float64(-205.94192745887207), np.float64(-222.9108424954063), np.float64(-209.24988208903304), np.float64(-243.77355991027557), np.float64(-267.8926025452551), np.float64(-264.13252962005424), np.float64(-281.04963965162347), np.float64(-176.69844913873857), np.float64(-235.471756455781), np.float64(-154.44258133509484), np.float64(-159.169025319122), np.float64(-200.28342012072946), np.float64(-193.5007591495159), np.float64(-125.91157633181624), np.float64(-175.70513694661022), np.float64(-172.95351502538222), np.float64(-218.5764213963486), np.float64(-233.93520573111522), np.float64(-248.6981881099773), np.float64(-107.57900771093867), np.float64(-300.5009437742603), np.float64(-280.71760473985944), np.float64(-213.5208644380312), np.float64(-186.8181678287598), np.float64(-156.1422581915858), np.float64(-213.26766932172936), np.float64(-189.0545426572954), np.float64(-232.78629935588734), np.float64(-127.06078950855938), np.float64(-194.66035168603764), np.float64(-178.92020447096928), np.float64(-200.12535759875666), np.float64(-251.83915662855932), np.float64(-146.4520350378026), np.float64(-196.73276021213732), np.float64(-210.6694797214984), np.float64(-250.56222266877882), np.float64(-235.71191707505795), np.float64(-119.17821681513107), np.float64(-125.33162714514444), np.float64(-98.31586478338365), np.float64(-128.95455177924978), np.float64(-126.7681736353628), np.float64(-203.5129793994155), np.float64(-195.26878187914716)], 'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], 'policy_pursuer_0_reward': [np.float64(-27.273564969250696), np.float64(-50.23968375421234), np.float64(-107.75383069514464), np.float64(-72.25874997795505), np.float64(-91.07873816366528), np.float64(-73.8921093942477), np.float64(-90.19461047490454), np.float64(-69.70578231325185), np.float64(-110.88641093689522), np.float64(-49.51019167973318), np.float64(-49.920194181303884), np.float64(-112.15139658689594), np.float64(-65.67300514498757), np.float64(-70.09154985299807), np.float64(-90.26071524998164), np.float64(-11.282684387809729), np.float64(-86.87711007226166), np.float64(-30.161819407448014), np.float64(-94.18938379728824), np.float64(-93.24607736810731), np.float64(-50.04201679870226), np.float64(-24.66412153729765), np.float64(-17.485925708222766), np.float64(-108.07499428398033), np.float64(-62.632012252245595), np.float64(-60.464054667652746), np.float64(-87.00916716695406), np.float64(-88.24966117602558), np.float64(-12.216348549195025), np.float64(-66.11210489008579), np.float64(-90.89115711355274), np.float64(-107.05621377207851), np.float64(63.218716075993676), np.float64(-7.745235544675222), np.float64(-67.15664709770904), np.float64(-48.35236845029673), np.float64(-71.53745243329715), np.float64(-48.602052415963975), np.float64(-70.77962010336944), np.float64(-92.40845394706008), np.float64(-67.47778342627657), np.float64(-68.5809296342887), np.float64(-48.84348484149235), np.float64(-45.18551425597062), np.float64(-38.404000660142145), np.float64(-66.83484285236788), np.float64(-28.056994458685473), np.float64(-71.39307962476043), np.float64(0.37888781618597067), np.float64(-41.49658761338609), np.float64(-3.546459385687965), np.float64(-81.13759232175138), np.float64(-22.11577722680005), np.float64(-65.14667115364016), np.float64(-2.533881636298743), np.float64(-86.57235302255701), np.float64(-109.8629505252991), np.float64(-66.12725783972853), np.float64(-60.87195873463635), np.float64(-21.467276956695773), np.float64(-60.95777612480822), np.float64(-2.0427358416525423), np.float64(-19.63119916043664), np.float64(-1.7670508193898637), np.float64(-12.534273190602246), np.float64(-81.26003956174611), np.float64(-83.73256619010671), np.float64(-62.017569872384925), np.float64(-16.664456897663353), np.float64(-8.807607385252595), np.float64(-23.421182150321478), np.float64(-87.45896312967005), np.float64(-66.999924392644), np.float64(-26.463238036138193), np.float64(-17.326918695409713), np.float64(-18.21479274168097), np.float64(44.759198888701135), np.float64(19.567397002252914), np.float64(-9.050297925821585), np.float64(-25.35590104006608)], 'policy_pursuer_1_reward': [np.float64(-136.28349904169545), np.float64(-173.38998307825844), np.float64(-179.60935379770137), np.float64(-139.55784081779672), np.float64(-194.8162343947623), np.float64(-175.26549174389694), np.float64(-218.21818964137185), np.float64(-135.3288278062462), np.float64(-180.0126858516028), np.float64(-157.37544780100038), np.float64(-186.98691707734542), np.float64(-163.09707425530604), np.float64(-157.72864714406091), np.float64(-193.83516559474043), np.float64(-194.36799017780672), np.float64(-211.07114754946318), np.float64(-186.42480336505142), np.float64(-193.8396211902778), np.float64(-192.14046781503052), np.float64(-194.9041831492174), np.float64(-137.1939349130047), np.float64(-157.5520664002084), np.float64(-155.2711406416091), np.float64(-219.46226524053978), np.float64(-154.3655030422797), np.float64(-142.5938198324778), np.float64(-155.55889865787702), np.float64(-183.6845756213749), np.float64(-155.2466207062352), np.float64(-166.18567164862378), np.float64(-160.5357597724894), np.float64(-143.62945021122576), np.float64(-151.81686270736978), np.float64(-177.03870127466425), np.float64(-176.20011803578348), np.float64(-157.58955900857543), np.float64(-151.37339006210908), np.float64(-160.6478296730689), np.float64(-172.99393980690562), np.float64(-175.4841485981951), np.float64(-196.65474619377753), np.float64(-212.46871001733479), np.float64(-127.8549642972461), np.float64(-190.28624219981054), np.float64(-116.03858067495273), np.float64(-92.33418246675419), np.float64(-172.2264256620441), np.float64(-122.10767952475533), np.float64(-126.29046414800227), np.float64(-134.20854933322406), np.float64(-169.40705563969408), np.float64(-137.4388290745972), np.float64(-211.81942850431523), np.float64(-183.55151695633708), np.float64(-105.04512607463985), np.float64(-213.92859075170304), np.float64(-170.85465421456024), np.float64(-147.3936065983026), np.float64(-125.94620909412353), np.float64(-134.67498123489005), np.float64(-152.3098931969213), np.float64(-187.01180681564293), np.float64(-213.15510019545056), np.float64(-125.29373868916947), np.float64(-182.1260784954353), np.float64(-97.66016490922273), np.float64(-116.39279140864988), np.float64(-189.82158675617413), np.float64(-129.7875781401393), np.float64(-187.92515282688476), np.float64(-187.2482975711769), np.float64(-163.1032595391086), np.float64(-168.71199268241404), np.float64(-92.71497877899301), np.float64(-108.00470844973479), np.float64(-80.10107204170268), np.float64(-173.71375066795068), np.float64(-146.33557063761566), np.float64(-194.46268147359382), np.float64(-169.91288083908114)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.4311195631143619), 'mean_inference_ms': np.float64(1.5308585708678597), 'mean_action_processing_ms': np.float64(0.2080200872965438), 'mean_env_wait_ms': np.float64(1.793121419794589), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.003678947687149048), 'StateBufferConnector_ms': np.float64(0.0027632713317871094), 'ViewRequirementAgentConnector_ms': np.float64(0.06836071610450745)}, 'num_episodes': 8, 'episode_return_max': np.float64(-88.59814663137603), 'episode_return_min': np.float64(-327.5372595245201), 'episode_return_mean': np.float64(-213.68207949729018), 'episodes_this_iter': 8}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 170.121590197099, 'num_env_steps_trained_throughput_per_sec': 170.121590197099, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 80000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 24123.206, 'restore_workers_time_ms': 0.034, 'training_step_time_ms': 24123.106, 'sample_time_ms': 8158.672, 'learn_time_ms': 15949.955, 'learn_throughput': 250.784, 'synch_weights_time_ms': 14.054}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'perf': {'cpu_util_percent': np.float64(32.84411764705882), 'ram_util_percent': np.float64(17.735294117647058)}},\n",
       "    path='/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00001_1_2024-09-28_14-41-10',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00001_1_2024-09-28_14-41-10/checkpoint_000000)\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'pursuer_0': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(3.6451383), 'cur_kl_coeff': np.float64(0.10000000000000002), 'cur_lr': np.float64(5.0000000000000016e-05), 'total_loss': np.float64(4.388929148266713), 'policy_loss': np.float64(-0.021291275953505343), 'vf_loss': np.float64(4.408763808508714), 'vf_explained_var': np.float64(0.02267032687862714), 'kl': np.float64(0.014566012486125185), 'entropy': np.float64(2.242644399901231), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(125.0), 'num_grad_updates_lifetime': np.float64(9120.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}, 'pursuer_1': {'learner_stats': {'allreduce_latency': np.float64(0.0), 'grad_gnorm': np.float32(2.6652873), 'cur_kl_coeff': np.float64(0.10000000000000002), 'cur_lr': np.float64(5.0000000000000016e-05), 'total_loss': np.float64(6.674920690556367), 'policy_loss': np.float64(-0.014248947574136158), 'vf_loss': np.float64(6.688073832293352), 'vf_explained_var': np.float64(6.457169850667318e-09), 'kl': np.float64(0.010958172467432343), 'entropy': np.float64(2.3664672071735064), 'entropy_coeff': np.float64(0.0)}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': np.float64(125.0), 'num_grad_updates_lifetime': np.float64(9120.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'env_runners': {'episode_reward_max': np.float64(-109.91431194146944), 'episode_reward_min': np.float64(-298.7184147633438), 'episode_reward_mean': np.float64(-228.94587691636798), 'episode_len_mean': np.float64(500.0), 'episode_media': {}, 'episodes_timesteps_total': 40000, 'policy_reward_min': {'pursuer_0': np.float64(-113.8010956018662), 'pursuer_1': np.float64(-220.75756586131507)}, 'policy_reward_max': {'pursuer_0': np.float64(37.806550781453886), 'pursuer_1': np.float64(-51.75556256831941)}, 'policy_reward_mean': {'pursuer_0': np.float64(-65.86400982364955), 'pursuer_1': np.float64(-163.08186709271837)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-288.19604400750137), np.float64(-263.7468038366759), np.float64(-244.30111123903578), np.float64(-283.9948898961454), np.float64(-266.52424942426353), np.float64(-283.24287880404324), np.float64(-284.17441424624997), np.float64(-248.62746680865448), np.float64(-257.9417130533655), np.float64(-220.42647413159722), np.float64(-279.10487828195244), np.float64(-225.83226865969763), np.float64(-267.5815759207497), np.float64(-271.49241709495544), np.float64(-178.22703088448463), np.float64(-229.84590911390137), np.float64(-283.29252735448046), np.float64(-221.4788464036972), np.float64(-242.04756682274078), np.float64(-209.87059251260922), np.float64(-263.5882247304495), np.float64(-279.5352918810063), np.float64(-207.44858996916977), np.float64(-285.56029219438506), np.float64(-273.78530598321595), np.float64(-216.366507748988), np.float64(-157.21812407740353), np.float64(-279.2009393513053), np.float64(-224.1327013249195), np.float64(-258.9438470860721), np.float64(-214.21352376888956), np.float64(-176.96741257154406), np.float64(-216.26404294800517), np.float64(-279.6278106961485), np.float64(-208.9982970535929), np.float64(-298.7184147633438), np.float64(-287.40283754424377), np.float64(-253.73638213813956), np.float64(-176.14185961165376), np.float64(-270.23272851396246), np.float64(-231.5977383001091), np.float64(-228.2317140956118), np.float64(-142.97772652541653), np.float64(-224.06504969032426), np.float64(-216.31520108962522), np.float64(-161.94456375292484), np.float64(-163.2006765974115), np.float64(-228.09950280356236), np.float64(-206.44540298297636), np.float64(-248.0693002335791), np.float64(-238.0591045290493), np.float64(-224.96247305625587), np.float64(-226.36519768391653), np.float64(-163.07998073919688), np.float64(-242.084650185815), np.float64(-214.34671619042751), np.float64(-246.7996298110595), np.float64(-109.91431194146944), np.float64(-297.73409381647144), np.float64(-171.42468026493637), np.float64(-283.58250590538063), np.float64(-290.4526932581631), np.float64(-261.38643421717035), np.float64(-227.41501198040567), np.float64(-242.515063822877), np.float64(-161.37458440122356), np.float64(-158.41690014386194), np.float64(-146.23992380707847), np.float64(-249.44759438357062), np.float64(-236.96364034289675), np.float64(-198.42201909025943), np.float64(-159.28626787164157), np.float64(-203.1828814992124), np.float64(-200.89287378134142), np.float64(-242.6789717237335), np.float64(-227.3448139903929), np.float64(-126.00548816260753), np.float64(-198.78253444865277), np.float64(-216.27547814287493), np.float64(-221.25396559271206)], 'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], 'policy_pursuer_0_reward': [np.float64(-67.43847814618631), np.float64(-87.01379060574175), np.float64(-49.678346047075436), np.float64(-88.41905269889577), np.float64(-70.43092731998523), np.float64(-67.89562608166656), np.float64(-111.52255883910973), np.float64(-91.86081243678316), np.float64(-68.27276719717983), np.float64(-89.20450022380615), np.float64(-108.9048830176642), np.float64(-29.810811391292283), np.float64(-69.14586756039105), np.float64(-74.15235687394541), np.float64(-50.76983075748302), np.float64(-89.22796895587922), np.float64(-90.41257166313841), np.float64(-111.47712615942426), np.float64(-43.93062332799966), np.float64(-48.90796985908147), np.float64(-85.61332762702827), np.float64(-85.56041558013236), np.float64(-72.5702600039611), np.float64(-90.98792754691185), np.float64(-104.60089364497696), np.float64(-103.6947405911414), np.float64(-46.25422893490652), np.float64(-109.06477154876286), np.float64(-30.06257926610819), np.float64(-87.0399728363215), np.float64(-85.19555027496872), np.float64(-3.3234484530167534), np.float64(-45.61793227588634), np.float64(-68.01766143446345), np.float64(-63.35798382196723), np.float64(-86.14136708394201), np.float64(-85.58663815074983), np.float64(-45.79046148286436), np.float64(-88.26425804432336), np.float64(-68.85190050516039), np.float64(-42.15027200468986), np.float64(-113.8010956018662), np.float64(-41.44781130619788), np.float64(-60.467221914845084), np.float64(-104.59458265433146), np.float64(-48.49453590206116), np.float64(-24.51670045124924), np.float64(-39.85201313087268), np.float64(-64.48492465649565), np.float64(-63.72223624722697), np.float64(-80.56958856923775), np.float64(-82.39071543464719), np.float64(-22.679745411820523), np.float64(-43.133812170536764), np.float64(-80.84140494752786), np.float64(-84.87055463893823), np.float64(-61.64944773527349), np.float64(-58.15874937315008), np.float64(-104.74780377368405), np.float64(18.288976596539484), np.float64(-78.70178752804192), np.float64(-104.21177021215824), np.float64(-59.047468954171634), np.float64(-59.68425366231564), np.float64(-82.88091340582244), np.float64(-89.39760087770851), np.float64(-35.913954005344806), np.float64(37.806550781453886), np.float64(-80.96395793394198), np.float64(-38.2855542208746), np.float64(-15.937873661372281), np.float64(-18.93716190318739), np.float64(-102.14447938795182), np.float64(-41.83242019973604), np.float64(-95.49982253451242), np.float64(-39.18781142321924), np.float64(21.621880822003956), np.float64(-80.31830692637276), np.float64(-53.7684032592031), np.float64(-83.47824980105196)], 'policy_pursuer_1_reward': [np.float64(-220.75756586131507), np.float64(-176.73301323093426), np.float64(-194.6227651919605), np.float64(-195.57583719724977), np.float64(-196.09332210427843), np.float64(-215.34725272237662), np.float64(-172.65185540714018), np.float64(-156.76665437187114), np.float64(-189.66894585618525), np.float64(-131.2219739077913), np.float64(-170.19999526428822), np.float64(-196.02145726840556), np.float64(-198.4357083603586), np.float64(-197.34006022101002), np.float64(-127.45720012700166), np.float64(-140.6179401580221), np.float64(-192.87995569134222), np.float64(-110.00172024427266), np.float64(-198.11694349474112), np.float64(-160.96262265352794), np.float64(-177.97489710342134), np.float64(-193.97487630087383), np.float64(-134.87832996520848), np.float64(-194.572364647473), np.float64(-169.1844123382389), np.float64(-112.67176715784672), np.float64(-110.96389514249705), np.float64(-170.1361678025425), np.float64(-194.0701220588113), np.float64(-171.90387424975077), np.float64(-129.0179734939207), np.float64(-173.64396411852744), np.float64(-170.6461106721188), np.float64(-211.61014926168505), np.float64(-145.6403132316256), np.float64(-212.5770476794018), np.float64(-201.8161993934941), np.float64(-207.94592065527533), np.float64(-87.87760156733042), np.float64(-201.3808280088021), np.float64(-189.44746629541905), np.float64(-114.43061849374548), np.float64(-101.5299152192185), np.float64(-163.5978277754791), np.float64(-111.72061843529373), np.float64(-113.45002785086385), np.float64(-138.6839761461619), np.float64(-188.24748967268977), np.float64(-141.96047832648074), np.float64(-184.34706398635208), np.float64(-157.48951595981134), np.float64(-142.57175762160884), np.float64(-203.68545227209603), np.float64(-119.94616856866006), np.float64(-161.24324523828696), np.float64(-129.47616155148904), np.float64(-185.15018207578598), np.float64(-51.75556256831941), np.float64(-192.98629004278743), np.float64(-189.7136568614758), np.float64(-204.88071837733895), np.float64(-186.2409230460048), np.float64(-202.33896526299867), np.float64(-167.73075831809012), np.float64(-159.63415041705446), np.float64(-71.9769835235151), np.float64(-122.50294613851715), np.float64(-184.04647458853208), np.float64(-168.48363644962856), np.float64(-198.67808612202208), np.float64(-182.48414542888705), np.float64(-140.34910596845415), np.float64(-101.03840211126058), np.float64(-159.06045358160554), np.float64(-147.17914918922116), np.float64(-188.15700256717338), np.float64(-147.62736898461145), np.float64(-118.46422752228023), np.float64(-162.5070748836717), np.float64(-137.7757157916601)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.45197264253195446), 'mean_inference_ms': np.float64(1.6312213667720208), 'mean_action_processing_ms': np.float64(0.21701613847897255), 'mean_env_wait_ms': np.float64(1.8669775382498046), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0037285685539245605), 'StateBufferConnector_ms': np.float64(0.0026425719261169434), 'ViewRequirementAgentConnector_ms': np.float64(0.06747499108314514)}, 'num_episodes': 8, 'episode_return_max': np.float64(-109.91431194146944), 'episode_return_min': np.float64(-298.7184147633438), 'episode_return_mean': np.float64(-228.94587691636798), 'episodes_this_iter': 8}, 'num_healthy_workers': 2, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 150.75771106284066, 'num_env_steps_trained_throughput_per_sec': 150.75771106284066, 'num_env_steps_sampled_lifetime': 40000, 'num_agent_steps_sampled_lifetime': 80000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 27057.386, 'restore_workers_time_ms': 0.045, 'training_step_time_ms': 27057.24, 'sample_time_ms': 8556.097, 'learn_time_ms': 18479.763, 'learn_throughput': 216.453, 'synch_weights_time_ms': 19.452}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'perf': {'cpu_util_percent': np.float64(32.27631578947369), 'ram_util_percent': np.float64(17.650000000000006)}},\n",
       "  path='/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00000_0_2024-09-28_14-41-10',\n",
       "  filesystem='local',\n",
       "  checkpoint=Checkpoint(filesystem=local, path=/root/ray_results/PPO_2024-09-28_14-41-10/PPO_2_agent_waterworld_b4113_00000_0_2024-09-28_14-41-10/checkpoint_000000)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results.__getitem__(0).path\n",
    "#results.__getitem__(0).metrics#['env_runners']['episode_reward_mean']\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move checkpoint contents:\n",
    "import shutil \n",
    "\n",
    "\n",
    "for i in range(len(results)):   # or args.num_agents\n",
    "    source = results.__getitem__(i).path\n",
    "    score = results.__getitem__(i).metrics['env_runners']['episode_reward_mean']\n",
    "    destination = f\"/root/test/{env}/{algo}/{num_agents}/{score}\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shutil.move(source, destination, copy_function = shutil.copytree) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled Restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['/root/test/waterworld/PPO/2_agent/22.30845564138441/policies/pursuer_0',\n",
       "       '/root/test/waterworld/PPO/2_agent/22.30845564138441/policies/pursuer_1',\n",
       "       '/root/test/waterworld/PPO/2_agent/33.04836291061455/policies/pursuer_0',\n",
       "       '/root/test/waterworld/PPO/2_agent/33.04836291061455/policies/pursuer_1',\n",
       "       '/root/test/waterworld/PPO/2_agent/53.00706844190301/policies/pursuer_0',\n",
       "       '/root/test/waterworld/PPO/2_agent/53.00706844190301/policies/pursuer_1',\n",
       "       '/root/test/waterworld/PPO/2_agent/65.31630841725516/policies/pursuer_0',\n",
       "       '/root/test/waterworld/PPO/2_agent/65.31630841725516/policies/pursuer_1'],\n",
       "      dtype='<U70')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "path_to_checkpoint = \"/root/test/waterworld/PPO/2_agent/\"\n",
    "\n",
    "top_per = 0.5\n",
    "\n",
    "x = glob(path_to_checkpoint+\"*\")\n",
    "#print(x)\n",
    "x.sort()\n",
    "#print(x)\n",
    "top_num = int(len(x)*top_per)\n",
    "print(top_num)\n",
    "#print(x[-top_num:])\n",
    "candidate_runs = x[-top_num:]\n",
    "#print(candidate_runs)\n",
    "pool = np.array([glob(f+\"/policies/*\") for f in candidate_runs]).flatten()\n",
    "pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = lambda x: [_ for _ in range(x)]\n",
    "\n",
    "b = a(4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 0, 1]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 5\n",
    "\n",
    "h = []\n",
    "while len(h) < n:\n",
    "    for e in np.random.choice(b, min(len(b),n-len(h)), replace=False):\n",
    "        h.append(int(e))\n",
    "\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbhosley\u001b[0m (\u001b[33mno-organization-for-signup\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/marl-baseline/dev/wandb/run-20241021_005611-8osg7msr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/no-organization-for-signup/your_project_name/runs/8osg7msr' target=\"_blank\">vivid-water-1</a></strong> to <a href='https://wandb.ai/no-organization-for-signup/your_project_name' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/no-organization-for-signup/your_project_name' target=\"_blank\">https://wandb.ai/no-organization-for-signup/your_project_name</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/no-organization-for-signup/your_project_name/runs/8osg7msr' target=\"_blank\">https://wandb.ai/no-organization-for-signup/your_project_name/runs/8osg7msr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 58\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Run one iteration of training\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Update tracking variables\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     total_episodes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisodes_this_iter\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Initialize Weights and Biases (optional)\n",
    "use_wandb = True  # Set to False if you don't want to use Wandb\n",
    "if use_wandb:\n",
    "    wandb.init(project=\"your_project_name\", config={\n",
    "        \"num_iterations\": 100,\n",
    "        \"checkpoint_freq\": 10,\n",
    "        \"evaluation_freq\": 5,\n",
    "        \"max_episodes\": 1000,\n",
    "        \"max_timesteps\": 100000,\n",
    "        \"moving_average_window\": 10,\n",
    "        \"reward_threshold\": 200,\n",
    "        \"patience\": 10,\n",
    "        \"min_reward_improvement\": 1e-3\n",
    "    })\n",
    "\n",
    "# Assuming algo is already initialized (e.g., PPO or any other algorithm)\n",
    "# algo = PPOConfig().environment(\"your_env\").framework(\"torch\").build()\n",
    "\n",
    "num_iterations = 100  # Set your desired number of iterations\n",
    "checkpoint_freq = 10   # How often to save checkpoints\n",
    "evaluation_freq = 5    # How often to evaluate\n",
    "\n",
    "# Stopping criteria\n",
    "max_episodes = 1000    \n",
    "max_timesteps = 100000  \n",
    "reward_threshold = 200  \n",
    "moving_average_window = 10  \n",
    "patience = 10  \n",
    "min_reward_improvement = 1e-3  \n",
    "\n",
    "# Tracking variables\n",
    "total_episodes, total_timesteps, no_improvement_steps = 0, 0, 0\n",
    "best_moving_average_reward = -np.inf  \n",
    "reward_history = deque(maxlen=moving_average_window)  # Efficient sliding window\n",
    "\n",
    "def should_stop_early(moving_average_reward):\n",
    "    \"\"\"Check all stopping criteria.\"\"\"\n",
    "    if total_episodes >= max_episodes:\n",
    "        print(f\"Stopping due to max_episodes: {total_episodes}\")\n",
    "        return True\n",
    "    if total_timesteps >= max_timesteps:\n",
    "        print(f\"Stopping due to max_timesteps: {total_timesteps}\")\n",
    "        return True\n",
    "    if moving_average_reward >= reward_threshold:\n",
    "        print(f\"Stopping due to reward threshold: {moving_average_reward}\")\n",
    "        return True\n",
    "    if no_improvement_steps >= patience:\n",
    "        print(f\"Stopping due to lack of improvement for {patience} iterations.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Run one iteration of training\n",
    "    results = algo.train()\n",
    "    \n",
    "    # Update tracking variables\n",
    "    total_episodes += results['episodes_this_iter']\n",
    "    total_timesteps += results['timesteps_this_iter']\n",
    "    \n",
    "    # Track and compute moving average reward\n",
    "    \n",
    "    reward_history.append(results['episode_reward_mean'])\n",
    "    moving_average_reward = np.mean(reward_history)\n",
    "\n",
    "    # Log important metrics to Wandb\n",
    "    if use_wandb:\n",
    "        wandb.log({\n",
    "            \"iteration\": i,\n",
    "            \"moving_average_reward\": moving_average_reward,\n",
    "            \"episode_reward_mean\": results['episode_reward_mean'],\n",
    "            \"total_episodes\": total_episodes,\n",
    "            \"total_timesteps\": total_timesteps\n",
    "        })\n",
    "\n",
    "    # Print iteration summary\n",
    "    print(f\"Iteration {i}: reward_mean = {results['episode_reward_mean']}, \"\n",
    "          f\"moving_average_reward = {moving_average_reward}, \"\n",
    "          f\"total_episodes = {total_episodes}, total_timesteps = {total_timesteps}\")\n",
    "\n",
    "    # Save a checkpoint at intervals\n",
    "    if i % checkpoint_freq == 0:\n",
    "        checkpoint = algo.save(checkpoint_dir=\"checkpoints\")\n",
    "        print(f\"Checkpoint saved at iteration {i}: {checkpoint}\")\n",
    "\n",
    "    # Evaluate at intervals\n",
    "    if i % evaluation_freq == 0:\n",
    "        eval_results = algo.evaluate()\n",
    "        if use_wandb:\n",
    "            wandb.log(eval_results)\n",
    "        print(f\"Evaluation results at iteration {i}: {eval_results}\")\n",
    "\n",
    "    # Check if moving average reward has improved\n",
    "    if moving_average_reward > best_moving_average_reward + min_reward_improvement:\n",
    "        best_moving_average_reward = moving_average_reward\n",
    "        no_improvement_steps = 0  # Reset patience counter\n",
    "    else:\n",
    "        no_improvement_steps += 1  # Increment patience counter\n",
    "\n",
    "    # Check stopping conditions\n",
    "    if should_stop_early(moving_average_reward):\n",
    "        break\n",
    "        wandb.log({\"termination_reason\": term})\n",
    "\n",
    "\n",
    "# Finish the Wandb run (optional)\n",
    "if use_wandb:\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<class 'ray.rllib.algorithms.ppo.ppo.PPO'>\n"
     ]
    }
   ],
   "source": [
    "from ray.tune import Trainable, Tuner\n",
    "from ray.tune.registry import register_trainable\n",
    "\n",
    "print(issubclass(type(\"string\"), Trainable))\n",
    "print(issubclass(type(resto_algo), Trainable))\n",
    "print(type(resto_algo))\n",
    "resto_algo.config = resto_algo.config\n",
    "register_trainable(\"cloned_algo\", lambda _: resto_algo)\n",
    "test_tuner = Tuner(\"cloned_algo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_trainable_cls('PPO')=<class 'ray.rllib.algorithms.ppo.ppo.PPO'>\n",
      "get_trainable_cls('cloned_algo')=<class '__main__.ClonedClass'>\n"
     ]
    }
   ],
   "source": [
    "from ray.tune import Trainable, Tuner\n",
    "from ray.tune.registry import register_trainable, validate_trainable\n",
    "\n",
    "class ClonedClass(type(resto_algo)):  # Inheriting from the type of resto_algo object\n",
    "    def __new__(cls):\n",
    "        # Create the instance of the class\n",
    "        #instance = super(ClonedClass, cls).__new__(cls)\n",
    "        instance = resto_config.build()  # Initialize the config attribute here\n",
    "\n",
    "        #checkpoint_path = \"/root/ray_results/PPO_2024-10-20_17-36-00/PPO_2_agent_waterworld_c5957_00000_0_2024-10-20_17-36-00/checkpoint_000000\"\n",
    "        #pols = glob(checkpoint_path+\"/policies/*\")\n",
    "        #specs = {path.basename(p) : Policy.from_checkpoint(p) for p in pols}\n",
    "        #instance.get_policy(\"pursuer_0\").set_weights(specs[\"pursuer_0\"].get_weights())\n",
    "        #instance.get_policy(\"pursuer_1\").set_weights(specs[\"pursuer_1\"].get_weights())\n",
    "\n",
    "        return instance\n",
    "\n",
    "register_trainable(\"cloned_algo\", ClonedClass)\n",
    "validate_trainable('cloned_algo')\n",
    "\n",
    "print(f\"{get_trainable_cls('PPO')=}\")\n",
    "print(f\"{get_trainable_cls('cloned_algo')=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_trainable_cls('PPO')\n",
    "b = get_trainable_cls('PPO')\n",
    "\n",
    "a is b\n",
    "\n",
    "#resto_algo = resto_config.build()\n",
    "#for test_id in range(num_test_agents):\n",
    "#    train_id = np.random.randint(num_trained_agents)\n",
    "#    resto_algo.get_policy(f\"pursuer_{test_id}\").set_weights(specs[f\"pursuer_{train_id}\"].get_weights())\n",
    "\n",
    "#resto_algo.get_policy(\"pursuer_0\").set_weights(specs[\"pursuer_0\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_1\").set_weights(specs[\"pursuer_1\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_0\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:13:15,041\tINFO worker.py:1619 -- Calling ray.init() again after it has already been called.\n",
      "2024-10-20 21:13:15,060\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-10-20 21:13:15,061\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 21:13:15,067\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-10-20 21:13:19,014\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-10-20 21:13:19,114\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tracked actor is not managed by this event manager: <TrackedActor 70630161317072633402302813275770675611>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/tune.py:994\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 994\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/execution/tune_controller.py:685\u001b[0m, in \u001b[0;36mTuneController.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnum_live_actors:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:225\u001b[0m, in \u001b[0;36mRayActorManager.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_ready_resource_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Ready resource futures don't count as one event as they don't trigger\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# any callbacks. So we repeat until we hit anything that is not a resource\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# future.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:310\u001b[0m, in \u001b[0;36mRayActorManager._handle_ready_resource_future\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# We handle resource futures one by one, so only try to start 1 actor at a time\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_start_actors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_actors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:352\u001b[0m, in \u001b[0;36mRayActorManager._try_start_actors\u001b[0;34m(self, max_actors)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(actor_cls, ray\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mActorClass):\n\u001b[0;32m--> 352\u001b[0m     actor_cls \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactor_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# Associate to acquired resources\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/_private/worker.py:3499\u001b[0m, in \u001b[0;36mremote\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _make_remote(args[\u001b[38;5;241m0\u001b[39m], {})\n\u001b[0;32m-> 3499\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, ray_option_utils\u001b[38;5;241m.\u001b[39mremote_args_error_string\n\u001b[1;32m   3500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m functools\u001b[38;5;241m.\u001b[39mpartial(_make_remote, options\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The @ray.remote decorator must be applied either with no arguments and no parentheses, for example '@ray.remote', or it must be applied using some of the arguments in the list ['max_calls', 'max_retries', 'num_cpus', 'num_returns', 'object_store_memory', 'retry_exceptions', '_generator_backpressure_num_objects', 'concurrency_groups', 'lifetime', 'max_concurrency', 'max_restarts', 'max_task_retries', 'max_pending_calls', 'namespace', 'get_if_exists', 'accelerator_type', 'memory', 'name', 'num_gpus', 'placement_group', 'placement_group_bundle_index', 'placement_group_capture_child_tasks', 'resources', 'runtime_env', 'scheduling_strategy', '_metadata', 'enable_task_events'], for example '@ray.remote(num_returns=2, resources={\"CustomResource\": 1})'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaterworld\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m register_env(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_agents\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_agent_env\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m _: ParallelPettingZooEnv(waterworld_v4\u001b[38;5;241m.\u001b[39mparallel_env(n_pursuers\u001b[38;5;241m=\u001b[39mnum_agents)))\n\u001b[0;32m---> 14\u001b[0m \u001b[43mrun_rllib_example_script_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#base_config,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresto_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#stop=stopper,\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcloned_algo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#trainable=resto_algo\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/rllib/utils/test_utils.py:1521\u001b[0m, in \u001b[0;36mrun_rllib_example_script_experiment\u001b[0;34m(base_config, args, stop, success_metric, trainable, tune_callbacks, keep_config, scheduler, progress_reporter)\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Run the actual experiment (using Tune).\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1504\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_at_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_reporter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_reporter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTuneConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m   1524\u001b[0m ray\u001b[38;5;241m.\u001b[39mshutdown()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/tuner.py:377\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes hyperparameter tuning job as configured and returns result.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03mFailure handling:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    RayTaskError: If user-provided trainable raises an exception\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_ray_client:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     (\n\u001b[1;32m    380\u001b[0m         progress_reporter,\n\u001b[1;32m    381\u001b[0m         string_queue,\n\u001b[1;32m    382\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_remote_tuner_for_jupyter_progress_reporting()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/impl/tuner_internal.py:476\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m param_space \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_space)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_restored:\n\u001b[0;32m--> 476\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resume(trainable, param_space)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/impl/tuner_internal.py:592\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fitting for a fresh Tuner.\"\"\"\u001b[39;00m\n\u001b[1;32m    580\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuner_kwargs,\n\u001b[1;32m    591\u001b[0m }\n\u001b[0;32m--> 592\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_remote_string_queue()\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/tune.py:1001\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m    999\u001b[0m             _report_air_progress(runner, air_progress_reporter)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m tune_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tune_start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/execution/tune_controller.py:1975\u001b[0m, in \u001b[0;36mTuneController.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cleanup_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1976\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_experiment_callbacks()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/execution/tune_controller.py:792\u001b[0m, in \u001b[0;36mTuneController._cleanup_trials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_to_trial[tracked_actor]\n\u001b[1;32m    788\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScheduling trial stop at end of experiment (trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtracked_actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m     )\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_trial_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# Clean up cached actors now\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cleanup_cached_actors(force_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/execution/tune_controller.py:1403\u001b[0m, in \u001b[0;36mTuneController._schedule_trial_stop\u001b[0;34m(self, trial, exception)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_to_trial\u001b[38;5;241m.\u001b[39mpop(tracked_actor)\n\u001b[1;32m   1401\u001b[0m trial\u001b[38;5;241m.\u001b[39mset_ray_actor(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1403\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remove_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracked_actor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/tune/execution/tune_controller.py:811\u001b[0m, in \u001b[0;36mTuneController._remove_actor\u001b[0;34m(self, tracked_actor)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_remove_actor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tracked_actor: TrackedActor):\n\u001b[0;32m--> 811\u001b[0m     stop_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_actor_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m     now \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mremove_actor(\n\u001b[1;32m    817\u001b[0m         tracked_actor, kill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stop_future\u001b[38;5;241m=\u001b[39mstop_future\n\u001b[1;32m    818\u001b[0m     ):\n\u001b[1;32m    819\u001b[0m         \u001b[38;5;66;03m# If the actor was previously alive, track\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/air/execution/_internal/actor_manager.py:726\u001b[0m, in \u001b[0;36mRayActorManager.schedule_actor_task\u001b[0;34m(self, tracked_actor, method_name, args, kwargs, on_result, on_error, _return_future)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracked_actor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_live_actors_to_ray_actors_resources:\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;66;03m# Actor is not started, yet\u001b[39;00m\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracked_actor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_actors_to_attrs:\n\u001b[0;32m--> 726\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    727\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracked actor is not managed by this event manager: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    728\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtracked_actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    729\u001b[0m         )\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# Cache tasks for future execution\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pending_actors_to_enqueued_actor_tasks[tracked_actor]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    733\u001b[0m         (tracked_actor_task, method_name, args, kwargs)\n\u001b[1;32m    734\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Tracked actor is not managed by this event manager: <TrackedActor 70630161317072633402302813275770675611>"
     ]
    }
   ],
   "source": [
    "parser = add_rllib_example_script_args(\n",
    "    default_iters=10,\n",
    "    default_timesteps=1000000,\n",
    "    default_reward=300,\n",
    ")\n",
    "args = parser.parse_args(args=[])\n",
    "#args.checkpoint_at_end = True\n",
    "#args.num_samples = 2\n",
    "args.num_agents = 2\n",
    "env = 'waterworld'\n",
    "\n",
    "register_env(f\"{num_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=num_agents)))\n",
    "\n",
    "run_rllib_example_script_experiment(\n",
    "    #base_config,\n",
    "    resto_config,\n",
    "    args=args,\n",
    "    #stop=stopper,\n",
    "    trainable=\"cloned_algo\"\n",
    "    #trainable=resto_algo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "2024-10-21 00:41:17,212\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:555: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-10-21 00:41:18,557\tWARNING services.py:2022 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67059712 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-10-21 00:41:18,661\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267 \u001b[39m\u001b[22m\n",
      "2024-10-21 00:41:23,148\tWARNING algorithm_config.py:4225 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-10-21 00:41:23,226\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
      "2024-10-21 00:41:30,208\tWARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "from os import path\n",
    "\n",
    "import ray\n",
    "from ray.tune import Trainable, Tuner\n",
    "from ray.tune.registry import register_trainable, validate_trainable\n",
    "from ray.rllib.core.rl_module.marl_module import MultiAgentRLModuleSpec\n",
    "from ray.rllib.core.rl_module.rl_module import RLModuleSpec\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "\n",
    "from pettingzoo.sisl import waterworld_v4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = add_rllib_example_script_args(\n",
    "    default_iters=10,\n",
    "    default_timesteps=1000000,\n",
    "    default_reward=300,\n",
    ")\n",
    "args = parser.parse_args(args=[])\n",
    "args.num_env_runners = 10\n",
    "#env = 'waterworld'\n",
    "args.num_agents = 2\n",
    "args.test_agents = 2\n",
    "\n",
    "\n",
    "checkpoint_path = \"/root/ray_results/PPO_2024-10-20_17-36-00/PPO_2_agent_waterworld_c5957_00000_0_2024-10-20_17-36-00/checkpoint_000000\"\n",
    "pols = glob(checkpoint_path+\"/policies/*\")\n",
    "specs = {path.basename(p) : Policy.from_checkpoint(p) for p in pols}\n",
    "\n",
    "register_env(f\"{args.num_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=args.num_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(args.num_agents)}\n",
    "\n",
    "\n",
    "resto_config = (\n",
    "    get_trainable_cls(\"PPO\")\n",
    "    .get_default_config()\n",
    "    .environment(f\"{args.num_agents}_agent_env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .rl_module(\n",
    "        rl_module_spec=MultiAgentRLModuleSpec(\n",
    "            module_specs={p: RLModuleSpec() for p in policies},\n",
    "        ),\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "    )\n",
    ")\n",
    "resto_algo = resto_config.build()\n",
    "for test_id in range(args.test_agents):\n",
    "    train_id = np.random.randint(args.num_agents)\n",
    "    resto_algo.get_policy(f\"pursuer_{test_id}\").set_weights(specs[f\"pursuer_{train_id}\"].get_weights())\n",
    "\n",
    "#resto_algo.evaluate()\n",
    "\n",
    "#register_trainable(\"cloned_algo\", lambda _: resto_algo)\n",
    "#run_rllib_example_script_experiment(\n",
    "#    resto_config,\n",
    "#    args=args,\n",
    "#    trainable=\"cloned_algo\"\n",
    "#)\n",
    "\n",
    "results = resto_algo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'env_runners': {'episode_reward_max': np.float64(-131.68730216240365),\n",
       "   'episode_reward_min': np.float64(-266.73560437749757),\n",
       "   'episode_reward_mean': np.float64(-208.95588420336244),\n",
       "   'episode_len_mean': np.float64(500.0),\n",
       "   'episode_media': {},\n",
       "   'episodes_timesteps_total': 5000,\n",
       "   'policy_reward_min': {'pursuer_0': np.float64(-90.66629220461637),\n",
       "    'pursuer_1': np.float64(-203.62428448947136)},\n",
       "   'policy_reward_max': {'pursuer_0': np.float64(10.859818810065214),\n",
       "    'pursuer_1': np.float64(-124.92327822959729)},\n",
       "   'policy_reward_mean': {'pursuer_0': np.float64(-47.40599192993528),\n",
       "    'pursuer_1': np.float64(-161.54989227342708)},\n",
       "   'custom_metrics': {},\n",
       "   'hist_stats': {'episode_reward': [np.float64(-256.2627302966058),\n",
       "     np.float64(-248.82995988943728),\n",
       "     np.float64(-177.90856596823969),\n",
       "     np.float64(-266.73560437749757),\n",
       "     np.float64(-131.68730216240365),\n",
       "     np.float64(-224.42221752494717),\n",
       "     np.float64(-136.19221133120277),\n",
       "     np.float64(-190.24784274850597),\n",
       "     np.float64(-254.85813980421963),\n",
       "     np.float64(-202.41426793056448)],\n",
       "    'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "    'policy_pursuer_0_reward': [np.float64(-83.32569900480141),\n",
       "     np.float64(-90.66629220461637),\n",
       "     np.float64(-49.94818645945657),\n",
       "     np.float64(-88.81637391735867),\n",
       "     np.float64(10.859818810065214),\n",
       "     np.float64(-70.82152857282011),\n",
       "     np.float64(-11.26893310160539),\n",
       "     np.float64(9.802863255772037),\n",
       "     np.float64(-51.23385531474835),\n",
       "     np.float64(-48.641732789783184)],\n",
       "    'policy_pursuer_1_reward': [np.float64(-172.9370312918043),\n",
       "     np.float64(-158.16366768482092),\n",
       "     np.float64(-127.96037950878308),\n",
       "     np.float64(-177.91923046013892),\n",
       "     np.float64(-142.54712097246906),\n",
       "     np.float64(-153.6006889521265),\n",
       "     np.float64(-124.92327822959729),\n",
       "     np.float64(-200.05070600427788),\n",
       "     np.float64(-203.62428448947136),\n",
       "     np.float64(-153.77253514078134)]},\n",
       "   'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.34581296707577425),\n",
       "    'mean_inference_ms': np.float64(1.3272717484853858),\n",
       "    'mean_action_processing_ms': np.float64(0.188024681440665),\n",
       "    'mean_env_wait_ms': np.float64(1.6913584675032767),\n",
       "    'mean_env_render_ms': np.float64(0.0)},\n",
       "   'num_faulty_episodes': 0,\n",
       "   'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.005033016204833984),\n",
       "    'StateBufferConnector_ms': np.float64(0.002328157424926758),\n",
       "    'ViewRequirementAgentConnector_ms': np.float64(0.058057308197021484)},\n",
       "   'num_episodes': 10,\n",
       "   'episode_return_max': np.float64(-131.68730216240365),\n",
       "   'episode_return_min': np.float64(-266.73560437749757),\n",
       "   'episode_return_mean': np.float64(-208.95588420336244),\n",
       "   'episodes_this_iter': 10},\n",
       "  'num_agent_steps_sampled_this_iter': 10000,\n",
       "  'num_env_steps_sampled_this_iter': 5000,\n",
       "  'timesteps_this_iter': 5000,\n",
       "  'num_healthy_workers': 0,\n",
       "  'num_in_flight_async_reqs': 0,\n",
       "  'num_remote_worker_restarts': 0},\n",
       " 'custom_metrics': {},\n",
       " 'episode_media': {},\n",
       " 'info': {'learner': {'pursuer_1': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(23.325788),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(10.094938150048256),\n",
       "     'policy_loss': np.float64(0.20909077483714403),\n",
       "     'vf_loss': np.float64(8.744362220168114),\n",
       "     'vf_explained_var': np.float64(-0.02377051847676436),\n",
       "     'kl': np.float64(5.707425774711495),\n",
       "     'entropy': np.float64(5.746665870770812),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_0': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(22.170527),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(8.749413944284122),\n",
       "     'policy_loss': np.float64(0.19690287743578666),\n",
       "     'vf_loss': np.float64(7.3891978278756145),\n",
       "     'vf_explained_var': np.float64(0.07173154248545567),\n",
       "     'kl': np.float64(5.816566243224467),\n",
       "     'entropy': np.float64(5.890406196936965),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}},\n",
       "  'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 8000,\n",
       "  'num_agent_steps_trained': 8000,\n",
       "  'num_env_steps_sampled_for_evaluation_this_iter': 5000},\n",
       " 'env_runners': {'episode_reward_max': np.float64(-167.35909412924005),\n",
       "  'episode_reward_min': np.float64(-328.8138988261868),\n",
       "  'episode_reward_mean': np.float64(-234.5663631454904),\n",
       "  'episode_len_mean': np.float64(500.0),\n",
       "  'episode_media': {},\n",
       "  'episodes_timesteps_total': 4000,\n",
       "  'policy_reward_min': {'pursuer_0': np.float64(-113.88336367008858),\n",
       "   'pursuer_1': np.float64(-215.10146837525366)},\n",
       "  'policy_reward_max': {'pursuer_0': np.float64(-8.49787659674868),\n",
       "   'pursuer_1': np.float64(-135.01186609071374)},\n",
       "  'policy_reward_mean': {'pursuer_0': np.float64(-61.520532179901565),\n",
       "   'pursuer_1': np.float64(-173.04583096558875)},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [np.float64(-328.8138988261868),\n",
       "    np.float64(-282.7044218727104),\n",
       "    np.float64(-181.72675877713442),\n",
       "    np.float64(-186.0888857873663),\n",
       "    np.float64(-307.15619549520403),\n",
       "    np.float64(-167.35909412924005),\n",
       "    np.float64(-177.2059853981688),\n",
       "    np.float64(-245.47566487791244)],\n",
       "   'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500],\n",
       "   'policy_pursuer_0_reward': [np.float64(-113.88336367008858),\n",
       "    np.float64(-110.40144551286174),\n",
       "    np.float64(-8.49787659674868),\n",
       "    np.float64(-51.0770196966526),\n",
       "    np.float64(-92.05472711995037),\n",
       "    np.float64(-28.761219200368007),\n",
       "    np.float64(-38.67587356321842),\n",
       "    np.float64(-48.81273207932417)],\n",
       "   'policy_pursuer_1_reward': [np.float64(-214.9305351560978),\n",
       "    np.float64(-172.3029763598484),\n",
       "    np.float64(-173.22888218038585),\n",
       "    np.float64(-135.01186609071374),\n",
       "    np.float64(-215.10146837525366),\n",
       "    np.float64(-138.59787492887207),\n",
       "    np.float64(-138.53011183495028),\n",
       "    np.float64(-196.66293279858814)]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.3753567504501534),\n",
       "   'mean_inference_ms': np.float64(1.272018285824739),\n",
       "   'mean_action_processing_ms': np.float64(0.18326632086483613),\n",
       "   'mean_env_wait_ms': np.float64(1.6154475595759248),\n",
       "   'mean_env_render_ms': np.float64(0.0)},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.004789233207702637),\n",
       "   'StateBufferConnector_ms': np.float64(0.0024557113647460938),\n",
       "   'ViewRequirementAgentConnector_ms': np.float64(0.056655704975128174)},\n",
       "  'num_episodes': 8,\n",
       "  'episode_return_max': np.float64(-167.35909412924005),\n",
       "  'episode_return_min': np.float64(-328.8138988261868),\n",
       "  'episode_return_mean': np.float64(-234.5663631454904),\n",
       "  'episodes_this_iter': 8},\n",
       " 'num_healthy_workers': 2,\n",
       " 'num_in_flight_async_sample_reqs': 0,\n",
       " 'num_remote_worker_restarts': 0,\n",
       " 'num_agent_steps_sampled': 8000,\n",
       " 'num_agent_steps_trained': 8000,\n",
       " 'num_env_steps_sampled': 4000,\n",
       " 'num_env_steps_trained': 4000,\n",
       " 'num_env_steps_sampled_this_iter': 4000,\n",
       " 'num_env_steps_trained_this_iter': 4000,\n",
       " 'num_env_steps_sampled_throughput_per_sec': 86.05917838584853,\n",
       " 'num_env_steps_trained_throughput_per_sec': 86.05917838584853,\n",
       " 'timesteps_total': 4000,\n",
       " 'num_env_steps_sampled_lifetime': 4000,\n",
       " 'num_agent_steps_sampled_lifetime': 8000,\n",
       " 'num_steps_trained_this_iter': 4000,\n",
       " 'agent_timesteps_total': 8000,\n",
       " 'timers': {'training_iteration_time_ms': 46479.658,\n",
       "  'restore_workers_time_ms': 0.023,\n",
       "  'training_step_time_ms': 46479.59,\n",
       "  'sample_time_ms': 6969.376,\n",
       "  'learn_time_ms': 39500.175,\n",
       "  'learn_throughput': 101.265,\n",
       "  'synch_weights_time_ms': 9.66,\n",
       "  'restore_eval_workers_time_ms': 0.011,\n",
       "  'evaluation_iteration_time_ms': 17837.811,\n",
       "  'evaluation_iteration_throughput': 280.303},\n",
       " 'counters': {'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 8000,\n",
       "  'num_agent_steps_trained': 8000,\n",
       "  'num_env_steps_sampled_for_evaluation_this_iter': 5000},\n",
       " 'done': False,\n",
       " 'training_iteration': 1,\n",
       " 'trial_id': 'default',\n",
       " 'date': '2024-10-21_00-42-27',\n",
       " 'timestamp': 1729471347,\n",
       " 'time_this_iter_s': 64.32225203514099,\n",
       " 'time_total_s': 64.32225203514099,\n",
       " 'pid': 2878274,\n",
       " 'hostname': 'e-bgbfbjbn-sfks6-0',\n",
       " 'node_ip': '10.42.142.216',\n",
       " 'config': {'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'placement_strategy': 'PACK',\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_for_main_process': 1,\n",
       "  'eager_tracing': True,\n",
       "  'eager_max_retraces': 20,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'torch_compile_learner': False,\n",
       "  'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
       "  'torch_compile_learner_dynamo_backend': 'inductor',\n",
       "  'torch_compile_learner_dynamo_mode': None,\n",
       "  'torch_compile_worker': False,\n",
       "  'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
       "  'torch_compile_worker_dynamo_mode': None,\n",
       "  'torch_ddp_kwargs': {},\n",
       "  'torch_skip_nan_gradients': False,\n",
       "  'enable_rl_module_and_learner': False,\n",
       "  'enable_env_runner_and_connector_v2': False,\n",
       "  'env': '2_agent_env',\n",
       "  'env_config': {},\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  '_is_atari': None,\n",
       "  'disable_env_checking': False,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'action_mask_key': 'action_mask',\n",
       "  'env_runner_cls': None,\n",
       "  'num_env_runners': 2,\n",
       "  'num_envs_per_env_runner': 1,\n",
       "  'num_cpus_per_env_runner': 1,\n",
       "  'num_gpus_per_env_runner': 0,\n",
       "  'custom_resources_per_env_runner': {},\n",
       "  'validate_env_runners_after_construction': True,\n",
       "  'sample_timeout_s': 60.0,\n",
       "  '_env_to_module_connector': None,\n",
       "  'add_default_connectors_to_env_to_module_pipeline': True,\n",
       "  '_module_to_env_connector': None,\n",
       "  'add_default_connectors_to_module_to_env_pipeline': True,\n",
       "  'episode_lookback_horizon': 1,\n",
       "  'rollout_fragment_length': 'auto',\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'compress_observations': False,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'enable_tf1_exec_eagerly': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'update_worker_filter_stats': True,\n",
       "  'use_worker_filter_stats': True,\n",
       "  'enable_connectors': True,\n",
       "  'sampler_perf_stats_ema_coef': None,\n",
       "  'num_learners': 0,\n",
       "  'num_gpus_per_learner': 0,\n",
       "  'num_cpus_per_learner': 1,\n",
       "  'local_gpu_idx': 0,\n",
       "  'gamma': 0.99,\n",
       "  'lr': 5e-05,\n",
       "  'grad_clip': None,\n",
       "  'grad_clip_by': 'global_norm',\n",
       "  'train_batch_size_per_learner': None,\n",
       "  'train_batch_size': 4000,\n",
       "  'model': {'_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'fcnet_weights_initializer': None,\n",
       "   'fcnet_weights_initializer_config': None,\n",
       "   'fcnet_bias_initializer': None,\n",
       "   'fcnet_bias_initializer_config': None,\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'conv_kernel_initializer': None,\n",
       "   'conv_kernel_initializer_config': None,\n",
       "   'conv_bias_initializer': None,\n",
       "   'conv_bias_initializer_config': None,\n",
       "   'conv_transpose_kernel_initializer': None,\n",
       "   'conv_transpose_kernel_initializer_config': None,\n",
       "   'conv_transpose_bias_initializer': None,\n",
       "   'conv_transpose_bias_initializer_config': None,\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'post_fcnet_weights_initializer': None,\n",
       "   'post_fcnet_weights_initializer_config': None,\n",
       "   'post_fcnet_bias_initializer': None,\n",
       "   'post_fcnet_bias_initializer_config': None,\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   'lstm_weights_initializer': None,\n",
       "   'lstm_weights_initializer_config': None,\n",
       "   'lstm_bias_initializer': None,\n",
       "   'lstm_bias_initializer_config': None,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'encoder_latent_dim': None,\n",
       "   'always_check_shapes': False,\n",
       "   'lstm_use_prev_action_reward': -1,\n",
       "   '_use_default_native_models': -1},\n",
       "  '_learner_connector': None,\n",
       "  'add_default_connectors_to_learner_pipeline': True,\n",
       "  'learner_config_dict': {},\n",
       "  'optimizer': {},\n",
       "  'max_requests_in_flight_per_sampler_worker': 2,\n",
       "  '_learner_class': None,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'count_steps_by': 'env_steps',\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_mapping_fn': <function __main__.<lambda>(aid, *args, **kwargs)>,\n",
       "  'policies_to_train': None,\n",
       "  'policy_states_are_swappable': False,\n",
       "  'observation_fn': None,\n",
       "  'input_read_method': 'read_parquet',\n",
       "  'input_read_method_kwargs': {},\n",
       "  'input_read_schema': {},\n",
       "  'input_read_episodes': False,\n",
       "  'input_read_sample_batches': False,\n",
       "  'input_filesystem': None,\n",
       "  'input_filesystem_kwargs': {},\n",
       "  'input_compress_columns': ['obs', 'new_obs'],\n",
       "  'input_spaces_jsonable': True,\n",
       "  'map_batches_kwargs': {},\n",
       "  'iter_batches_kwargs': {},\n",
       "  'prelearner_class': None,\n",
       "  'prelearner_module_synch_period': 10,\n",
       "  'dataset_num_iters_per_learner': None,\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_config': {},\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'output_max_rows_per_file': None,\n",
       "  'output_write_method': 'write_parquet',\n",
       "  'output_write_method_kwargs': {},\n",
       "  'output_filesystem': None,\n",
       "  'output_filesystem_kwargs': {},\n",
       "  'output_write_episodes': True,\n",
       "  'offline_sampling': False,\n",
       "  'evaluation_interval': 1,\n",
       "  'evaluation_duration': 10,\n",
       "  'evaluation_duration_unit': 'episodes',\n",
       "  'evaluation_sample_timeout_s': 120.0,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'evaluation_force_reset_envs_before_iteration': True,\n",
       "  'evaluation_config': None,\n",
       "  'off_policy_estimation_methods': {},\n",
       "  'ope_split_batch_by_episode': True,\n",
       "  'evaluation_num_env_runners': 0,\n",
       "  'in_evaluation': False,\n",
       "  'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
       "  'keep_per_episode_custom_metrics': False,\n",
       "  'metrics_episode_collection_timeout_s': 60.0,\n",
       "  'metrics_num_episodes_for_smoothing': 100,\n",
       "  'min_time_s_per_iteration': None,\n",
       "  'min_train_timesteps_per_iteration': 0,\n",
       "  'min_sample_timesteps_per_iteration': 0,\n",
       "  'export_native_model_files': False,\n",
       "  'checkpoint_trainable_policies_only': False,\n",
       "  'logger_creator': None,\n",
       "  'logger_config': None,\n",
       "  'log_level': 'WARN',\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'seed': None,\n",
       "  '_run_training_always_in_thread': False,\n",
       "  '_evaluation_parallel_to_training_wo_thread': False,\n",
       "  'ignore_env_runner_failures': False,\n",
       "  'recreate_failed_env_runners': False,\n",
       "  'max_num_env_runner_restarts': 1000,\n",
       "  'delay_between_env_runner_restarts_s': 60.0,\n",
       "  'restart_failed_sub_environments': False,\n",
       "  'num_consecutive_env_runner_failures_tolerance': 100,\n",
       "  'env_runner_health_probe_timeout_s': 30,\n",
       "  'env_runner_restore_timeout_s': 1800,\n",
       "  '_model_config_dict': {},\n",
       "  '_rl_module_spec': MultiRLModuleSpec(multi_rl_module_class=<class 'ray.rllib.core.rl_module.multi_rl_module.MultiRLModule'>, inference_only=False, module_specs={'pursuer_1': RLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_0': RLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config_dict=None, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None, marl_module_class=<class 'ray.rllib.core.rl_module.multi_rl_module.MultiRLModule'>),\n",
       "  '_AlgorithmConfig__prior_exploration_config': None,\n",
       "  'algorithm_config_overrides_per_module': {},\n",
       "  '_per_module_overrides': {},\n",
       "  '_torch_grad_scaler_class': None,\n",
       "  '_torch_lr_scheduler_classes': None,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  '_disable_initialize_loss_from_dummy_batch': False,\n",
       "  '_dont_auto_sync_env_runner_states': False,\n",
       "  'simple_optimizer': True,\n",
       "  'policy_map_cache': -1,\n",
       "  'worker_cls': -1,\n",
       "  'synchronize_filters': -1,\n",
       "  'enable_async_evaluation': -1,\n",
       "  'custom_async_evaluation_function': -1,\n",
       "  '_enable_rl_module_api': -1,\n",
       "  'auto_wrap_old_gym_envs': -1,\n",
       "  'always_attach_evaluation_results': -1,\n",
       "  'replay_sequence_length': None,\n",
       "  '_disable_execution_plan_api': -1,\n",
       "  'lr_schedule': None,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'use_kl_loss': True,\n",
       "  'kl_coeff': 0.2,\n",
       "  'kl_target': 0.01,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'mini_batch_size_per_learner': None,\n",
       "  'num_sgd_iter': 30,\n",
       "  'shuffle_sequences': True,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'vf_share_layers': -1,\n",
       "  'lambda': 1.0,\n",
       "  'input': 'sampler',\n",
       "  'policies': {'pursuer_1': (None, None, None, None),\n",
       "   'pursuer_0': (None, None, None, None)},\n",
       "  'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       "  'create_env_on_driver': False,\n",
       "  'custom_eval_function': None,\n",
       "  'framework': 'torch'},\n",
       " 'time_since_restore': 64.32225203514099,\n",
       " 'iterations_since_restore': 1,\n",
       " 'perf': {'cpu_util_percent': np.float64(19.22065217391305),\n",
       "  'ram_util_percent': np.float64(15.998913043478263)}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results['training_iteration']=3\n",
      "results['env_runners']['num_episodes']=8\n",
      "results['env_runners']['episode_return_mean']=np.float64(-190.84602312225365)\n"
     ]
    }
   ],
   "source": [
    "results = resto_algo.train()\n",
    "print(f\"{results['training_iteration']=}\")\n",
    "print(f\"{results['env_runners']['num_episodes']=}\")\n",
    "print(f\"{results['env_runners']['episode_return_mean']=}\")\n",
    "# 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results['training_iteration']=4\n",
      "results['env_runners']['num_episodes']=8\n",
      "results['env_runners']['episode_return_mean']=np.float64(-191.70060061384294)\n",
      "results['env_runners']['episodes_timesteps_total']=16000\n"
     ]
    }
   ],
   "source": [
    "results = resto_algo.train()\n",
    "print(f\"{results['training_iteration']=}\")\n",
    "print(f\"{results['env_runners']['num_episodes']=}\")\n",
    "print(f\"{results['env_runners']['episode_return_mean']=}\")\n",
    "print(f\"{results['env_runners']['episodes_timesteps_total']=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# timesteps\n",
    "results['env_runners']['episodes_timesteps_total']\n",
    "\n",
    "\n",
    "#reward_history.append(results['episode_reward_mean'])\n",
    "#moving_average_reward = np.mean(reward_history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
