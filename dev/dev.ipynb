{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.17.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (59.6.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 KB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /root/.local/lib/python3.10/site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: platformdirs in /root/.local/lib/python3.10/site-packages (from wandb) (4.2.2)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 KB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.27.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /root/.local/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m817.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install ray[rllib,tune]\n",
    "#!pip install pettingzoo pygame pymunk\n",
    "#!pip install torch\n",
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-10 15:03:28,425\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-09-10 15:03:30,761\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.core.rl_module.marl_module import MultiAgentRLModuleSpec\n",
    "from ray.rllib.core.rl_module.rl_module import SingleAgentRLModuleSpec\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "\n",
    "from pettingzoo.sisl import waterworld_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment.  If you were attempting to deepcopy a module, this may be because of a torch.nn.utils.weight_norm usage, see https://github.com/pytorch/pytorch/pull/103001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m\n\u001b[1;32m     19\u001b[0m policies \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpursuer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_agents)}\n\u001b[1;32m     22\u001b[0m resto_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     23\u001b[0m     get_trainable_cls(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;241m.\u001b[39mget_default_config()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m resto_algo \u001b[38;5;241m=\u001b[39m \u001b[43mresto_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#resto_algo.get_policy(\"pursuer_0\").set_weights(specs[\"pursuer_0\"].get_weights())\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#resto_algo.get_policy(\"pursuer_1\").set_weights(specs[\"pursuer_1\"].get_weights())\u001b[39;00m\n\u001b[1;32m     48\u001b[0m resto_algo\u001b[38;5;241m.\u001b[39mget_policy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpursuer_0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mget_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm_config.py:867\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator, use_copy)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    864\u001b[0m     algo_class \u001b[38;5;241m=\u001b[39m get_trainable_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class)\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algo_class(\n\u001b[0;32m--> 867\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_copy \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    868\u001b[0m     logger_creator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger_creator,\n\u001b[1;32m    869\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "    \u001b[0;31m[... skipping similar frames: _deepcopy_dict at line 231 (1 times), deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "    \u001b[0;31m[... skipping similar frames: deepcopy at line 146 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[0;32m--> 206\u001b[0m     append(\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:87\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__deepcopy__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, memo)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly Tensors created explicitly by the user \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(graph leaves) support the deepcopy protocol at the moment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you were attempting to deepcopy a module, this may be because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof a torch.nn.utils.weight_norm usage, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msee https://github.com/pytorch/pytorch/pull/103001\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment.  If you were attempting to deepcopy a module, this may be because of a torch.nn.utils.weight_norm usage, see https://github.com/pytorch/pytorch/pull/103001"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from os import path\n",
    "import ray\n",
    "from ray.rllib.policy.policy import Policy\n",
    "\n",
    "ray.shutdown() \n",
    "\n",
    "# Trained to about 0 combined return\n",
    "checkpoint_path = \"/root/ray_results/PPO_2024-08-28_20-57-45/PPO_2_agent_env_2cf59_00000_0_2024-08-28_20-57-45/checkpoint_000000\"\n",
    "pols = glob(checkpoint_path+\"/policies/*\")\n",
    "specs = {path.basename(p) : Policy.from_checkpoint(p) for p in pols}\n",
    "#specs = {path.basename(p) : SingleAgentRLModuleSpec(load_state_path=p) for p in pols} # Non-deterministic policy weight return (implies new)\n",
    "\n",
    "\n",
    "num_agents = 2\n",
    "\n",
    "register_env(f\"{num_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=num_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(num_agents)}\n",
    "\n",
    "\n",
    "resto_config = (\n",
    "    get_trainable_cls(\"PPO\")\n",
    "    .get_default_config()\n",
    "    .environment(f\"{num_agents}_agent_env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .rl_module(\n",
    "        #model_config_dict={\"vf_share_layers\": True},\n",
    "        rl_module_spec=MultiAgentRLModuleSpec(\n",
    "            #load_state_path=\n",
    "            #module_specs=specs,\n",
    "            #module_specs={p: SingleAgentRLModuleSpec() for p in policies},\n",
    "            module_specs={p: Policy.from_checkpoint(pols[0]) for p in policies},\n",
    "        ),\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "resto_algo = resto_config.build()\n",
    "#resto_algo.get_policy(\"pursuer_0\").set_weights(specs[\"pursuer_0\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_1\").set_weights(specs[\"pursuer_1\"].get_weights())\n",
    "resto_algo.get_policy(\"pursuer_0\").get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_logits._model.0.weight': array([[-0.0057713 ,  0.02130763, -0.00332906, ..., -0.00251019,\n",
       "          0.01308718, -0.01480941],\n",
       "        [ 0.02027893, -0.00918621,  0.0372359 , ...,  0.00163348,\n",
       "          0.01085026,  0.00847802],\n",
       "        [-0.03894725,  0.07293524, -0.01994372, ...,  0.0666676 ,\n",
       "         -0.03469629, -0.02116322],\n",
       "        [ 0.00803491,  0.02462115, -0.01157856, ..., -0.0220483 ,\n",
       "         -0.02909413,  0.0477805 ]], dtype=float32),\n",
       " '_logits._model.0.bias': array([ 0.00049785,  0.00283682, -0.01044037, -0.01154366], dtype=float32),\n",
       " '_hidden_layers.0._model.0.weight': array([[-0.06341984, -0.01866287,  0.04820696, ..., -0.06329054,\n",
       "         -0.0094757 , -0.1880102 ],\n",
       "        [ 0.04908092, -0.02408476,  0.01319859, ...,  0.0380294 ,\n",
       "          0.11712942,  0.10649226],\n",
       "        [ 0.00440866, -0.02424742, -0.0211874 , ..., -0.00685773,\n",
       "          0.04866119, -0.04014146],\n",
       "        ...,\n",
       "        [ 0.05629121,  0.01958698, -0.01932536, ..., -0.06350598,\n",
       "          0.00073303,  0.02494574],\n",
       "        [ 0.05767507,  0.02367592, -0.1000184 , ..., -0.11080205,\n",
       "          0.0306826 , -0.03873601],\n",
       "        [ 0.02814285,  0.03304771, -0.09030563, ...,  0.03586492,\n",
       "          0.01803334, -0.01949282]], dtype=float32),\n",
       " '_hidden_layers.0._model.0.bias': array([-4.9215741e-03, -7.9965236e-04, -2.4410791e-03,  8.3407015e-03,\n",
       "         2.5819575e-03, -5.9175650e-03,  3.9655319e-03, -6.7910682e-03,\n",
       "        -7.5380644e-04,  4.2199772e-03,  2.0718735e-03,  2.5407004e-03,\n",
       "        -5.4690042e-03,  5.3602420e-03, -8.5677374e-03, -9.2091151e-03,\n",
       "        -5.7352977e-03, -8.4550452e-04,  3.7027923e-03, -4.0584356e-03,\n",
       "         4.9816691e-03,  8.9696562e-03,  8.3527286e-03, -6.1261132e-03,\n",
       "         5.4205512e-03,  9.8865060e-03, -1.0399016e-02,  2.7397119e-03,\n",
       "         4.7436361e-03, -3.3557618e-03,  2.9393870e-03, -1.3278585e-03,\n",
       "        -3.9261407e-03, -7.3005026e-03, -2.5783060e-03,  5.6719049e-03,\n",
       "        -1.2751970e-02,  2.0315130e-03, -5.5209566e-03, -4.3343924e-04,\n",
       "         2.6122809e-03, -1.6808164e-03,  9.3071739e-04,  6.9880101e-04,\n",
       "         1.9063377e-03, -1.9599102e-03,  1.4504656e-04,  8.4571550e-03,\n",
       "        -9.1759255e-03,  1.3203590e-04,  3.7308107e-03, -7.6364568e-03,\n",
       "        -5.3742947e-03,  5.3487602e-03,  5.0470135e-03, -2.1941641e-03,\n",
       "         4.5197131e-03,  5.4127183e-03,  6.3287566e-04, -9.9554770e-03,\n",
       "         2.7463054e-03,  9.1316234e-03,  4.4055730e-03,  4.8095430e-04,\n",
       "         3.5528291e-03,  6.7760097e-03, -5.8875280e-03, -1.9864729e-04,\n",
       "         5.6102136e-03, -1.1827166e-03,  4.0337571e-04, -3.9985552e-03,\n",
       "         3.3620661e-03,  2.8050370e-03, -6.5903459e-04,  8.4974598e-03,\n",
       "        -3.3536640e-03,  6.7684897e-03, -6.6895047e-03, -4.4209096e-03,\n",
       "        -4.0384452e-03, -5.2271625e-03, -8.6489815e-04,  4.3526744e-03,\n",
       "        -1.5154033e-02,  1.0036849e-02, -5.7738852e-03,  1.5471431e-03,\n",
       "         4.3985909e-03, -2.7652828e-03,  1.2129702e-02,  1.0046180e-02,\n",
       "         5.0983843e-03, -7.2724679e-03, -7.1640131e-03,  9.9235866e-03,\n",
       "         2.5125539e-03, -4.6541539e-04,  3.1848189e-03,  8.8275416e-04,\n",
       "        -6.1802804e-03,  2.9187303e-03,  4.0186830e-03, -8.9154448e-03,\n",
       "        -1.8736621e-03, -1.6149345e-03, -2.8330006e-03, -1.0474589e-02,\n",
       "         9.5108841e-03,  2.2977600e-03, -2.5169107e-03,  1.1776578e-02,\n",
       "        -4.5618797e-03,  3.0588498e-04, -2.6591753e-03, -6.4575137e-04,\n",
       "         2.2268115e-04, -2.6605166e-03,  1.2104529e-03, -6.7105476e-04,\n",
       "         7.9218550e-03,  9.9338088e-03, -4.3195388e-03, -8.3753197e-03,\n",
       "        -3.3879906e-03,  1.2543694e-03, -1.3198438e-03,  3.7802428e-03,\n",
       "        -4.0064944e-04,  1.0576708e-03,  4.5219925e-03,  3.2911068e-03,\n",
       "         6.8505673e-04, -1.5530059e-03,  3.3427032e-03, -2.3827814e-03,\n",
       "        -1.1705259e-03,  7.9276031e-03, -5.3756265e-03, -4.1489433e-03,\n",
       "        -9.1787409e-03, -4.5014676e-04, -8.7661762e-03,  6.9023934e-03,\n",
       "         1.8051646e-04,  6.6780695e-03, -3.6000062e-03, -5.1577948e-03,\n",
       "        -3.3317653e-03, -2.3510640e-03,  7.1135010e-03,  3.4507168e-03,\n",
       "        -1.9366671e-03, -4.5648676e-06,  4.8224319e-04,  8.4225554e-03,\n",
       "         2.3426574e-03, -1.2590097e-03,  1.8956030e-02,  4.4449833e-03,\n",
       "        -8.1024831e-03, -2.4914986e-03,  1.0293867e-03, -6.3438737e-03,\n",
       "         5.1028291e-03, -5.1667704e-03, -5.3620660e-03,  1.2200833e-03,\n",
       "         4.0453221e-03, -5.7939249e-03,  1.0953906e-03, -4.3215957e-03,\n",
       "        -6.8659522e-04,  3.5273675e-03, -2.9476173e-03,  2.9052696e-03,\n",
       "        -1.9109624e-03, -7.1653370e-03, -3.6732212e-03,  8.7197246e-03,\n",
       "         2.4582150e-03, -1.4793021e-03,  6.4889394e-04, -9.0748463e-03,\n",
       "         1.2644636e-03,  2.0964504e-03, -4.8619783e-03, -1.7664438e-03,\n",
       "         9.2152324e-05,  6.2957532e-03,  8.1428783e-03,  7.2709392e-03,\n",
       "        -1.2165843e-02,  2.3598000e-03,  4.3597552e-03,  1.1020376e-02,\n",
       "        -4.9264235e-03, -1.0092086e-02, -3.9806068e-03,  3.0257777e-04,\n",
       "        -3.3451691e-03, -2.1796445e-03, -5.1862011e-03, -5.5999756e-03,\n",
       "         6.7013726e-03, -4.7693746e-03, -8.7331859e-03,  1.2547286e-02,\n",
       "         1.5408835e-04, -1.7956800e-03, -1.0104898e-02,  4.8258323e-03,\n",
       "         5.8629732e-03, -2.6784653e-03,  3.7116827e-03, -1.7999882e-04,\n",
       "         6.4195436e-04, -9.8293822e-04,  6.4517854e-04,  4.9572578e-03,\n",
       "        -4.9804122e-04, -2.4375874e-04, -2.5525566e-03, -6.1881640e-03,\n",
       "         3.4258137e-05,  1.5054173e-03,  2.0825304e-03, -3.8640483e-04,\n",
       "         2.4520031e-03, -3.0114420e-03, -2.9144108e-03,  1.3093388e-03,\n",
       "        -2.3681950e-03, -2.7204845e-03,  4.2295670e-03,  1.5123185e-03,\n",
       "        -4.7613056e-03,  4.5374744e-03, -6.7227967e-03,  1.2252724e-03,\n",
       "        -4.1295430e-03, -7.8394526e-04, -1.4562532e-03,  8.6202075e-05,\n",
       "        -9.0148570e-03,  1.3717955e-03, -1.2362893e-03,  2.6005176e-03,\n",
       "         1.2509948e-02, -4.6894345e-03, -8.7176552e-03, -1.9968755e-03,\n",
       "        -7.5558233e-03, -1.0756257e-02,  6.1853486e-03,  2.2083875e-03],\n",
       "       dtype=float32),\n",
       " '_hidden_layers.1._model.0.weight': array([[-0.01419797, -0.12486223, -0.00886009, ..., -0.02681187,\n",
       "          0.00568813, -0.00070431],\n",
       "        [ 0.00858973,  0.01427813, -0.1839366 , ...,  0.00312674,\n",
       "          0.11305308, -0.01247808],\n",
       "        [-0.03847576, -0.08451046,  0.01350692, ...,  0.00575237,\n",
       "         -0.01126341, -0.03715782],\n",
       "        ...,\n",
       "        [ 0.06541324,  0.1559761 ,  0.06431769, ..., -0.03454493,\n",
       "         -0.0179561 ,  0.06414513],\n",
       "        [-0.05857896,  0.06287325, -0.00726445, ..., -0.09529498,\n",
       "         -0.03645266, -0.05787133],\n",
       "        [ 0.13874765, -0.10967673,  0.01516597, ..., -0.07411338,\n",
       "          0.13767652, -0.01762111]], dtype=float32),\n",
       " '_hidden_layers.1._model.0.bias': array([ 5.96611528e-03, -5.76855906e-04, -4.59683593e-03, -1.45714590e-03,\n",
       "        -7.55869178e-03,  1.00326100e-02, -1.78591337e-03,  6.73368061e-03,\n",
       "        -3.77278822e-03,  7.41181662e-04,  2.65748613e-03,  4.16512456e-04,\n",
       "        -1.59616547e-03,  1.71415100e-03, -5.23075694e-03, -1.77612307e-03,\n",
       "         7.35583855e-03, -1.09745853e-03,  5.04293479e-03,  2.58164038e-03,\n",
       "         2.45687412e-03, -4.00487287e-03,  8.41654371e-04, -1.00584887e-03,\n",
       "         2.30706250e-03, -6.99081938e-05,  9.42576677e-04,  8.06865934e-03,\n",
       "        -5.26900589e-03, -2.88849056e-04,  1.10928565e-02,  7.85285514e-03,\n",
       "        -2.32297136e-03,  1.18762872e-03,  6.04209816e-03, -4.39740391e-03,\n",
       "        -1.03426271e-03,  2.14495696e-03, -2.40828423e-03,  1.61782503e-02,\n",
       "        -6.62333984e-03, -1.27244452e-02, -3.06532718e-04,  3.40028899e-03,\n",
       "         1.58401504e-02, -4.69478918e-03,  8.73202272e-03, -8.07604846e-03,\n",
       "        -3.46625783e-03, -1.67459788e-04,  3.50534846e-03, -4.06955322e-03,\n",
       "         3.17642419e-03,  5.89969661e-03, -8.07978306e-03, -2.01826673e-02,\n",
       "        -3.78156314e-03, -3.12575442e-03, -3.42433364e-03,  7.48425769e-03,\n",
       "        -1.41151904e-05, -1.71756260e-02,  1.10869780e-02,  1.23244431e-03,\n",
       "         1.96174922e-04,  3.66872712e-03,  9.78782028e-03, -3.51770478e-03,\n",
       "         3.52498121e-03,  1.12680076e-02, -2.04273337e-03,  1.91302248e-03,\n",
       "        -9.34837572e-03, -2.31268746e-03,  1.07111584e-03,  8.64100643e-03,\n",
       "        -3.82899816e-05, -5.59639279e-03,  5.58635173e-03, -2.14619352e-03,\n",
       "        -2.16163485e-03, -2.76102714e-04,  1.68947142e-03,  9.54952743e-03,\n",
       "         8.56875069e-03,  7.31621403e-04,  4.56130365e-03, -1.59028487e-03,\n",
       "         3.57710198e-03,  7.44422025e-04,  5.35588618e-03,  3.38473311e-03,\n",
       "         1.15053300e-02, -4.25844360e-03,  1.68488862e-03, -3.30383750e-03,\n",
       "         3.11664073e-03,  1.16220806e-02, -8.04630667e-03,  1.40374964e-02,\n",
       "        -4.98975511e-04, -6.88665686e-03,  2.29330547e-03, -3.19676357e-04,\n",
       "        -8.63400381e-03, -7.61512900e-03,  8.35160725e-03,  1.85764779e-03,\n",
       "        -5.02078468e-03, -6.19360188e-04,  3.40268156e-03, -8.65096413e-03,\n",
       "         1.08707389e-02, -1.19427834e-02,  3.54797929e-04, -1.86375401e-03,\n",
       "        -1.92011602e-03, -2.16234545e-03, -2.94033601e-03,  1.53007684e-03,\n",
       "         1.17739020e-02, -3.49585389e-05, -3.07419011e-03, -6.73397444e-03,\n",
       "        -1.52760965e-03,  4.10519773e-03,  5.73435158e-04,  8.12295172e-03,\n",
       "        -5.09667164e-03,  5.78952115e-03, -2.39725225e-03, -8.71523842e-03,\n",
       "         7.69020710e-03, -3.76070122e-04,  9.68495850e-03,  6.10301504e-04,\n",
       "        -2.66626640e-03, -5.82826929e-03,  1.06024444e-02,  1.16860978e-02,\n",
       "         3.11539555e-03,  6.81164768e-03,  3.09729774e-04, -3.29445186e-03,\n",
       "        -4.48451983e-03, -1.32789393e-03,  1.59049104e-03,  2.55962904e-03,\n",
       "         6.19008578e-03,  1.06378431e-02,  6.21485291e-03, -6.74660038e-03,\n",
       "         2.13687448e-03, -3.98384919e-03,  1.84299436e-03,  3.46669724e-04,\n",
       "        -5.41885942e-03,  1.17429858e-02,  8.77584703e-03,  1.41411531e-03,\n",
       "         1.84947252e-03,  2.88689858e-04,  1.16133690e-02,  5.77970175e-03,\n",
       "        -2.27033946e-04, -2.20858841e-03, -1.97993987e-03,  2.40586861e-03,\n",
       "        -7.67981401e-03, -1.89263214e-04, -3.65916872e-03,  1.19949866e-03,\n",
       "         3.29373893e-03, -8.29509285e-04,  8.37699103e-04,  8.48740619e-03,\n",
       "        -1.03239287e-02,  9.84366145e-03,  1.15829809e-02,  5.09666186e-03,\n",
       "        -8.33827630e-03,  4.09874693e-03, -7.50868721e-03, -1.96655886e-03,\n",
       "        -1.31416763e-03,  5.00048697e-03, -2.87327426e-03, -1.36159910e-02,\n",
       "         5.92433522e-03, -1.36103695e-02,  3.88317858e-03,  8.38228688e-03,\n",
       "        -5.62498579e-03, -8.90260655e-03, -3.55811149e-04,  1.25406114e-02,\n",
       "         4.11608955e-03,  1.79491559e-04,  8.07579234e-03, -8.51192605e-03,\n",
       "         1.51429244e-03,  5.76576777e-03, -2.89966847e-04,  2.62681395e-03,\n",
       "         3.01184715e-04,  4.20235284e-03, -2.44504749e-03,  4.24479414e-03,\n",
       "        -4.53244476e-03, -4.08727350e-03, -7.61651341e-03,  1.53040164e-03,\n",
       "        -4.36132483e-04,  4.33138432e-03,  6.13777013e-03,  1.34385366e-03,\n",
       "         7.53864530e-04,  6.37923833e-03, -2.32840632e-03,  8.52599798e-04,\n",
       "        -9.07132868e-03,  4.96702362e-03,  7.25330506e-03,  1.00701768e-02,\n",
       "        -3.37843871e-04,  2.02261168e-03,  8.36737826e-03, -4.06535622e-03,\n",
       "         8.30084831e-03, -1.30080513e-03, -7.94754550e-03, -6.21039886e-03,\n",
       "        -1.52868289e-03,  1.34376809e-03, -3.39815556e-03,  2.13383045e-03,\n",
       "        -1.17406463e-02, -5.79015072e-03,  1.64820813e-03,  7.94670079e-03,\n",
       "         8.80266353e-03, -4.25690878e-03,  1.93305372e-04,  8.12825095e-03,\n",
       "         3.76156764e-03, -1.08832112e-02, -2.88135419e-03, -2.37888237e-03,\n",
       "         4.08063689e-03, -5.22716297e-03,  9.32747126e-03, -9.92594101e-03,\n",
       "        -2.14484427e-03, -8.50934163e-03,  1.00643132e-02,  2.25334777e-03],\n",
       "       dtype=float32),\n",
       " '_value_branch_separate.0._model.0.weight': array([[-0.04970036,  0.03203391,  0.00243363, ..., -0.06702767,\n",
       "         -0.12597966,  0.12103654],\n",
       "        [-0.12401084, -0.02051374,  0.05926413, ...,  0.0443644 ,\n",
       "          0.0133007 , -0.05439172],\n",
       "        [-0.02843739,  0.07499654, -0.03342893, ...,  0.0080643 ,\n",
       "         -0.12435565,  0.00427401],\n",
       "        ...,\n",
       "        [ 0.12807427,  0.01837508,  0.02018862, ..., -0.0514529 ,\n",
       "         -0.29573435, -0.09681422],\n",
       "        [ 0.08869156, -0.03710815,  0.20448565, ...,  0.0180778 ,\n",
       "          0.20351565, -0.10750779],\n",
       "        [-0.05637036, -0.07293333, -0.03156194, ...,  0.10288819,\n",
       "         -0.2955758 ,  0.06182278]], dtype=float32),\n",
       " '_value_branch_separate.0._model.0.bias': array([-0.0010297 , -0.00852578,  0.00840731, -0.00406268, -0.00499971,\n",
       "        -0.00130923,  0.0012036 ,  0.01300859,  0.01069793, -0.0054142 ,\n",
       "         0.00396203, -0.00302994,  0.00044154, -0.00879998,  0.00320336,\n",
       "         0.00323951, -0.01606052,  0.00695157, -0.00836208, -0.00547832,\n",
       "         0.01451502, -0.00267458,  0.00666413, -0.00637406,  0.00296296,\n",
       "        -0.00342759,  0.00046361,  0.00064746,  0.01322812,  0.00795913,\n",
       "         0.00802953, -0.00566066,  0.00421941,  0.00044057,  0.00717026,\n",
       "        -0.0052074 , -0.00021227,  0.00805288,  0.00884139, -0.00604825,\n",
       "         0.0035219 ,  0.0094638 , -0.00428554, -0.00165782,  0.01057032,\n",
       "         0.00396798,  0.02163752, -0.00354436,  0.01004389, -0.00344089,\n",
       "        -0.00722691,  0.00643427, -0.00405442, -0.00408284,  0.01141442,\n",
       "        -0.01200057,  0.00734671, -0.00168726, -0.00169027,  0.00094941,\n",
       "        -0.00554819,  0.00605509, -0.00045625,  0.00193306, -0.00014868,\n",
       "        -0.00648753, -0.00011278,  0.00263319, -0.00187391,  0.0099256 ,\n",
       "        -0.00286756, -0.00763068, -0.00898433,  0.00078709, -0.00385257,\n",
       "         0.00167723, -0.01235814,  0.00331029,  0.01149394,  0.00689055,\n",
       "        -0.00943056, -0.01100323, -0.01235725, -0.00195728,  0.00019799,\n",
       "         0.01160845,  0.0083557 , -0.00146513, -0.00969621, -0.00735722,\n",
       "         0.00252102,  0.00466229,  0.00112646, -0.00778371, -0.00022134,\n",
       "        -0.00884005,  0.00911994,  0.00136713,  0.00307578,  0.0071259 ,\n",
       "         0.00929253,  0.00166829,  0.01058448, -0.00024754,  0.00732977,\n",
       "         0.001108  , -0.0049492 ,  0.0054294 , -0.00062842, -0.00379291,\n",
       "         0.00720747,  0.00288305, -0.00146543, -0.00859149, -0.0083317 ,\n",
       "        -0.00706867,  0.00633601, -0.01014439,  0.00367313, -0.0030167 ,\n",
       "         0.00972833,  0.0008775 , -0.00576993,  0.00166002,  0.01222146,\n",
       "        -0.00310087,  0.0018407 ,  0.00182144,  0.00289183, -0.0092439 ,\n",
       "        -0.00995371,  0.00308712, -0.00299237,  0.00392276, -0.00422367,\n",
       "         0.00114275, -0.00966086, -0.00299619,  0.00050538, -0.00147799,\n",
       "         0.00207396, -0.00452284, -0.01703806,  0.00146503, -0.00732849,\n",
       "         0.00180093, -0.00182914, -0.00940056, -0.01067785,  0.00270051,\n",
       "         0.01260122, -0.00019225, -0.00246878,  0.00354375, -0.00056727,\n",
       "         0.00536013,  0.00115221, -0.00561405, -0.01397411,  0.00878822,\n",
       "         0.00017763,  0.00554326,  0.00312585,  0.00276149, -0.0028667 ,\n",
       "        -0.00783686,  0.01168928, -0.0019508 ,  0.00146498,  0.00787322,\n",
       "         0.01301087, -0.00127864, -0.00401893,  0.00183864,  0.00051559,\n",
       "         0.0103961 , -0.00699071,  0.00087868, -0.00992878,  0.0066347 ,\n",
       "        -0.00039348,  0.00187528, -0.00379433, -0.00036312,  0.00396534,\n",
       "        -0.00642555, -0.00246436,  0.00349093,  0.00433336, -0.00451706,\n",
       "         0.00398069, -0.00011469, -0.00211482,  0.0084324 , -0.00434367,\n",
       "         0.00838219,  0.00870765, -0.00177449, -0.00033412, -0.01077957,\n",
       "        -0.01560737, -0.00792194, -0.0149783 , -0.01514071, -0.000693  ,\n",
       "         0.0031766 , -0.000684  , -0.02231018, -0.00271035,  0.00685956,\n",
       "         0.00607167,  0.00712792,  0.00080275,  0.00074943, -0.00731311,\n",
       "         0.00332331,  0.00198254, -0.00471799, -0.01244231, -0.00858918,\n",
       "        -0.00344909,  0.0066731 ,  0.00465444, -0.01350829,  0.00253004,\n",
       "        -0.00211454,  0.01013362, -0.00179413,  0.00696708, -0.00233623,\n",
       "        -0.01076809,  0.00956486, -0.00852775,  0.00588326, -0.00687923,\n",
       "         0.00644134,  0.01405144,  0.00488838,  0.00171498,  0.01001802,\n",
       "         0.00216297, -0.00828313, -0.00688689, -0.00479712, -0.00318053,\n",
       "         0.00674059, -0.00067008, -0.00209929,  0.00138947, -0.00319238,\n",
       "         0.00493294, -0.00367873, -0.00570769,  0.00463654,  0.003082  ,\n",
       "         0.0147713 ], dtype=float32),\n",
       " '_value_branch_separate.1._model.0.weight': array([[ 0.11341242,  0.08716995, -0.06344729, ...,  0.05233669,\n",
       "         -0.18362823,  0.02336317],\n",
       "        [ 0.10005645,  0.06784332,  0.03034151, ..., -0.0227753 ,\n",
       "         -0.01229427, -0.06866226],\n",
       "        [ 0.12753579,  0.16951483, -0.16183662, ..., -0.09463967,\n",
       "         -0.01709697, -0.00039028],\n",
       "        ...,\n",
       "        [-0.08854911, -0.03754264,  0.04793702, ..., -0.06958213,\n",
       "         -0.04912792,  0.0291281 ],\n",
       "        [-0.1665807 , -0.03394984, -0.03100488, ..., -0.07425211,\n",
       "          0.04243387,  0.14282341],\n",
       "        [ 0.05781211, -0.16986232,  0.02373631, ...,  0.11714494,\n",
       "          0.09787598, -0.08373186]], dtype=float32),\n",
       " '_value_branch_separate.1._model.0.bias': array([ 1.83917247e-02, -1.36149619e-02,  5.69366664e-03,  3.32698645e-03,\n",
       "        -5.49690053e-03, -2.66673043e-02, -1.89405885e-02, -7.24653574e-03,\n",
       "         2.85876985e-03, -1.12694036e-03,  5.55469934e-03, -1.31472135e-02,\n",
       "        -1.19780470e-02,  2.00648103e-02, -2.86532212e-02, -6.39350293e-03,\n",
       "        -6.80475915e-03,  4.53639030e-03, -3.15486314e-03, -1.86809117e-03,\n",
       "         5.56976441e-03,  1.59810428e-02, -5.70418313e-03, -2.09201351e-02,\n",
       "        -1.87541563e-02, -8.86297610e-04, -2.94110067e-02,  4.55507456e-04,\n",
       "         2.79180449e-03,  3.29859438e-03,  1.56854000e-02, -8.86365771e-03,\n",
       "        -1.00039458e-03, -6.84447167e-03, -6.28631702e-03,  2.48845224e-03,\n",
       "        -2.44015437e-02, -2.67841425e-02, -6.80375332e-03,  1.42600713e-02,\n",
       "        -2.51439288e-02, -2.05777697e-02, -1.01484004e-02, -3.11026786e-04,\n",
       "        -1.74308605e-02, -6.08120067e-03,  3.12358439e-02, -4.25180234e-03,\n",
       "        -6.94517931e-03,  1.44485030e-02, -1.72435921e-02, -7.77855376e-03,\n",
       "        -3.75466887e-03, -9.88923293e-03, -1.36983646e-02, -4.91092587e-03,\n",
       "         9.28977598e-03, -2.85947528e-02, -1.98397245e-02,  2.61260965e-03,\n",
       "         1.23012085e-02, -5.56888990e-04, -5.65416366e-03, -1.65598113e-02,\n",
       "         1.50595009e-02,  1.72409117e-02, -5.62938303e-03,  4.13298700e-03,\n",
       "        -1.13364514e-02, -3.28048074e-04,  3.16801458e-03,  5.28352743e-04,\n",
       "        -5.53474575e-03,  3.69769968e-02,  2.01235041e-02,  2.81581376e-02,\n",
       "        -2.06387546e-02,  4.04673256e-03, -7.86217675e-03,  3.68101825e-03,\n",
       "        -5.29834826e-04,  1.06832432e-02,  1.72478482e-02, -1.09616760e-02,\n",
       "         1.75877381e-02,  6.44774060e-04,  2.09306178e-04, -1.26633029e-02,\n",
       "         3.45106749e-03, -2.27224771e-02, -7.37315509e-03, -9.57677793e-03,\n",
       "        -1.75516633e-03, -3.62847783e-02,  4.12855064e-03, -5.47849433e-03,\n",
       "         8.77382793e-03,  1.80660170e-02, -1.39645981e-02, -9.38950293e-03,\n",
       "        -6.71099965e-03, -1.95905776e-03, -6.05876558e-03,  6.95621781e-03,\n",
       "         2.13016197e-03,  4.88668028e-03,  1.38794528e-02, -2.75584683e-02,\n",
       "         2.32414361e-02,  2.25696689e-03, -1.92658808e-02, -3.00269704e-02,\n",
       "        -2.02525035e-02,  1.85527317e-02,  1.37196276e-02, -1.40309967e-02,\n",
       "        -1.42517220e-02, -7.03857047e-04, -1.50419706e-02,  5.65500231e-03,\n",
       "        -1.59192886e-02,  3.75211681e-03, -2.79593654e-03, -4.78360569e-03,\n",
       "        -3.78741464e-03,  2.24756077e-02, -2.73554903e-02,  3.35502322e-03,\n",
       "         1.30266082e-02, -3.01851728e-03, -5.58734220e-03,  6.64214778e-04,\n",
       "        -2.87574623e-03, -1.49302678e-02, -2.63644960e-02, -1.01035275e-02,\n",
       "        -2.59499308e-02,  1.43308006e-02,  1.93049069e-02,  1.73238181e-02,\n",
       "         4.92123887e-03, -1.01344865e-02, -1.93313360e-02, -5.32076741e-03,\n",
       "         3.45347379e-03,  1.40181854e-02, -2.11265944e-02, -2.19652499e-03,\n",
       "        -2.85258889e-02, -6.24373322e-03,  1.36956209e-04,  4.83896583e-03,\n",
       "        -1.97553318e-02, -2.33800393e-02, -1.23552354e-02,  1.69963781e-02,\n",
       "        -1.43900430e-02,  2.10716501e-02, -1.00222100e-02,  1.36076985e-02,\n",
       "        -1.69816297e-02, -8.69629002e-05,  7.23565277e-03, -5.58940321e-03,\n",
       "         2.16803215e-02, -4.97017847e-03, -1.00251846e-02,  2.62200320e-03,\n",
       "        -7.23797781e-03, -1.75426751e-02, -8.70757643e-03,  2.04810258e-02,\n",
       "        -4.63855965e-03,  4.69230162e-03,  3.41936410e-03, -1.37198977e-02,\n",
       "        -1.17255850e-02,  9.57384147e-03, -3.60641512e-03, -3.66260298e-02,\n",
       "        -3.97244329e-03,  1.00812856e-02,  3.91897839e-03,  3.82599770e-03,\n",
       "        -1.36469323e-02,  1.06421551e-02, -2.63078022e-03,  4.79093613e-03,\n",
       "         2.14642403e-03, -5.08898776e-03, -7.70621700e-03,  2.70997756e-04,\n",
       "        -2.62012612e-02, -2.06580991e-03, -2.11661987e-04,  2.10426114e-02,\n",
       "        -1.65745188e-02, -1.16886208e-02, -1.51587115e-03, -1.39020439e-02,\n",
       "         1.49001237e-02, -1.49046455e-03,  1.41456621e-02, -2.17592679e-02,\n",
       "        -5.02850115e-03,  9.31894127e-03, -2.72554848e-02, -6.89003197e-03,\n",
       "        -1.86259225e-02,  5.43540437e-03,  8.36206041e-03,  1.33735267e-02,\n",
       "        -3.88419256e-02, -2.60464307e-02,  2.42727958e-02,  2.11467072e-02,\n",
       "        -4.34266869e-03,  3.31167411e-03,  2.90701608e-03, -9.91424825e-03,\n",
       "         1.18218940e-02,  2.18369327e-02, -1.56094844e-03,  1.50163937e-02,\n",
       "        -2.92854533e-02,  7.18914717e-03,  2.33976599e-02,  1.99346431e-03,\n",
       "         7.23156519e-03, -9.25445464e-03,  2.14480776e-02, -1.98617019e-02,\n",
       "        -4.29213466e-03,  2.57133413e-02,  3.87445907e-03, -9.24794003e-03,\n",
       "         2.09915023e-02,  5.15318103e-03, -2.98643392e-02, -3.68958036e-03,\n",
       "        -2.65078489e-02, -2.65691280e-02, -9.46378056e-03, -2.94499770e-02,\n",
       "         2.68020644e-03, -1.74437538e-02, -6.41596690e-03,  3.60183138e-03,\n",
       "        -9.90363187e-04, -8.43373872e-03, -3.80091392e-03,  9.42771323e-03,\n",
       "        -8.83641373e-03, -1.30815031e-02, -5.49820811e-03,  1.28217852e-02],\n",
       "       dtype=float32),\n",
       " '_value_branch._model.0.weight': array([[-0.09685739,  0.10204422,  0.11382004, -0.12016171,  0.1879257 ,\n",
       "          0.09951178,  0.10325524,  0.12050769,  0.0956592 ,  0.11051001,\n",
       "         -0.12163546,  0.09477183, -0.12168957, -0.09488759,  0.09661108,\n",
       "          0.12156169,  0.12760012, -0.09287509, -0.11088078,  0.14327872,\n",
       "          0.1145133 , -0.09619763,  0.09689442,  0.09385432,  0.12525001,\n",
       "          0.10574875,  0.09873099,  0.09497759, -0.11035238, -0.09303454,\n",
       "          0.12295954, -0.12243055, -0.12541397,  0.12748022,  0.09774599,\n",
       "         -0.12213303,  0.09694438,  0.09608631,  0.09635255, -0.10911861,\n",
       "          0.09908074,  0.09432366, -0.12600142, -0.09972029, -0.12736513,\n",
       "         -0.11211174, -0.09514734,  0.11757316,  0.10018542, -0.10184382,\n",
       "         -0.10178859,  0.09816045, -0.1308878 , -0.09957751, -0.12599885,\n",
       "         -0.12994067, -0.0930857 ,  0.0954634 ,  0.12031533,  0.12296412,\n",
       "         -0.09304298,  0.11716642, -0.10327705, -0.13351755, -0.12576172,\n",
       "         -0.09778485,  0.1130378 ,  0.12515235,  0.0946253 , -0.08888732,\n",
       "          0.13284028,  0.11598621, -0.09612398, -0.09862149, -0.0982853 ,\n",
       "         -0.10014033,  0.09789253, -0.09670278,  0.09126233,  0.12469993,\n",
       "         -0.15661107,  0.1083665 , -0.09805214,  0.10745321, -0.09614501,\n",
       "         -0.1083281 ,  0.10105564,  0.0963931 , -0.16180405,  0.09738844,\n",
       "         -0.12404702,  0.09328256, -0.16514298,  0.09415328, -0.09432323,\n",
       "          0.09723281, -0.12799422, -0.09096902,  0.13229536, -0.11052245,\n",
       "          0.09667765, -0.12037994,  0.10032708, -0.11593886,  0.09917749,\n",
       "         -0.09225675, -0.09388541, -0.14716603, -0.09971527,  0.0916438 ,\n",
       "          0.09890755,  0.09747197,  0.09915451, -0.10045778, -0.12382446,\n",
       "         -0.12377475, -0.11824128, -0.09723979,  0.097005  , -0.11364949,\n",
       "         -0.09568013, -0.09642328,  0.08992667, -0.10917249, -0.11126029,\n",
       "         -0.09933977,  0.09924643, -0.09783559, -0.11439145, -0.11262877,\n",
       "          0.14036617,  0.12375462, -0.09724275,  0.09480543,  0.15616457,\n",
       "         -0.09328046,  0.09829656, -0.10160958, -0.09489747, -0.09886203,\n",
       "          0.10223646,  0.09433934, -0.11793679,  0.11709118,  0.10497491,\n",
       "         -0.09794281,  0.09964287, -0.09561935,  0.09728532,  0.13291009,\n",
       "         -0.11992565, -0.09627008,  0.09916302,  0.1002488 ,  0.09775931,\n",
       "         -0.09671386,  0.09936415,  0.12133887,  0.0934125 , -0.09608831,\n",
       "          0.09773172,  0.1274399 ,  0.12244686, -0.12104436, -0.09878192,\n",
       "          0.10890982,  0.0935517 , -0.09553151,  0.10010022,  0.09649426,\n",
       "          0.09624248, -0.08957305, -0.12201768, -0.09760268, -0.07038572,\n",
       "          0.0912165 ,  0.10187466,  0.0981763 ,  0.09910034,  0.09720149,\n",
       "         -0.10342839, -0.09560277, -0.09791899, -0.18800297,  0.09836881,\n",
       "         -0.09698343, -0.08763644, -0.09929045, -0.11313511,  0.08587165,\n",
       "         -0.11101194, -0.12209579,  0.09547919, -0.09600978, -0.09235878,\n",
       "         -0.09826187,  0.09500773,  0.0997613 ,  0.1070352 ,  0.10135145,\n",
       "         -0.10064498, -0.123394  , -0.09379527,  0.09180369,  0.09140099,\n",
       "          0.11559799,  0.09893335,  0.09528342,  0.09731776, -0.09769794,\n",
       "          0.09318442, -0.10523485,  0.09546892,  0.09479638, -0.09704197,\n",
       "         -0.09264503,  0.1095501 ,  0.1301942 ,  0.11389173,  0.09472876,\n",
       "         -0.09736084, -0.09747019,  0.10929353, -0.0990186 ,  0.09510524,\n",
       "         -0.09104326, -0.09646888, -0.12138402,  0.10693341, -0.08857139,\n",
       "         -0.0995316 ,  0.09742892,  0.09972417, -0.09662492,  0.14916362,\n",
       "          0.11451414, -0.09754356,  0.10391837,  0.09850677,  0.12448643,\n",
       "          0.09781878,  0.10033976,  0.09578694,  0.10092627, -0.09539241,\n",
       "          0.09980961, -0.12053497,  0.11823866, -0.10596152,  0.09905232,\n",
       "          0.10496774,  0.10488825,  0.09813692,  0.0960589 ,  0.09729555,\n",
       "         -0.13879882]], dtype=float32),\n",
       " '_value_branch._model.0.bias': array([-0.09462959], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs['pursuer_0'].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we restore an algo to its original size, and evaluate below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_runners': {'episode_reward_max': np.float64(104.48447046235398),\n",
       "  'episode_reward_min': np.float64(-49.97758701259906),\n",
       "  'episode_reward_mean': np.float64(34.31495169008534),\n",
       "  'episode_len_mean': np.float64(500.0),\n",
       "  'episode_media': {},\n",
       "  'episodes_timesteps_total': 5000,\n",
       "  'policy_reward_min': {'pursuer_0': np.float64(-27.80399612520721),\n",
       "   'pursuer_1': np.float64(-74.73581968384396)},\n",
       "  'policy_reward_max': {'pursuer_0': np.float64(108.50397211584374),\n",
       "   'pursuer_1': np.float64(66.59594375510522)},\n",
       "  'policy_reward_mean': {'pursuer_0': np.float64(32.97170784631929),\n",
       "   'pursuer_1': np.float64(1.3432438437660394)},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [np.float64(44.487376281462424),\n",
       "    np.float64(98.65380257932057),\n",
       "    np.float64(84.50964155764572),\n",
       "    np.float64(20.08502968193733),\n",
       "    np.float64(104.48447046235398),\n",
       "    np.float64(-38.577462399422544),\n",
       "    np.float64(-49.97758701259906),\n",
       "    np.float64(20.465628189378837),\n",
       "    np.float64(91.2633147856224),\n",
       "    np.float64(-32.24469722484628)],\n",
       "   'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "   'policy_pursuer_0_reward': [np.float64(40.07564281289912),\n",
       "    np.float64(53.608308921809055),\n",
       "    np.float64(70.12441925264447),\n",
       "    np.float64(-27.80399612520721),\n",
       "    np.float64(37.88852670724881),\n",
       "    np.float64(-4.464299391091167),\n",
       "    np.float64(4.619717553032),\n",
       "    np.float64(4.673664157016454),\n",
       "    np.float64(108.50397211584374),\n",
       "    np.float64(42.49112245899767)],\n",
       "   'policy_pursuer_1_reward': [np.float64(4.411733468563258),\n",
       "    np.float64(45.04549365751143),\n",
       "    np.float64(14.38522230500113),\n",
       "    np.float64(47.889025807144655),\n",
       "    np.float64(66.59594375510522),\n",
       "    np.float64(-34.113163008331284),\n",
       "    np.float64(-54.59730456563125),\n",
       "    np.float64(15.79196403236251),\n",
       "    np.float64(-17.24065733022132),\n",
       "    np.float64(-74.73581968384396)]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.337330916680976),\n",
       "   'mean_inference_ms': np.float64(1.317882094427581),\n",
       "   'mean_action_processing_ms': np.float64(0.18205562599562794),\n",
       "   'mean_env_wait_ms': np.float64(1.6657234775866285),\n",
       "   'mean_env_render_ms': np.float64(0.0)},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0024259090423583984),\n",
       "   'StateBufferConnector_ms': np.float64(0.0023412704467773438),\n",
       "   'ViewRequirementAgentConnector_ms': np.float64(0.05772590637207031)},\n",
       "  'num_episodes': 10,\n",
       "  'episode_return_max': np.float64(104.48447046235398),\n",
       "  'episode_return_min': np.float64(-49.97758701259906),\n",
       "  'episode_return_mean': np.float64(34.31495169008534),\n",
       "  'episodes_this_iter': 10},\n",
       " 'num_agent_steps_sampled_this_iter': 10000,\n",
       " 'num_env_steps_sampled_this_iter': 5000,\n",
       " 'timesteps_this_iter': 5000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resto_algo.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets try with a different number of test agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "2024-09-03 17:50:57,409\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "/opt/conda/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:557: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/opt/conda/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-09-03 17:50:58,981\tWARNING services.py:2017 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67059712 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-09-03 17:51:00,086\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "2024-09-03 17:51:06,518\tWARNING algorithm_config.py:4258 -- You have setup a RLModuleSpec (via calling `config.rl_module(...)`), but have not enabled the new API stack. To enable it, call `config.api_stack(enable_rl_module_and_learner=True)`.\n",
      "2024-09-03 17:51:06,899\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'env_runners': {'episode_reward_max': np.float64(-133.08651258384768),\n",
       "  'episode_reward_min': np.float64(-429.6043485772751),\n",
       "  'episode_reward_mean': np.float64(-279.01460767396213),\n",
       "  'episode_len_mean': np.float64(500.0),\n",
       "  'episode_media': {},\n",
       "  'episodes_timesteps_total': 5000,\n",
       "  'policy_reward_min': {'pursuer_0': np.float64(-70.69341337433875),\n",
       "   'pursuer_1': np.float64(-83.28156152153042),\n",
       "   'pursuer_2': np.float64(-89.37824978401237),\n",
       "   'pursuer_3': np.float64(-64.26033845731828),\n",
       "   'pursuer_4': np.float64(-104.50749893251731),\n",
       "   'pursuer_5': np.float64(-180.21766134359572)},\n",
       "  'policy_reward_max': {'pursuer_0': np.float64(-8.571273725909617),\n",
       "   'pursuer_1': np.float64(60.30311215169101),\n",
       "   'pursuer_2': np.float64(42.74708175708947),\n",
       "   'pursuer_3': np.float64(-7.6108996017414645),\n",
       "   'pursuer_4': np.float64(67.86120096904311),\n",
       "   'pursuer_5': np.float64(-44.10802049107301)},\n",
       "  'policy_reward_mean': {'pursuer_0': np.float64(-42.284014583047856),\n",
       "   'pursuer_1': np.float64(-40.1377328008583),\n",
       "   'pursuer_2': np.float64(-40.48262924096856),\n",
       "   'pursuer_3': np.float64(-45.66979861051086),\n",
       "   'pursuer_4': np.float64(1.1955199344886225),\n",
       "   'pursuer_5': np.float64(-111.63595237306478)},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [np.float64(-166.19797254025622),\n",
       "    np.float64(-326.0186364467571),\n",
       "    np.float64(-345.568169571401),\n",
       "    np.float64(-429.6043485772751),\n",
       "    np.float64(-220.67587333793387),\n",
       "    np.float64(-185.92611986327765),\n",
       "    np.float64(-262.3994365645389),\n",
       "    np.float64(-415.2977044772379),\n",
       "    np.float64(-133.08651258384768),\n",
       "    np.float64(-305.3713027770962)],\n",
       "   'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "   'policy_pursuer_0_reward': [np.float64(-19.490907228469617),\n",
       "    np.float64(-41.93875258924693),\n",
       "    np.float64(-8.571273725909617),\n",
       "    np.float64(-70.69341337433875),\n",
       "    np.float64(-36.23102767416677),\n",
       "    np.float64(-53.02094782426345),\n",
       "    np.float64(-40.14230482430377),\n",
       "    np.float64(-53.63067677345778),\n",
       "    np.float64(-58.96140226997416),\n",
       "    np.float64(-40.1594395463477)],\n",
       "   'policy_pursuer_1_reward': [np.float64(-20.32164907733235),\n",
       "    np.float64(-63.36892477087198),\n",
       "    np.float64(-78.8616327184739),\n",
       "    np.float64(-83.28156152153042),\n",
       "    np.float64(-17.192987182804654),\n",
       "    np.float64(60.30311215169101),\n",
       "    np.float64(-81.58622316165038),\n",
       "    np.float64(15.66510774069288),\n",
       "    np.float64(-59.336612818969634),\n",
       "    np.float64(-73.39595664933358)],\n",
       "   'policy_pursuer_2_reward': [np.float64(42.74708175708947),\n",
       "    np.float64(-48.91667205879994),\n",
       "    np.float64(-60.285853924302046),\n",
       "    np.float64(-75.61061275050122),\n",
       "    np.float64(-50.681475798239205),\n",
       "    np.float64(-28.212178049285676),\n",
       "    np.float64(-24.130360475552504),\n",
       "    np.float64(-89.37824978401237),\n",
       "    np.float64(-13.983339211166555),\n",
       "    np.float64(-56.37463211491561)],\n",
       "   'policy_pursuer_3_reward': [np.float64(-56.420543595035035),\n",
       "    np.float64(-30.623046206764013),\n",
       "    np.float64(-57.08194477161877),\n",
       "    np.float64(-51.94511833327789),\n",
       "    np.float64(-33.07761992343081),\n",
       "    np.float64(-64.26033845731828),\n",
       "    np.float64(-35.91195257054746),\n",
       "    np.float64(-61.13473613175747),\n",
       "    np.float64(-7.6108996017414645),\n",
       "    np.float64(-58.631786513617456)],\n",
       "   'policy_pursuer_4_reward': [np.float64(-33.06575598603719),\n",
       "    np.float64(-3.5606353837811464),\n",
       "    np.float64(39.45019691249885),\n",
       "    np.float64(29.81497359985701),\n",
       "    np.float64(-9.630923310699172),\n",
       "    np.float64(9.37285418175031),\n",
       "    np.float64(48.922254756580564),\n",
       "    np.float64(-104.50749893251731),\n",
       "    np.float64(67.86120096904311),\n",
       "    np.float64(-32.70146746180881)],\n",
       "   'policy_pursuer_5_reward': [np.float64(-79.64619841047161),\n",
       "    np.float64(-137.61060543729332),\n",
       "    np.float64(-180.21766134359572),\n",
       "    np.float64(-177.88861619748133),\n",
       "    np.float64(-73.86183944859376),\n",
       "    np.float64(-110.1086218658516),\n",
       "    np.float64(-129.55085028906458),\n",
       "    np.float64(-122.31165059618439),\n",
       "    np.float64(-61.05545965103868),\n",
       "    np.float64(-44.10802049107301)]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(1.183615472645217),\n",
       "   'mean_inference_ms': np.float64(5.674096303709839),\n",
       "   'mean_action_processing_ms': np.float64(0.6120333169083957),\n",
       "   'mean_env_wait_ms': np.float64(6.530168032174205),\n",
       "   'mean_env_render_ms': np.float64(0.0)},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.005753835042317708),\n",
       "   'StateBufferConnector_ms': np.float64(0.002828836441040039),\n",
       "   'ViewRequirementAgentConnector_ms': np.float64(0.07375001907348633)},\n",
       "  'num_episodes': 10,\n",
       "  'episode_return_max': np.float64(-133.08651258384768),\n",
       "  'episode_return_min': np.float64(-429.6043485772751),\n",
       "  'episode_return_mean': np.float64(-279.01460767396213),\n",
       "  'episodes_this_iter': 10},\n",
       " 'num_agent_steps_sampled_this_iter': 30000,\n",
       " 'num_env_steps_sampled_this_iter': 5000,\n",
       " 'timesteps_this_iter': 5000}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from glob import glob\n",
    "from os import path\n",
    "from ray.rllib.policy.policy import Policy\n",
    "import numpy as np\n",
    "\n",
    "ray.shutdown() \n",
    "\n",
    "# Trained to about 0 combined return\n",
    "checkpoint_path = \"/root/ray_results/PPO_2024-08-28_20-57-45/PPO_2_agent_env_2cf59_00000_0_2024-08-28_20-57-45/checkpoint_000000\"\n",
    "pols = glob(checkpoint_path+\"/policies/*\")\n",
    "specs = {path.basename(p) : Policy.from_checkpoint(p) for p in pols}\n",
    "#specs = {path.basename(p) : SingleAgentRLModuleSpec(load_state_path=p) for p in pols} # Non-deterministic policy weight return (implies new)\n",
    "\n",
    "num_trained_agents = 2\n",
    "num_test_agents = 6\n",
    "\n",
    "register_env(f\"{num_test_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=num_test_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(num_test_agents)}\n",
    "\n",
    "\n",
    "resto_config = (\n",
    "    get_trainable_cls(\"PPO\")\n",
    "    .get_default_config()\n",
    "    .environment(f\"{num_test_agents}_agent_env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .rl_module(\n",
    "        #model_config_dict={\"vf_share_layers\": True},\n",
    "        rl_module_spec=MultiAgentRLModuleSpec(\n",
    "            #load_state_path=\n",
    "            #module_specs=specs,\n",
    "            module_specs={p: SingleAgentRLModuleSpec() for p in policies},\n",
    "        ),\n",
    "    )\n",
    "    .evaluation(\n",
    "        evaluation_interval=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "resto_algo = resto_config.build()\n",
    "for test_id in range(num_test_agents):\n",
    "    train_id = np.random.randint(num_trained_agents)\n",
    "    resto_algo.get_policy(f\"pursuer_{test_id}\").set_weights(specs[f\"pursuer_{train_id}\"].get_weights())\n",
    "\n",
    "#resto_algo.get_policy(\"pursuer_0\").set_weights(specs[\"pursuer_0\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_1\").set_weights(specs[\"pursuer_1\"].get_weights())\n",
    "#resto_algo.get_policy(\"pursuer_0\").get_weights()\n",
    "\n",
    "resto_algo.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 17:55:20,672\tWARNING deprecation.py:50 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'env_runners': {'episode_reward_max': np.float64(-364.769848341295),\n",
       "   'episode_reward_min': np.float64(-619.0375683355406),\n",
       "   'episode_reward_mean': np.float64(-493.78093420107905),\n",
       "   'episode_len_mean': np.float64(500.0),\n",
       "   'episode_media': {},\n",
       "   'episodes_timesteps_total': 5000,\n",
       "   'policy_reward_min': {'pursuer_0': np.float64(-113.90485384019159),\n",
       "    'pursuer_1': np.float64(-109.27251741852379),\n",
       "    'pursuer_2': np.float64(-114.55402342215696),\n",
       "    'pursuer_3': np.float64(-111.76090622319133),\n",
       "    'pursuer_4': np.float64(-109.0597747992956),\n",
       "    'pursuer_5': np.float64(-217.50166684483233)},\n",
       "   'policy_reward_max': {'pursuer_0': np.float64(11.303415129637894),\n",
       "    'pursuer_1': np.float64(0.2069972847033158),\n",
       "    'pursuer_2': np.float64(-46.84567547040106),\n",
       "    'pursuer_3': np.float64(-6.933874989835202),\n",
       "    'pursuer_4': np.float64(-7.903867561959164),\n",
       "    'pursuer_5': np.float64(-102.74657319368887)},\n",
       "   'policy_reward_mean': {'pursuer_0': np.float64(-62.68889913535977),\n",
       "    'pursuer_1': np.float64(-65.25422536988678),\n",
       "    'pursuer_2': np.float64(-74.27730941244923),\n",
       "    'pursuer_3': np.float64(-65.3008027191293),\n",
       "    'pursuer_4': np.float64(-63.75138013879174),\n",
       "    'pursuer_5': np.float64(-162.50831742546185)},\n",
       "   'custom_metrics': {},\n",
       "   'hist_stats': {'episode_reward': [np.float64(-512.3823702423662),\n",
       "     np.float64(-508.5460752882049),\n",
       "     np.float64(-613.3155297566499),\n",
       "     np.float64(-364.769848341295),\n",
       "     np.float64(-495.4410446420681),\n",
       "     np.float64(-619.0375683355406),\n",
       "     np.float64(-389.5228384962124),\n",
       "     np.float64(-382.61291184917025),\n",
       "     np.float64(-603.3023013627752),\n",
       "     np.float64(-448.8788536965084)],\n",
       "    'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "    'policy_pursuer_0_reward': [np.float64(-60.37390249750134),\n",
       "     np.float64(-60.741754372675686),\n",
       "     np.float64(-92.38409091020394),\n",
       "     np.float64(11.303415129637894),\n",
       "     np.float64(-89.95122930874328),\n",
       "     np.float64(-113.90485384019159),\n",
       "     np.float64(-33.69541775768187),\n",
       "     np.float64(-57.605645430906925),\n",
       "     np.float64(-82.23981599404104),\n",
       "     np.float64(-47.29569637128995)],\n",
       "    'policy_pursuer_1_reward': [np.float64(-69.16587427966073),\n",
       "     np.float64(-49.64229550423252),\n",
       "     np.float64(-96.41777564875132),\n",
       "     np.float64(-69.87433716798475),\n",
       "     np.float64(-109.27251741852379),\n",
       "     np.float64(-89.99336501878994),\n",
       "     np.float64(0.2069972847033158),\n",
       "     np.float64(-10.887723201806109),\n",
       "     np.float64(-93.20806475836568),\n",
       "     np.float64(-64.28729798545638)],\n",
       "    'policy_pursuer_2_reward': [np.float64(-89.8094922272591),\n",
       "     np.float64(-68.80568767053518),\n",
       "     np.float64(-114.55402342215696),\n",
       "     np.float64(-70.71135157105256),\n",
       "     np.float64(-75.0275389938279),\n",
       "     np.float64(-47.789534609511726),\n",
       "     np.float64(-46.88852374743173),\n",
       "     np.float64(-91.35057806874335),\n",
       "     np.float64(-46.84567547040106),\n",
       "     np.float64(-90.99068834357274)],\n",
       "    'policy_pursuer_3_reward': [np.float64(-111.32630440205934),\n",
       "     np.float64(-103.95080333396903),\n",
       "     np.float64(-84.83800127252131),\n",
       "     np.float64(-6.933874989835202),\n",
       "     np.float64(-8.589331807829799),\n",
       "     np.float64(-111.76090622319133),\n",
       "     np.float64(-30.30373001435348),\n",
       "     np.float64(-11.583014317344874),\n",
       "     np.float64(-110.78242937291465),\n",
       "     np.float64(-72.93963145727405)],\n",
       "    'policy_pursuer_4_reward': [np.float64(-66.7274235142958),\n",
       "     np.float64(-7.903867561959164),\n",
       "     np.float64(-54.9051831086639),\n",
       "     np.float64(-109.0597747992956),\n",
       "     np.float64(-52.28148786129459),\n",
       "     np.float64(-71.4751414424136),\n",
       "     np.float64(-67.6893324307532),\n",
       "     np.float64(-46.52229002548692),\n",
       "     np.float64(-90.3303342985284),\n",
       "     np.float64(-70.61896634522623)],\n",
       "    'policy_pursuer_5_reward': [np.float64(-114.97937332158938),\n",
       "     np.float64(-217.50166684483233),\n",
       "     np.float64(-170.21645539435244),\n",
       "     np.float64(-119.49392494276402),\n",
       "     np.float64(-160.31893925184878),\n",
       "     np.float64(-184.113767201442),\n",
       "     np.float64(-211.15283183069522),\n",
       "     np.float64(-164.66366080488214),\n",
       "     np.float64(-179.89598146852364),\n",
       "     np.float64(-102.74657319368887)]},\n",
       "   'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(1.2004366875553045),\n",
       "    'mean_inference_ms': np.float64(5.637246124172983),\n",
       "    'mean_action_processing_ms': np.float64(0.6170369138623248),\n",
       "    'mean_env_wait_ms': np.float64(6.577228381745566),\n",
       "    'mean_env_render_ms': np.float64(0.0)},\n",
       "   'num_faulty_episodes': 0,\n",
       "   'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0030291080474853516),\n",
       "    'StateBufferConnector_ms': np.float64(0.002672274907430013),\n",
       "    'ViewRequirementAgentConnector_ms': np.float64(0.0721895694732666)},\n",
       "   'num_episodes': 10,\n",
       "   'episode_return_max': np.float64(-364.769848341295),\n",
       "   'episode_return_min': np.float64(-619.0375683355406),\n",
       "   'episode_return_mean': np.float64(-493.78093420107905),\n",
       "   'episodes_this_iter': 10},\n",
       "  'num_agent_steps_sampled_this_iter': 30000,\n",
       "  'num_env_steps_sampled_this_iter': 5000,\n",
       "  'timesteps_this_iter': 5000,\n",
       "  'num_healthy_workers': 0,\n",
       "  'num_in_flight_async_reqs': 0,\n",
       "  'num_remote_worker_restarts': 0},\n",
       " 'custom_metrics': {},\n",
       " 'episode_media': {},\n",
       " 'info': {'learner': {'pursuer_1': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(8.284326),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.566026151676973),\n",
       "     'policy_loss': np.float64(0.09367009556881385),\n",
       "     'vf_loss': np.float64(6.283298968772093),\n",
       "     'vf_explained_var': np.float64(0.08557038928071657),\n",
       "     'kl': np.float64(0.9452853819413576),\n",
       "     'entropy': np.float64(3.36656474818786),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_2': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(9.113566),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.077735746900241),\n",
       "     'policy_loss': np.float64(0.0958497002410392),\n",
       "     'vf_loss': np.float64(5.798774990439415),\n",
       "     'vf_explained_var': np.float64(0.037562563084065914),\n",
       "     'kl': np.float64(0.9155552069811771),\n",
       "     'entropy': np.float64(3.340836751833558),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_4': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(5.2964835),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.91358299801747),\n",
       "     'policy_loss': np.float64(0.06978534823089527),\n",
       "     'vf_loss': np.float64(6.716566329697768),\n",
       "     'vf_explained_var': np.float64(-0.01836751662194729),\n",
       "     'kl': np.float64(0.6361566481510332),\n",
       "     'entropy': np.float64(3.28274431626002),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_3': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(10.332651),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(6.854018593331178),\n",
       "     'policy_loss': np.float64(0.09294957247087345),\n",
       "     'vf_loss': np.float64(6.589247601230939),\n",
       "     'vf_explained_var': np.float64(0.09223279201736052),\n",
       "     'kl': np.float64(0.8591070479790991),\n",
       "     'entropy': np.float64(3.249066265951842),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_0': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(13.473987),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(8.077613924443721),\n",
       "     'policy_loss': np.float64(0.2053523147891004),\n",
       "     'vf_loss': np.float64(7.52750322073698),\n",
       "     'vf_explained_var': np.float64(0.006246730933586756),\n",
       "     'kl': np.float64(1.723792077577673),\n",
       "     'entropy': np.float64(3.565287616228064),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_5': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(6.1548185),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(9.17444859991471),\n",
       "     'policy_loss': np.float64(0.06458147976275844),\n",
       "     'vf_loss': np.float64(8.96580339173476),\n",
       "     'vf_explained_var': np.float64(0.117337599893411),\n",
       "     'kl': np.float64(0.7203187775623519),\n",
       "     'entropy': np.float64(3.3291859274109203),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}},\n",
       "  'num_env_steps_sampled_for_evaluation_this_iter': 5000,\n",
       "  'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 24000,\n",
       "  'num_agent_steps_trained': 24000},\n",
       " 'env_runners': {'episode_reward_max': np.float64(-327.1718818863369),\n",
       "  'episode_reward_min': np.float64(-651.0568312071787),\n",
       "  'episode_reward_mean': np.float64(-521.166285331625),\n",
       "  'episode_len_mean': np.float64(500.0),\n",
       "  'episode_media': {},\n",
       "  'episodes_timesteps_total': 4000,\n",
       "  'policy_reward_min': {'pursuer_0': np.float64(-89.84811267121047),\n",
       "   'pursuer_1': np.float64(-112.50249861020443),\n",
       "   'pursuer_2': np.float64(-91.24802819055824),\n",
       "   'pursuer_3': np.float64(-107.97904688389782),\n",
       "   'pursuer_4': np.float64(-111.11837925890522),\n",
       "   'pursuer_5': np.float64(-212.1694086810163)},\n",
       "  'policy_reward_max': {'pursuer_0': np.float64(-7.318217051177981),\n",
       "   'pursuer_1': np.float64(-27.58393728642566),\n",
       "   'pursuer_2': np.float64(-48.906998868469366),\n",
       "   'pursuer_3': np.float64(-9.74873670808441),\n",
       "   'pursuer_4': np.float64(-8.12314018169635),\n",
       "   'pursuer_5': np.float64(-79.59940902683455)},\n",
       "  'policy_reward_mean': {'pursuer_0': np.float64(-49.37423269147564),\n",
       "   'pursuer_1': np.float64(-78.80312803094313),\n",
       "   'pursuer_2': np.float64(-79.74707460928532),\n",
       "   'pursuer_3': np.float64(-73.11886170322728),\n",
       "   'pursuer_4': np.float64(-69.70677086543017),\n",
       "   'pursuer_5': np.float64(-170.41621743126296)},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [np.float64(-327.1718818863369),\n",
       "    np.float64(-651.0568312071787),\n",
       "    np.float64(-620.2393821320601),\n",
       "    np.float64(-489.3921927436716),\n",
       "    np.float64(-410.1731976198102),\n",
       "    np.float64(-581.8466747940897),\n",
       "    np.float64(-575.4050666625217),\n",
       "    np.float64(-514.0450556073309)],\n",
       "   'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500],\n",
       "   'policy_pursuer_0_reward': [np.float64(-7.318217051177981),\n",
       "    np.float64(-89.84811267121047),\n",
       "    np.float64(-67.81082695742018),\n",
       "    np.float64(-71.91190472880133),\n",
       "    np.float64(-27.599276463261358),\n",
       "    np.float64(-31.960898365748204),\n",
       "    np.float64(-49.030113199761296),\n",
       "    np.float64(-49.51451209442428)],\n",
       "   'policy_pursuer_1_reward': [np.float64(-74.23225189379251),\n",
       "    np.float64(-68.39240528210188),\n",
       "    np.float64(-111.25103087508597),\n",
       "    np.float64(-111.30135546528297),\n",
       "    np.float64(-78.52141808791102),\n",
       "    np.float64(-46.64012674674057),\n",
       "    np.float64(-112.50249861020443),\n",
       "    np.float64(-27.58393728642566)],\n",
       "   'policy_pursuer_2_reward': [np.float64(-48.906998868469366),\n",
       "    np.float64(-91.24802819055824),\n",
       "    np.float64(-91.00219260111501),\n",
       "    np.float64(-88.84490928958596),\n",
       "    np.float64(-68.45956923680166),\n",
       "    np.float64(-89.8016870322555),\n",
       "    np.float64(-90.06113917726304),\n",
       "    np.float64(-69.65207247823379)],\n",
       "   'policy_pursuer_3_reward': [np.float64(-9.74873670808441),\n",
       "    np.float64(-107.97904688389782),\n",
       "    np.float64(-66.036674815765),\n",
       "    np.float64(-84.80410159987245),\n",
       "    np.float64(-68.74731589259862),\n",
       "    np.float64(-90.15617470942277),\n",
       "    np.float64(-88.53004439188066),\n",
       "    np.float64(-68.94879862429651)],\n",
       "   'policy_pursuer_4_reward': [np.float64(-8.12314018169635),\n",
       "    np.float64(-90.02686706189297),\n",
       "    np.float64(-111.09759313888274),\n",
       "    np.float64(-52.930512633294214),\n",
       "    np.float64(-9.520213959131988),\n",
       "    np.float64(-111.11837925890522),\n",
       "    np.float64(-68.83816491212305),\n",
       "    np.float64(-105.99929577751489)],\n",
       "   'policy_pursuer_5_reward': [np.float64(-178.84253718311618),\n",
       "    np.float64(-203.5623711175165),\n",
       "    np.float64(-173.04106374379046),\n",
       "    np.float64(-79.59940902683455),\n",
       "    np.float64(-157.3254039801049),\n",
       "    np.float64(-212.1694086810163),\n",
       "    np.float64(-166.44310637128856),\n",
       "    np.float64(-192.34643934643628)]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(1.3141188843139466),\n",
       "   'mean_inference_ms': np.float64(5.375802308425255),\n",
       "   'mean_action_processing_ms': np.float64(0.6453345740574232),\n",
       "   'mean_env_wait_ms': np.float64(6.361957551955223),\n",
       "   'mean_env_render_ms': np.float64(0.0)},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.005188087622324626),\n",
       "   'StateBufferConnector_ms': np.float64(0.002494951089223226),\n",
       "   'ViewRequirementAgentConnector_ms': np.float64(0.06810774405797322)},\n",
       "  'num_episodes': 8,\n",
       "  'episode_return_max': np.float64(-327.1718818863369),\n",
       "  'episode_return_min': np.float64(-651.0568312071787),\n",
       "  'episode_return_mean': np.float64(-521.166285331625),\n",
       "  'episodes_this_iter': 8},\n",
       " 'num_healthy_workers': 2,\n",
       " 'num_in_flight_async_sample_reqs': 0,\n",
       " 'num_remote_worker_restarts': 0,\n",
       " 'num_agent_steps_sampled': 24000,\n",
       " 'num_agent_steps_trained': 24000,\n",
       " 'num_env_steps_sampled': 4000,\n",
       " 'num_env_steps_trained': 4000,\n",
       " 'num_env_steps_sampled_this_iter': 4000,\n",
       " 'num_env_steps_trained_this_iter': 4000,\n",
       " 'num_env_steps_sampled_throughput_per_sec': 13.793587026868678,\n",
       " 'num_env_steps_trained_throughput_per_sec': 13.793587026868678,\n",
       " 'timesteps_total': 4000,\n",
       " 'num_env_steps_sampled_lifetime': 4000,\n",
       " 'num_agent_steps_sampled_lifetime': 24000,\n",
       " 'num_steps_trained_this_iter': 4000,\n",
       " 'agent_timesteps_total': 24000,\n",
       " 'timers': {'training_iteration_time_ms': 289989.883,\n",
       "  'restore_workers_time_ms': 0.089,\n",
       "  'training_step_time_ms': 289989.692,\n",
       "  'sample_time_ms': 28168.457,\n",
       "  'learn_time_ms': 261805.355,\n",
       "  'learn_throughput': 15.279,\n",
       "  'synch_weights_time_ms': 15.047,\n",
       "  'restore_eval_workers_time_ms': 0.015,\n",
       "  'evaluation_iteration_time_ms': 70558.346,\n",
       "  'evaluation_iteration_throughput': 70.863},\n",
       " 'counters': {'num_env_steps_sampled_for_evaluation_this_iter': 5000,\n",
       "  'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 24000,\n",
       "  'num_agent_steps_trained': 24000},\n",
       " 'done': False,\n",
       " 'training_iteration': 1,\n",
       " 'trial_id': 'default',\n",
       " 'date': '2024-09-03_18-00-53',\n",
       " 'timestamp': 1725386453,\n",
       " 'time_this_iter_s': 360.55868124961853,\n",
       " 'time_total_s': 360.55868124961853,\n",
       " 'pid': 1345171,\n",
       " 'hostname': 'e-bgbfbjbn-sfks6-0',\n",
       " 'node_ip': '10.42.142.216',\n",
       " 'config': {'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'placement_strategy': 'PACK',\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_for_main_process': 1,\n",
       "  'eager_tracing': True,\n",
       "  'eager_max_retraces': 20,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'torch_compile_learner': False,\n",
       "  'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
       "  'torch_compile_learner_dynamo_backend': 'inductor',\n",
       "  'torch_compile_learner_dynamo_mode': None,\n",
       "  'torch_compile_worker': False,\n",
       "  'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
       "  'torch_compile_worker_dynamo_mode': None,\n",
       "  'enable_rl_module_and_learner': False,\n",
       "  'enable_env_runner_and_connector_v2': False,\n",
       "  'env': '6_agent_env',\n",
       "  'env_config': {},\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  '_is_atari': None,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'action_mask_key': 'action_mask',\n",
       "  'env_runner_cls': None,\n",
       "  'num_env_runners': 2,\n",
       "  'num_envs_per_env_runner': 1,\n",
       "  'num_cpus_per_env_runner': 1,\n",
       "  'num_gpus_per_env_runner': 0,\n",
       "  'custom_resources_per_env_runner': {},\n",
       "  'validate_env_runners_after_construction': True,\n",
       "  'sample_timeout_s': 60.0,\n",
       "  '_env_to_module_connector': None,\n",
       "  'add_default_connectors_to_env_to_module_pipeline': True,\n",
       "  '_module_to_env_connector': None,\n",
       "  'add_default_connectors_to_module_to_env_pipeline': True,\n",
       "  'episode_lookback_horizon': 1,\n",
       "  'rollout_fragment_length': 'auto',\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'compress_observations': False,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'enable_tf1_exec_eagerly': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'update_worker_filter_stats': True,\n",
       "  'use_worker_filter_stats': True,\n",
       "  'enable_connectors': True,\n",
       "  'sampler_perf_stats_ema_coef': None,\n",
       "  'num_learners': 0,\n",
       "  'num_gpus_per_learner': 0,\n",
       "  'num_cpus_per_learner': 1,\n",
       "  'local_gpu_idx': 0,\n",
       "  'gamma': 0.99,\n",
       "  'lr': 5e-05,\n",
       "  'grad_clip': None,\n",
       "  'grad_clip_by': 'global_norm',\n",
       "  'train_batch_size': 4000,\n",
       "  'train_batch_size_per_learner': None,\n",
       "  'model': {'_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'fcnet_weights_initializer': None,\n",
       "   'fcnet_weights_initializer_config': None,\n",
       "   'fcnet_bias_initializer': None,\n",
       "   'fcnet_bias_initializer_config': None,\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'conv_kernel_initializer': None,\n",
       "   'conv_kernel_initializer_config': None,\n",
       "   'conv_bias_initializer': None,\n",
       "   'conv_bias_initializer_config': None,\n",
       "   'conv_transpose_kernel_initializer': None,\n",
       "   'conv_transpose_kernel_initializer_config': None,\n",
       "   'conv_transpose_bias_initializer': None,\n",
       "   'conv_transpose_bias_initializer_config': None,\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'post_fcnet_weights_initializer': None,\n",
       "   'post_fcnet_weights_initializer_config': None,\n",
       "   'post_fcnet_bias_initializer': None,\n",
       "   'post_fcnet_bias_initializer_config': None,\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   'lstm_weights_initializer': None,\n",
       "   'lstm_weights_initializer_config': None,\n",
       "   'lstm_bias_initializer': None,\n",
       "   'lstm_bias_initializer_config': None,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'encoder_latent_dim': None,\n",
       "   'always_check_shapes': False,\n",
       "   'lstm_use_prev_action_reward': -1,\n",
       "   '_use_default_native_models': -1},\n",
       "  '_learner_connector': None,\n",
       "  'add_default_connectors_to_learner_pipeline': True,\n",
       "  'learner_config_dict': {},\n",
       "  'optimizer': {},\n",
       "  'max_requests_in_flight_per_sampler_worker': 2,\n",
       "  '_learner_class': None,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'algorithm_config_overrides_per_module': {},\n",
       "  '_per_module_overrides': {},\n",
       "  'count_steps_by': 'env_steps',\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_mapping_fn': <function __main__.<lambda>(aid, *args, **kwargs)>,\n",
       "  'policies_to_train': None,\n",
       "  'policy_states_are_swappable': False,\n",
       "  'observation_fn': None,\n",
       "  'input_read_method': 'read_parquet',\n",
       "  'input_read_method_kwargs': {},\n",
       "  'input_read_schema': {},\n",
       "  'map_batches_kwargs': {},\n",
       "  'iter_batches_kwargs': {},\n",
       "  'prelearner_class': None,\n",
       "  'prelearner_module_synch_period': 10,\n",
       "  'dataset_num_iters_per_learner': None,\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_config': {},\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'offline_sampling': False,\n",
       "  'evaluation_interval': 1,\n",
       "  'evaluation_duration': 10,\n",
       "  'evaluation_duration_unit': 'episodes',\n",
       "  'evaluation_sample_timeout_s': 120.0,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'evaluation_force_reset_envs_before_iteration': True,\n",
       "  'evaluation_config': None,\n",
       "  'off_policy_estimation_methods': {},\n",
       "  'ope_split_batch_by_episode': True,\n",
       "  'evaluation_num_env_runners': 0,\n",
       "  'in_evaluation': False,\n",
       "  'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
       "  'keep_per_episode_custom_metrics': False,\n",
       "  'metrics_episode_collection_timeout_s': 60.0,\n",
       "  'metrics_num_episodes_for_smoothing': 100,\n",
       "  'min_time_s_per_iteration': None,\n",
       "  'min_train_timesteps_per_iteration': 0,\n",
       "  'min_sample_timesteps_per_iteration': 0,\n",
       "  'export_native_model_files': False,\n",
       "  'checkpoint_trainable_policies_only': False,\n",
       "  'logger_creator': None,\n",
       "  'logger_config': None,\n",
       "  'log_level': 'WARN',\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'seed': None,\n",
       "  '_run_training_always_in_thread': False,\n",
       "  '_evaluation_parallel_to_training_wo_thread': False,\n",
       "  'ignore_env_runner_failures': False,\n",
       "  'recreate_failed_env_runners': False,\n",
       "  'max_num_env_runner_restarts': 1000,\n",
       "  'delay_between_env_runner_restarts_s': 60.0,\n",
       "  'restart_failed_sub_environments': False,\n",
       "  'num_consecutive_env_runner_failures_tolerance': 100,\n",
       "  'env_runner_health_probe_timeout_s': 30,\n",
       "  'env_runner_restore_timeout_s': 1800,\n",
       "  '_model_config_dict': {},\n",
       "  '_rl_module_spec': MultiAgentRLModuleSpec(marl_module_class=<class 'ray.rllib.core.rl_module.marl_module.MultiAgentRLModule'>, inference_only=False, module_specs={'pursuer_1': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_2': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_4': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_3': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_0': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_5': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None),\n",
       "  '_AlgorithmConfig__prior_exploration_config': None,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  '_disable_initialize_loss_from_dummy_batch': False,\n",
       "  '_dont_auto_sync_env_runner_states': False,\n",
       "  'simple_optimizer': True,\n",
       "  'policy_map_cache': -1,\n",
       "  'worker_cls': -1,\n",
       "  'synchronize_filters': -1,\n",
       "  'enable_async_evaluation': -1,\n",
       "  'custom_async_evaluation_function': -1,\n",
       "  '_enable_rl_module_api': -1,\n",
       "  'auto_wrap_old_gym_envs': -1,\n",
       "  'disable_env_checking': -1,\n",
       "  'always_attach_evaluation_results': -1,\n",
       "  'replay_sequence_length': None,\n",
       "  '_disable_execution_plan_api': -1,\n",
       "  'lr_schedule': None,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'use_kl_loss': True,\n",
       "  'kl_coeff': 0.2,\n",
       "  'kl_target': 0.01,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'mini_batch_size_per_learner': None,\n",
       "  'num_sgd_iter': 30,\n",
       "  'shuffle_sequences': True,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'vf_share_layers': -1,\n",
       "  'lambda': 1.0,\n",
       "  'input': 'sampler',\n",
       "  'policies': {'pursuer_1': (None, None, None, None),\n",
       "   'pursuer_2': (None, None, None, None),\n",
       "   'pursuer_4': (None, None, None, None),\n",
       "   'pursuer_3': (None, None, None, None),\n",
       "   'pursuer_0': (None, None, None, None),\n",
       "   'pursuer_5': (None, None, None, None)},\n",
       "  'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       "  'create_env_on_driver': False,\n",
       "  'custom_eval_function': None,\n",
       "  'framework': 'torch'},\n",
       " 'time_since_restore': 360.55868124961853,\n",
       " 'iterations_since_restore': 1,\n",
       " 'perf': {'cpu_util_percent': np.float64(38.932853717026376),\n",
       "  'ram_util_percent': np.float64(9.687649880095922)}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resto_algo.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Callbacks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AlgorithmConfig.training() got an unexpected keyword argument 'trained_agents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 55\u001b[0m\n\u001b[1;32m     34\u001b[0m register_env(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_agents\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_agent_env\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m _: ParallelPettingZooEnv(waterworld_v4\u001b[38;5;241m.\u001b[39mparallel_env(n_pursuers\u001b[38;5;241m=\u001b[39mnum_agents)))\n\u001b[1;32m     35\u001b[0m policies \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpursuer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_agents)}\n\u001b[1;32m     37\u001b[0m config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     38\u001b[0m     \u001b[43mget_trainable_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_agents\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_agent_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Exact 1:1 mapping from AgentID to ModuleID.\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_mapping_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrl_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrl_module_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMultiAgentRLModuleSpec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule_specs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSingleAgentRLModuleSpec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpolicies\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#.evaluation(\u001b[39;49;00m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#    evaluation_interval=1,\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#)\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMyCallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 55\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_agents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_agents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m algo \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mbuild()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py:275\u001b[0m, in \u001b[0;36mPPOConfig.training\u001b[0;34m(self, lr_schedule, use_critic, use_gae, lambda_, use_kl_loss, kl_coeff, kl_target, mini_batch_size_per_learner, sgd_minibatch_size, num_sgd_iter, shuffle_sequences, vf_loss_coeff, entropy_coeff, entropy_coeff_schedule, clip_param, vf_clip_param, grad_clip, vf_share_layers, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the training related configuration.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m    This updated AlgorithmConfig object.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# Pass kwargs onto super's `training()` method.\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_critic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NotProvided:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_critic \u001b[38;5;241m=\u001b[39m use_critic\n",
      "\u001b[0;31mTypeError\u001b[0m: AlgorithmConfig.training() got an unexpected keyword argument 'trained_agents'"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.evaluation import Episode, RolloutWorker\n",
    "from ray.rllib.policy import Policy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyCallbacks(DefaultCallbacks):\n",
    "    def on_episode_start(self, *, episode: Episode, **kwargs) -> None:\n",
    "        episode.hist_data[\"mean_agent_return\"] = []\n",
    "\n",
    "    def on_episode_end(self, *, episode: Episode, **kwargs) -> None:\n",
    "        episode.hist_data[\"mean_agent_return\"].append(\n",
    "            episode.total_reward / len(policies) )\n",
    "        #episode.hist_data['mod_return'] = episode.hist_data['episode_reward']/2\n",
    "    \n",
    "    def on_train_result(self, *, algorithm, result: dict, **kwargs) -> None:\n",
    "        #n_agents = len(policies)        \n",
    "        n_agents = len(result['info']['learner'])\n",
    "        result[\"num_agents\"] = n_agents\n",
    "        #result[\"mod_return\"] = result['info']['hist_stats'][\"episode_reward\"]/2\n",
    "        result[\"mod_return\"] = np.divide(\n",
    "            result['env_runners']['hist_stats']['episode_reward'], n_agents)\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "\n",
    "num_agents = 2\n",
    "register_env(f\"{num_agents}_agent_env\", lambda _: ParallelPettingZooEnv(waterworld_v4.parallel_env(n_pursuers=num_agents)))\n",
    "policies = {f\"pursuer_{i}\" for i in range(num_agents)}\n",
    "\n",
    "config = (\n",
    "    get_trainable_cls(\"PPO\")\n",
    "    .get_default_config()\n",
    "    .environment(f\"{num_agents}_agent_env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .rl_module(\n",
    "        rl_module_spec=MultiAgentRLModuleSpec(\n",
    "            module_specs={p: SingleAgentRLModuleSpec() for p in policies},\n",
    "        ),\n",
    "    )\n",
    "    #.evaluation(\n",
    "    #    evaluation_interval=1,\n",
    "    #)\n",
    "    .callbacks(MyCallbacks)\n",
    "    .training(trained_agents=num_agents)\n",
    ")\n",
    "\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = algo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_metrics': {},\n",
       " 'episode_media': {},\n",
       " 'info': {'learner': {'pursuer_0': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(2.6210372),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(8.687403419613839),\n",
       "     'policy_loss': np.float64(-0.005285420302243438),\n",
       "     'vf_loss': np.float64(8.691376147667567),\n",
       "     'vf_explained_var': np.float64(-7.799391945203145e-06),\n",
       "     'kl': np.float64(0.006563618332711485),\n",
       "     'entropy': np.float64(2.8232320780555407),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)},\n",
       "   'pursuer_1': {'learner_stats': {'allreduce_latency': np.float64(0.0),\n",
       "     'grad_gnorm': np.float32(1.7212684),\n",
       "     'cur_kl_coeff': np.float64(0.20000000000000004),\n",
       "     'cur_lr': np.float64(5.0000000000000016e-05),\n",
       "     'total_loss': np.float64(9.591291411717732),\n",
       "     'policy_loss': np.float64(-0.0064427012531571865),\n",
       "     'vf_loss': np.float64(9.59713891049226),\n",
       "     'vf_explained_var': np.float64(4.220716655254364e-05),\n",
       "     'kl': np.float64(0.002976043204379645),\n",
       "     'entropy': np.float64(2.884414534519116),\n",
       "     'entropy_coeff': np.float64(0.0)},\n",
       "    'model': {},\n",
       "    'custom_metrics': {},\n",
       "    'num_agent_steps_trained': np.float64(125.0),\n",
       "    'num_grad_updates_lifetime': np.float64(480.5),\n",
       "    'diff_num_grad_updates_vs_sampler_policy': np.float64(479.5)}},\n",
       "  'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 8000,\n",
       "  'num_agent_steps_trained': 8000},\n",
       " 'env_runners': {'episode_reward_max': np.float64(-165.02629530939475),\n",
       "  'episode_reward_min': np.float64(-289.7473406212149),\n",
       "  'episode_reward_mean': np.float64(-230.53974094624334),\n",
       "  'episode_len_mean': np.float64(500.0),\n",
       "  'episode_media': {},\n",
       "  'episodes_timesteps_total': 4000,\n",
       "  'policy_reward_min': {'pursuer_0': np.float64(-112.03651630179705),\n",
       "   'pursuer_1': np.float64(-221.37244872613195)},\n",
       "  'policy_reward_max': {'pursuer_0': np.float64(-28.910723104723512),\n",
       "   'pursuer_1': np.float64(-71.54037106148174)},\n",
       "  'policy_reward_mean': {'pursuer_0': np.float64(-65.22577256971653),\n",
       "   'pursuer_1': np.float64(-165.31396837652682)},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'mean_agent_return': [np.float64(-91.78844368163931),\n",
       "    np.float64(-144.87367031060745),\n",
       "    np.float64(-120.7425879385765),\n",
       "    np.float64(-112.4423399231702),\n",
       "    np.float64(-112.44106821259189),\n",
       "    np.float64(-143.5116369237169),\n",
       "    np.float64(-113.84606913997379),\n",
       "    np.float64(-82.51314765469738)],\n",
       "   'episode_reward': [np.float64(-183.57688736327862),\n",
       "    np.float64(-289.7473406212149),\n",
       "    np.float64(-241.485175877153),\n",
       "    np.float64(-224.8846798463404),\n",
       "    np.float64(-224.88213642518377),\n",
       "    np.float64(-287.0232738474338),\n",
       "    np.float64(-227.69213827994759),\n",
       "    np.float64(-165.02629530939475)],\n",
       "   'episode_lengths': [500, 500, 500, 500, 500, 500, 500, 500],\n",
       "   'policy_pursuer_0_reward': [np.float64(-112.03651630179705),\n",
       "    np.float64(-68.3748918950829),\n",
       "    np.float64(-68.4544707211679),\n",
       "    np.float64(-32.72226395986721),\n",
       "    np.float64(-70.79421805834343),\n",
       "    np.float64(-68.39199187660377),\n",
       "    np.float64(-72.12110464014638),\n",
       "    np.float64(-28.910723104723512)],\n",
       "   'policy_pursuer_1_reward': [np.float64(-71.54037106148174),\n",
       "    np.float64(-221.37244872613195),\n",
       "    np.float64(-173.0307051559852),\n",
       "    np.float64(-192.16241588647307),\n",
       "    np.float64(-154.0879183668402),\n",
       "    np.float64(-218.6312819708298),\n",
       "    np.float64(-155.57103363980116),\n",
       "    np.float64(-136.11557220467128)]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.43803057272633217),\n",
       "   'mean_inference_ms': np.float64(1.529297371139412),\n",
       "   'mean_action_processing_ms': np.float64(0.2100298489289901),\n",
       "   'mean_env_wait_ms': np.float64(1.8404896768077144),\n",
       "   'mean_env_render_ms': np.float64(0.0)},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.007826089859008789),\n",
       "   'StateBufferConnector_ms': np.float64(0.0026166439056396484),\n",
       "   'ViewRequirementAgentConnector_ms': np.float64(0.06763637065887451)},\n",
       "  'num_episodes': 8,\n",
       "  'episode_return_max': np.float64(-165.02629530939475),\n",
       "  'episode_return_min': np.float64(-289.7473406212149),\n",
       "  'episode_return_mean': np.float64(-230.53974094624334),\n",
       "  'episodes_this_iter': 8},\n",
       " 'num_healthy_workers': 2,\n",
       " 'num_in_flight_async_sample_reqs': 0,\n",
       " 'num_remote_worker_restarts': 0,\n",
       " 'num_agent_steps_sampled': 8000,\n",
       " 'num_agent_steps_trained': 8000,\n",
       " 'num_env_steps_sampled': 4000,\n",
       " 'num_env_steps_trained': 4000,\n",
       " 'num_env_steps_sampled_this_iter': 4000,\n",
       " 'num_env_steps_trained_this_iter': 4000,\n",
       " 'num_env_steps_sampled_throughput_per_sec': 44.59440704875901,\n",
       " 'num_env_steps_trained_throughput_per_sec': 44.59440704875901,\n",
       " 'timesteps_total': 4000,\n",
       " 'num_env_steps_sampled_lifetime': 4000,\n",
       " 'num_agent_steps_sampled_lifetime': 8000,\n",
       " 'num_steps_trained_this_iter': 4000,\n",
       " 'agent_timesteps_total': 8000,\n",
       " 'timers': {'training_iteration_time_ms': 89697.383,\n",
       "  'restore_workers_time_ms': 0.046,\n",
       "  'training_step_time_ms': 89697.251,\n",
       "  'sample_time_ms': 8158.678,\n",
       "  'learn_time_ms': 81514.168,\n",
       "  'learn_throughput': 49.071,\n",
       "  'synch_weights_time_ms': 23.998},\n",
       " 'counters': {'num_env_steps_sampled': 4000,\n",
       "  'num_env_steps_trained': 4000,\n",
       "  'num_agent_steps_sampled': 8000,\n",
       "  'num_agent_steps_trained': 8000},\n",
       " 'done': False,\n",
       " 'training_iteration': 1,\n",
       " 'trial_id': 'default',\n",
       " 'date': '2024-09-06_20-49-26',\n",
       " 'timestamp': 1725655766,\n",
       " 'time_this_iter_s': 89.70353984832764,\n",
       " 'time_total_s': 89.70353984832764,\n",
       " 'pid': 2066048,\n",
       " 'hostname': 'e-bgbfbjbn-sfks6-0',\n",
       " 'node_ip': '10.42.142.216',\n",
       " 'config': {'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'placement_strategy': 'PACK',\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_for_main_process': 1,\n",
       "  'eager_tracing': True,\n",
       "  'eager_max_retraces': 20,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'torch_compile_learner': False,\n",
       "  'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
       "  'torch_compile_learner_dynamo_backend': 'inductor',\n",
       "  'torch_compile_learner_dynamo_mode': None,\n",
       "  'torch_compile_worker': False,\n",
       "  'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
       "  'torch_compile_worker_dynamo_mode': None,\n",
       "  'enable_rl_module_and_learner': False,\n",
       "  'enable_env_runner_and_connector_v2': False,\n",
       "  'env': '2_agent_env',\n",
       "  'env_config': {},\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  '_is_atari': None,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'action_mask_key': 'action_mask',\n",
       "  'env_runner_cls': None,\n",
       "  'num_env_runners': 2,\n",
       "  'num_envs_per_env_runner': 1,\n",
       "  'num_cpus_per_env_runner': 1,\n",
       "  'num_gpus_per_env_runner': 0,\n",
       "  'custom_resources_per_env_runner': {},\n",
       "  'validate_env_runners_after_construction': True,\n",
       "  'sample_timeout_s': 60.0,\n",
       "  '_env_to_module_connector': None,\n",
       "  'add_default_connectors_to_env_to_module_pipeline': True,\n",
       "  '_module_to_env_connector': None,\n",
       "  'add_default_connectors_to_module_to_env_pipeline': True,\n",
       "  'episode_lookback_horizon': 1,\n",
       "  'rollout_fragment_length': 'auto',\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'compress_observations': False,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'enable_tf1_exec_eagerly': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'update_worker_filter_stats': True,\n",
       "  'use_worker_filter_stats': True,\n",
       "  'enable_connectors': True,\n",
       "  'sampler_perf_stats_ema_coef': None,\n",
       "  'num_learners': 0,\n",
       "  'num_gpus_per_learner': 0,\n",
       "  'num_cpus_per_learner': 1,\n",
       "  'local_gpu_idx': 0,\n",
       "  'gamma': 0.99,\n",
       "  'lr': 5e-05,\n",
       "  'grad_clip': None,\n",
       "  'grad_clip_by': 'global_norm',\n",
       "  'train_batch_size': 4000,\n",
       "  'train_batch_size_per_learner': None,\n",
       "  'model': {'_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'fcnet_weights_initializer': None,\n",
       "   'fcnet_weights_initializer_config': None,\n",
       "   'fcnet_bias_initializer': None,\n",
       "   'fcnet_bias_initializer_config': None,\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'conv_kernel_initializer': None,\n",
       "   'conv_kernel_initializer_config': None,\n",
       "   'conv_bias_initializer': None,\n",
       "   'conv_bias_initializer_config': None,\n",
       "   'conv_transpose_kernel_initializer': None,\n",
       "   'conv_transpose_kernel_initializer_config': None,\n",
       "   'conv_transpose_bias_initializer': None,\n",
       "   'conv_transpose_bias_initializer_config': None,\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'post_fcnet_weights_initializer': None,\n",
       "   'post_fcnet_weights_initializer_config': None,\n",
       "   'post_fcnet_bias_initializer': None,\n",
       "   'post_fcnet_bias_initializer_config': None,\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   'lstm_weights_initializer': None,\n",
       "   'lstm_weights_initializer_config': None,\n",
       "   'lstm_bias_initializer': None,\n",
       "   'lstm_bias_initializer_config': None,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'encoder_latent_dim': None,\n",
       "   'always_check_shapes': False,\n",
       "   'lstm_use_prev_action_reward': -1,\n",
       "   '_use_default_native_models': -1},\n",
       "  '_learner_connector': None,\n",
       "  'add_default_connectors_to_learner_pipeline': True,\n",
       "  'learner_config_dict': {},\n",
       "  'optimizer': {},\n",
       "  'max_requests_in_flight_per_sampler_worker': 2,\n",
       "  '_learner_class': None,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'algorithm_config_overrides_per_module': {},\n",
       "  '_per_module_overrides': {},\n",
       "  'count_steps_by': 'env_steps',\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_mapping_fn': <function __main__.<lambda>(aid, *args, **kwargs)>,\n",
       "  'policies_to_train': None,\n",
       "  'policy_states_are_swappable': False,\n",
       "  'observation_fn': None,\n",
       "  'input_read_method': 'read_parquet',\n",
       "  'input_read_method_kwargs': {},\n",
       "  'input_read_schema': {},\n",
       "  'map_batches_kwargs': {},\n",
       "  'iter_batches_kwargs': {},\n",
       "  'prelearner_class': None,\n",
       "  'prelearner_module_synch_period': 10,\n",
       "  'dataset_num_iters_per_learner': None,\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_config': {},\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'offline_sampling': False,\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_duration': 10,\n",
       "  'evaluation_duration_unit': 'episodes',\n",
       "  'evaluation_sample_timeout_s': 120.0,\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'evaluation_force_reset_envs_before_iteration': True,\n",
       "  'evaluation_config': None,\n",
       "  'off_policy_estimation_methods': {},\n",
       "  'ope_split_batch_by_episode': True,\n",
       "  'evaluation_num_env_runners': 0,\n",
       "  'in_evaluation': False,\n",
       "  'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
       "  'keep_per_episode_custom_metrics': False,\n",
       "  'metrics_episode_collection_timeout_s': 60.0,\n",
       "  'metrics_num_episodes_for_smoothing': 100,\n",
       "  'min_time_s_per_iteration': None,\n",
       "  'min_train_timesteps_per_iteration': 0,\n",
       "  'min_sample_timesteps_per_iteration': 0,\n",
       "  'export_native_model_files': False,\n",
       "  'checkpoint_trainable_policies_only': False,\n",
       "  'logger_creator': None,\n",
       "  'logger_config': None,\n",
       "  'log_level': 'WARN',\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'seed': None,\n",
       "  '_run_training_always_in_thread': False,\n",
       "  '_evaluation_parallel_to_training_wo_thread': False,\n",
       "  'ignore_env_runner_failures': False,\n",
       "  'recreate_failed_env_runners': False,\n",
       "  'max_num_env_runner_restarts': 1000,\n",
       "  'delay_between_env_runner_restarts_s': 60.0,\n",
       "  'restart_failed_sub_environments': False,\n",
       "  'num_consecutive_env_runner_failures_tolerance': 100,\n",
       "  'env_runner_health_probe_timeout_s': 30,\n",
       "  'env_runner_restore_timeout_s': 1800,\n",
       "  '_model_config_dict': {},\n",
       "  '_rl_module_spec': MultiAgentRLModuleSpec(marl_module_class=<class 'ray.rllib.core.rl_module.marl_module.MultiAgentRLModule'>, inference_only=False, module_specs={'pursuer_0': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None), 'pursuer_1': SingleAgentRLModuleSpec(module_class=None, observation_space=None, action_space=None, inference_only=False, model_config_dict=None, catalog_class=None, load_state_path=None)}, load_state_path=None, modules_to_load=None),\n",
       "  '_AlgorithmConfig__prior_exploration_config': None,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  '_disable_initialize_loss_from_dummy_batch': False,\n",
       "  '_dont_auto_sync_env_runner_states': False,\n",
       "  'simple_optimizer': True,\n",
       "  'policy_map_cache': -1,\n",
       "  'worker_cls': -1,\n",
       "  'synchronize_filters': -1,\n",
       "  'enable_async_evaluation': -1,\n",
       "  'custom_async_evaluation_function': -1,\n",
       "  '_enable_rl_module_api': -1,\n",
       "  'auto_wrap_old_gym_envs': -1,\n",
       "  'disable_env_checking': -1,\n",
       "  'always_attach_evaluation_results': -1,\n",
       "  'replay_sequence_length': None,\n",
       "  '_disable_execution_plan_api': -1,\n",
       "  'lr_schedule': None,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'use_kl_loss': True,\n",
       "  'kl_coeff': 0.2,\n",
       "  'kl_target': 0.01,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'mini_batch_size_per_learner': None,\n",
       "  'num_sgd_iter': 30,\n",
       "  'shuffle_sequences': True,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'vf_share_layers': -1,\n",
       "  'lambda': 1.0,\n",
       "  'input': 'sampler',\n",
       "  'policies': {'pursuer_0': (None, None, None, None),\n",
       "   'pursuer_1': (None, None, None, None)},\n",
       "  'callbacks': __main__.MyCallbacks,\n",
       "  'create_env_on_driver': False,\n",
       "  'custom_eval_function': None,\n",
       "  'framework': 'torch'},\n",
       " 'time_since_restore': 89.70353984832764,\n",
       " 'iterations_since_restore': 1,\n",
       " 'perf': {'cpu_util_percent': np.float64(49.089999999999996),\n",
       "  'ram_util_percent': np.float64(9.74846153846154)},\n",
       " 'num_agents': 2,\n",
       " 'mod_return': array([-112.28477977, -105.30352136, -135.2337303 , -150.27593418,\n",
       "        -134.60172764, -112.50189289, -110.97125765, -112.29131475,\n",
       "        -112.50852581, -144.84313125, -122.08270215, -133.03073351,\n",
       "         -88.58860856,  -92.54429235, -121.68296486, -112.93834275])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(-224.56955954147745),\n",
       " np.float64(-210.60704272678404),\n",
       " np.float64(-270.4674606087424),\n",
       " np.float64(-300.55186835564245),\n",
       " np.float64(-269.2034552824137),\n",
       " np.float64(-225.00378578885667),\n",
       " np.float64(-221.94251529451898),\n",
       " np.float64(-224.5826295071694),\n",
       " np.float64(-225.01705161938244),\n",
       " np.float64(-289.68626249930134),\n",
       " np.float64(-244.16540430415856),\n",
       " np.float64(-266.06146701715795),\n",
       " np.float64(-177.1772171119893),\n",
       " np.float64(-185.088584697531),\n",
       " np.float64(-243.36592972517653),\n",
       " np.float64(-225.87668550926975)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['env_runners']['hist_stats']['episode_reward']\n",
    "np.divide(results['env_runners']['hist_stats']['episode_reward'],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['info']['learner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
